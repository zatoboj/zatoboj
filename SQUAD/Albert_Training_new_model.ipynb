{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Albert_Training_new_model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"25229393e30a4396bde059f9037952cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7bf768fc6ec54c42aa5d8627c2a5cfad","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_739110c618374e96baa3be95b3f942fa","IPY_MODEL_ced0a4711ec643ae8a5f94cb253475e1"]}},"7bf768fc6ec54c42aa5d8627c2a5cfad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"739110c618374e96baa3be95b3f942fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9f2f12f9100046e2ac1e7a332e594717","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":760289,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":760289,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_59bb23c1ec7245928c1a78087a88b4c1"}},"ced0a4711ec643ae8a5f94cb253475e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f2bace60d727469293ddaeb1c2296f1a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 760k/760k [00:08&lt;00:00, 92.3kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4066ab35b71b41b582574331eecf0453"}},"9f2f12f9100046e2ac1e7a332e594717":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"59bb23c1ec7245928c1a78087a88b4c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2bace60d727469293ddaeb1c2296f1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4066ab35b71b41b582574331eecf0453":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b82bea190954cbda32ab27ac265416c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4e6448692ad946b48ff4eaafa0ec9913","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_74cafd20849d40f3a5548f3987dfd285","IPY_MODEL_dd0f3953b841446a829a02f9c52960a5"]}},"4e6448692ad946b48ff4eaafa0ec9913":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"74cafd20849d40f3a5548f3987dfd285":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bc99896662334afdb6033c93fa63a16f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":684,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":684,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7a51283232f24cc98ad4f8ce6d8634d1"}},"dd0f3953b841446a829a02f9c52960a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d9c5d89cc3fc4022a4f7bc1362e6d1e0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 684/684 [00:00&lt;00:00, 1.34kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ab9877d0508e451587e15282d11caeae"}},"bc99896662334afdb6033c93fa63a16f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7a51283232f24cc98ad4f8ce6d8634d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d9c5d89cc3fc4022a4f7bc1362e6d1e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ab9877d0508e451587e15282d11caeae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"de75e2db19404287bd5385809e916cc5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8737049e86c74a679e20a48b1eae8b5f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_152f104e20f74b62aaf44a43fbf24b8e","IPY_MODEL_3a53ea72f65a42f3b7efd00ff408f3f2"]}},"8737049e86c74a679e20a48b1eae8b5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"152f104e20f74b62aaf44a43fbf24b8e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2fec9aaddfe4403cbeb4b3e5fd3aff5d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":47376696,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":47376696,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6f91b4fb86804e6d913792413b811a7b"}},"3a53ea72f65a42f3b7efd00ff408f3f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b61778387e8e42928bad6dd7836e7c9f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 47.4M/47.4M [00:06&lt;00:00, 6.92MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_de03d055e8124d71ba114aed1087a911"}},"2fec9aaddfe4403cbeb4b3e5fd3aff5d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6f91b4fb86804e6d913792413b811a7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b61778387e8e42928bad6dd7836e7c9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"de03d055e8124d71ba114aed1087a911":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aff8bfd7c51d40cab3188303db5a8482":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_809cba4c3f7b49f18e52102643bc77b4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f3ada1a3d5b04515beb3ffd960bfde78","IPY_MODEL_85f5f83f67a3414e8a40c4f190b995f2"]}},"809cba4c3f7b49f18e52102643bc77b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"f3ada1a3d5b04515beb3ffd960bfde78":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c93292397ee84755a59192f28eeefcf6","_dom_classes":[],"description":"Validation sanity check: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_44dad2f9cef945bc9e31746f9b79452c"}},"85f5f83f67a3414e8a40c4f190b995f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_068d3eb9bc56453d9fa9787785f7a7d7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2/2 [00:00&lt;00:00,  5.04it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b7ab829272ef47abb7f47a413c3b1b76"}},"c93292397ee84755a59192f28eeefcf6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"44dad2f9cef945bc9e31746f9b79452c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"068d3eb9bc56453d9fa9787785f7a7d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b7ab829272ef47abb7f47a413c3b1b76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"55cbc50a95aa46bfb197babf0bbab9a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_67a79e0e8d574d449205f809772fc011","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b8870bfeeb644f2fb691f96442da97fc","IPY_MODEL_0089aeaf9f05435b9ad499213fd57664"]}},"67a79e0e8d574d449205f809772fc011":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"b8870bfeeb644f2fb691f96442da97fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d5eb6b9777614e3fbc6bbcabc5186866","_dom_classes":[],"description":"Epoch 1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":8280,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":8280,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1268a211f13e4c6ea10278c92cb9f258"}},"0089aeaf9f05435b9ad499213fd57664":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e703a0d380a6446d9992b1420bf3002e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 8280/8280 [58:18&lt;00:00,  2.37it/s, loss=0.203, v_num=3, label_acc=0.868]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_136847d02cee43cfb0673ee79b4ec002"}},"d5eb6b9777614e3fbc6bbcabc5186866":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1268a211f13e4c6ea10278c92cb9f258":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e703a0d380a6446d9992b1420bf3002e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"136847d02cee43cfb0673ee79b4ec002":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9e0565e5046949be9653b6f3e59ef1c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3f967ae484434294ad9a779897f5973c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d6381466b56f40c0934ec0c557379dcc","IPY_MODEL_792749c961ab43bba49f7ef2bfb19a41"]}},"3f967ae484434294ad9a779897f5973c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"d6381466b56f40c0934ec0c557379dcc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_383162c25cc542b0a324075308d003be","_dom_classes":[],"description":"Validating: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_efaef878f15544829dd3f4161db8ea69"}},"792749c961ab43bba49f7ef2bfb19a41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fa415e2c1c79486a874ffb5cecc6e806","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 331/331 [00:57&lt;00:00,  5.80it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fd51ee14613242b28c8c971705b50ee6"}},"383162c25cc542b0a324075308d003be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"efaef878f15544829dd3f4161db8ea69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fa415e2c1c79486a874ffb5cecc6e806":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fd51ee14613242b28c8c971705b50ee6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5ab1b3c15a6491da63985284ad7909c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3b6492cb1e234cf880e6e1c49176981d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_939220510623439b995aff7d0275f782","IPY_MODEL_2ede6fa96ea44b9aa8d03943ba85ce7c"]}},"3b6492cb1e234cf880e6e1c49176981d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"939220510623439b995aff7d0275f782":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bd170bbe751f405d99b161806581f03e","_dom_classes":[],"description":"Validating: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e04925d9f6cb474da475cba0851a1e99"}},"2ede6fa96ea44b9aa8d03943ba85ce7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_164fbb358602480ca1d9ebbebfb6e1e7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 331/331 [00:57&lt;00:00,  5.79it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7d64e2e759c243ea93f874d6344e64ff"}},"bd170bbe751f405d99b161806581f03e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e04925d9f6cb474da475cba0851a1e99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"164fbb358602480ca1d9ebbebfb6e1e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7d64e2e759c243ea93f874d6344e64ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c1e9cec26ad54b08831b35bba0c942db":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_eb4a8643b5bb4d8591dcb85e7cc2c707","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6d3d7f8f0f56496e833945010517f5cb","IPY_MODEL_c2b15fde8d3c4526bbd8e17c7335b88d"]}},"eb4a8643b5bb4d8591dcb85e7cc2c707":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"6d3d7f8f0f56496e833945010517f5cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ac06d1468a1a4baca5e8f5ec01570e1b","_dom_classes":[],"description":"Validating: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8329c3137f67400180422bd0670e60d9"}},"c2b15fde8d3c4526bbd8e17c7335b88d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_be35de1ef7b34c59a92a6bb06cff5774","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 331/331 [00:57&lt;00:00,  5.80it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bf67fd04d67f444aa3d14b6c54495593"}},"ac06d1468a1a4baca5e8f5ec01570e1b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8329c3137f67400180422bd0670e60d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"be35de1ef7b34c59a92a6bb06cff5774":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bf67fd04d67f444aa3d14b6c54495593":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"376ae0bce0db4e32aba46f26e3b8b425":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_01e90c74cca04b38a1d983674d765298","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8826d6e34a7f428bb335eac83b318df6","IPY_MODEL_c0b376063a2c4b9e90f95ec30ad9d8dd"]}},"01e90c74cca04b38a1d983674d765298":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"8826d6e34a7f428bb335eac83b318df6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_be67b451284e45809bb01884fd602b69","_dom_classes":[],"description":"Validating: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8f53a3bbb6ea4821ba881e7a2e8e8b7a"}},"c0b376063a2c4b9e90f95ec30ad9d8dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a307be437e014c7bb7bf5ab73cad188a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 331/331 [00:57&lt;00:00,  5.80it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ec07cfda511c430e9fc7447db21deca7"}},"be67b451284e45809bb01884fd602b69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8f53a3bbb6ea4821ba881e7a2e8e8b7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a307be437e014c7bb7bf5ab73cad188a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ec07cfda511c430e9fc7447db21deca7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0410d29ea72b4d90a88e6188168051af":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5354b2ecd84f479d9e983c72f5d69385","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ba529274a5604b40be7e2e8f49ca8cc7","IPY_MODEL_9ca325089d2e40f0802672fba370cb09"]}},"5354b2ecd84f479d9e983c72f5d69385":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"ba529274a5604b40be7e2e8f49ca8cc7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_da34ffe88e604875b6b43466b40cb50f","_dom_classes":[],"description":"Validating: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1b652742f8af4f87b4f495e153628389"}},"9ca325089d2e40f0802672fba370cb09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_711014d3992b46f0bb72103ea84ebd01","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 331/331 [00:57&lt;00:00,  5.78it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cb25b3b329124acfac60c1e4cd1e7145"}},"da34ffe88e604875b6b43466b40cb50f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1b652742f8af4f87b4f495e153628389":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"711014d3992b46f0bb72103ea84ebd01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cb25b3b329124acfac60c1e4cd1e7145":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9273b17bb1eb431d8b705555c6b157bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c0a303363d48477a8aa9687de1f356cc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4664cccc811340f7b2d66b2c4309b064","IPY_MODEL_56939e48cf424cf0829f135427c0e314"]}},"c0a303363d48477a8aa9687de1f356cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"4664cccc811340f7b2d66b2c4309b064":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_15fbf5363fb84c0a8c7a996da5973a68","_dom_classes":[],"description":"Validating: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4dfc46cc6eeb4f1197d0875f1b8324d2"}},"56939e48cf424cf0829f135427c0e314":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_52519e5aa06c480ba388500a8bbfead4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 331/331 [00:57&lt;00:00,  5.81it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_194911e280cd49d5aff77583eb843df1"}},"15fbf5363fb84c0a8c7a996da5973a68":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4dfc46cc6eeb4f1197d0875f1b8324d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"52519e5aa06c480ba388500a8bbfead4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"194911e280cd49d5aff77583eb843df1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"276f60ba892c48efab1717cfacd8b2f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5730bfe61760480fbbace064c5657e5d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_efdd7a05aa1d43ae88583d3e7c0bbcca","IPY_MODEL_6a1b83a2d01f4b99b880e3b47f07f0c8"]}},"5730bfe61760480fbbace064c5657e5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"efdd7a05aa1d43ae88583d3e7c0bbcca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2611f8388b834945bb078c408d0ab690","_dom_classes":[],"description":"Validating: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a442b7764b9444e2889658950bc921cf"}},"6a1b83a2d01f4b99b880e3b47f07f0c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_83a5ce09cdf84e99a80881c3bf3ff191","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 331/331 [00:57&lt;00:00,  5.79it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ea5c9991ec5f4ef1b4e51f7b440dad70"}},"2611f8388b834945bb078c408d0ab690":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a442b7764b9444e2889658950bc921cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"83a5ce09cdf84e99a80881c3bf3ff191":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ea5c9991ec5f4ef1b4e51f7b440dad70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"37255a32de244da8bcbd0894b885096b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_94149e17d02a49ec9e2c104fb151595c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2b709a7d0ded44f08da0d55066e51e7d","IPY_MODEL_0bbea138241a4448a5d1462357aad077"]}},"94149e17d02a49ec9e2c104fb151595c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"2b709a7d0ded44f08da0d55066e51e7d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5e751ebff53745c9bc95fe8a3fba8f39","_dom_classes":[],"description":"Validating: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_893d96c0cb9443b0872fed09206555ce"}},"0bbea138241a4448a5d1462357aad077":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_32c914b726b3404d81221b0b6b06f2f5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 331/331 [00:57&lt;00:00,  5.80it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_68db58baa602428495987ff7225e6392"}},"5e751ebff53745c9bc95fe8a3fba8f39":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"893d96c0cb9443b0872fed09206555ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"32c914b726b3404d81221b0b6b06f2f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"68db58baa602428495987ff7225e6392":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"GatZ6ZiXFzVh"},"source":["![image.png](data:image/png;base64,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)"]},{"cell_type":"markdown","metadata":{"id":"goRmGIRI5cfC"},"source":["# ALBERT for Question Answering\n","\n","We are using a tensor model on top of ALBERT for the SQUAD 2.0 dataset\n"]},{"cell_type":"markdown","metadata":{"id":"jKj5lgdr5j48"},"source":["## Setup  \n","First, let's check the GPU we got. If memory < 11GB, I'd suggest to do factory reset runtime. Ideally, try to get 16GB"]},{"cell_type":"code","metadata":{"id":"iesFMrWGTx3Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606748984730,"user_tz":-180,"elapsed":1051,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"bf3165c5-e34e-4aa2-c86c-4a43cece3566"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mon Nov 30 15:09:44 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yhf9UjQ3okV8"},"source":["Installing all necessary libraries -- Pytorch Lightning, transformers and tensorflow"]},{"cell_type":"code","metadata":{"id":"UGjilEHk4vb7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606749000538,"user_tz":-180,"elapsed":16848,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"78f1d6ef-73f1-4c0a-f85a-295cbf22057d"},"source":["%tensorflow_version 1.x\n","!pip install -q pytorch-lightning\n","!pip install -q transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","\u001b[K     |████████████████████████████████| 563kB 8.3MB/s \n","\u001b[K     |████████████████████████████████| 829kB 32.6MB/s \n","\u001b[K     |████████████████████████████████| 92kB 12.9MB/s \n","\u001b[K     |████████████████████████████████| 10.6MB 31.6MB/s \n","\u001b[K     |████████████████████████████████| 276kB 63.7MB/s \n","\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: tensorflow 1.15.2 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 1.15.2 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.4.0 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 1.3MB 8.3MB/s \n","\u001b[K     |████████████████████████████████| 890kB 29.6MB/s \n","\u001b[K     |████████████████████████████████| 1.1MB 48.6MB/s \n","\u001b[K     |████████████████████████████████| 2.9MB 68.1MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"X5omrSOMpRDK"},"source":["Some more importing"]},{"cell_type":"code","metadata":{"id":"orKOA-dmpU1j","executionInfo":{"status":"ok","timestamp":1606749010566,"user_tz":-180,"elapsed":26868,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["import os\n","import pickle, json\n","import torch\n","import numpy as np\n","from tqdm import tqdm, trange\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler, DataLoader, random_split\n","import pytorch_lightning as pl\n","from transformers import AlbertModel, AlbertTokenizer"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S8NuAKW9o7hj"},"source":["## Data download \n","\n","Mount the drive to get access to reading and writing files"]},{"cell_type":"code","metadata":{"id":"C5WA386uEpS8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606749027861,"user_tz":-180,"elapsed":44155,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"1cef4324-298d-4ee7-a671-1d2f3a679666"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","root_dir = \"/content/gdrive/My Drive/\"\n","base_dir = root_dir + 'ybshmmlchk/'"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yuUwBKpn-TIK"},"source":["#### Loading preprocessed data. For the preprocessing part -- see Albert_Preprocessing.ipynb\n"]},{"cell_type":"markdown","metadata":{"id":"c0E8SxTYvH2k"},"source":["Define your configuration -- bert model version and max_len"]},{"cell_type":"code","metadata":{"id":"fNHSSHxguiMP","executionInfo":{"status":"ok","timestamp":1606749031010,"user_tz":-180,"elapsed":967,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["conf = {\n","    'model': 'albert', ## options for now-- albert, bert\n","    'model_version' : 'base-v2',\n","    'max_len' : 256\n","}"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"YNlPCaDpuzia","colab":{"base_uri":"https://localhost:8080/","height":164,"referenced_widgets":["25229393e30a4396bde059f9037952cb","7bf768fc6ec54c42aa5d8627c2a5cfad","739110c618374e96baa3be95b3f942fa","ced0a4711ec643ae8a5f94cb253475e1","9f2f12f9100046e2ac1e7a332e594717","59bb23c1ec7245928c1a78087a88b4c1","f2bace60d727469293ddaeb1c2296f1a","4066ab35b71b41b582574331eecf0453","7b82bea190954cbda32ab27ac265416c","4e6448692ad946b48ff4eaafa0ec9913","74cafd20849d40f3a5548f3987dfd285","dd0f3953b841446a829a02f9c52960a5","bc99896662334afdb6033c93fa63a16f","7a51283232f24cc98ad4f8ce6d8634d1","d9c5d89cc3fc4022a4f7bc1362e6d1e0","ab9877d0508e451587e15282d11caeae","de75e2db19404287bd5385809e916cc5","8737049e86c74a679e20a48b1eae8b5f","152f104e20f74b62aaf44a43fbf24b8e","3a53ea72f65a42f3b7efd00ff408f3f2","2fec9aaddfe4403cbeb4b3e5fd3aff5d","6f91b4fb86804e6d913792413b811a7b","b61778387e8e42928bad6dd7836e7c9f","de03d055e8124d71ba114aed1087a911"]},"executionInfo":{"status":"ok","timestamp":1606749034494,"user_tz":-180,"elapsed":3943,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"9cc36660-82ab-4c52-b388-df7e5df184aa"},"source":["#returns tokenizer and model from configuration\n","def nlp_model_tokenizer(conf):\n","  if conf['model'] == 'albert':\n","    from transformers import AlbertTokenizer as your_tokenizer, AlbertModel as your_nlp_model\n","  elif conf['model'] == 'bert':\n","    from transformers import BertTokenizer as your_tokenizer, BertModel as your_nlp_model\n","  else:\n","    print('Please select a different model or rewrite the code for this function to add your model')\n","    return False\n","  try:\n","    return your_tokenizer.from_pretrained(conf['model'] + '-' + conf['model_version']), your_nlp_model.from_pretrained(conf['model'] + '-' + conf['model_version'])\n","  except:\n","    print('Wrong model version. Please select a valid one')\n","    return False\n","\n","tokenizer, bert = nlp_model_tokenizer(conf)"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25229393e30a4396bde059f9037952cb","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760289.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b82bea190954cbda32ab27ac265416c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=684.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de75e2db19404287bd5385809e916cc5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=47376696.0, style=ProgressStyle(descrip…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7dowEmZrEbl_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606749047252,"user_tz":-180,"elapsed":8616,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"a2ac6379-cc63-4d97-a492-2edfc40e47e9"},"source":["# load train dataset\n","pickle_prefix = conf['model'] + '-' + conf['model_version'] + '-' + str(conf['max_len'])\n","try:\n","  with open(root_dir + 'ybshmmlchk/' + pickle_prefix + '-train.pickle', 'rb') as f:\n","      train_data = pickle.load(f)\n","except:\n","  print('Training data hasnt been processed with your choice of model yet. Please go to preprocessing notebook first and run it with your configuration')  \n","input_ids = train_data[\"input_ids\"]\n","token_type_ids = train_data[\"token_type_ids\"]\n","labels = train_data[\"labels\"]\n","attention_mask = train_data[\"attention_mask\"]\n","answer_mask = train_data['answer_mask']\n","plausible_answer_mask = train_data['plausible_answer_mask']\n","actual_answers = train_data['actual_answers']\n","plausible_answers = train_data['plausible_answers']\n","answer_starts = train_data['answer_starts']\n","answer_ends = train_data['answer_ends']\n","full_questions = train_data['full_questions']\n","full_paragraphs = train_data['full_paragraphs']\n","indexing = list(range(0, len(labels)))\n","print('Number of train input ids:'.ljust(30), len(input_ids))\n","# print('Number of train token type ids:'.ljust(30), len(token_type_ids))\n","# print('Number of train labels:'.ljust(30), len(labels))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Number of train input ids:     111281\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RaUsGJo-w0Tl","executionInfo":{"status":"ok","timestamp":1606749048015,"user_tz":-180,"elapsed":8972,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"175d59e4-9c61-4216-fb0c-1771cd65358d"},"source":["# load val dataset\n","pickle_prefix = conf['model'] + '-' + conf['model_version'] + '-' + str(conf['max_len'])\n","try:\n","  with open(root_dir + 'ybshmmlchk/' + pickle_prefix + '-val.pickle', 'rb') as f:\n","      val_data = pickle.load(f)\n","except:\n","  print('Training data hasnt been processed with your choice of model yet. Please go to preprocessing notebook first and run it with your configuration') \n","    \n","val_input_ids = val_data[\"input_ids\"]\n","val_token_type_ids = val_data[\"token_type_ids\"]\n","val_labels = val_data[\"labels\"]\n","val_attention_mask = val_data[\"attention_mask\"]\n","val_answer_mask = val_data['answer_mask']\n","val_plausible_answer_mask = val_data['plausible_answer_mask']\n","val_actual_answers = val_data['actual_answers']\n","val_plausible_answers = val_data['plausible_answers']\n","val_answer_starts = val_data['answer_starts']\n","val_answer_ends = val_data['answer_ends']\n","val_full_questions = val_data['full_questions']\n","val_full_paragraphs = val_data['full_paragraphs']\n","val_indexing = list(range(0, len(val_labels)))\n","print('Number of val input ids:'.ljust(30), len(val_input_ids))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Number of val input ids:       5296\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QoKj1WLzyLEU"},"source":["The fraction of unanswerable questions is about 33%, so about 66% have an answer. The average number of tokens that are in the answer is about 1%. Since the length of our \"sentences\" is 256, the average length of answers is about 3 tokens."]},{"cell_type":"code","metadata":{"id":"P7CfHp4Kyu6k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606561751904,"user_tz":-180,"elapsed":4077,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"5f1334e6-a9e4-4465-a8a3-39c95b558f61"},"source":["print('Fraction of unaswerable questions:', np.mean(labels))\n","print('Average fraction of answer tokens in paragraph:',np.array([np.array(x).mean() for x in answer_mask]).mean())"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Fraction of unaswerable questions: 0.3361939594360223\n","Average fraction of answer tokens in paragraph: 0.011225874700083573\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_gfRvBMctUCD"},"source":["Here is an example of an entry in the dataset. Note that label is is_unanswerable, so True means there is no answer."]},{"cell_type":"code","metadata":{"id":"k8CHPkGNpt5u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606564265952,"user_tz":-180,"elapsed":727,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"5194aea0-999f-4eeb-f15f-a8dd2f8ca3c0"},"source":["i = 153\n","print('Input id:', i)\n","print('Question:', full_questions[i])\n","print('Paragraph:', full_paragraphs[i])\n","print('Answer:', actual_answers[i])\n","print('Plausible answer (if answer doesnt exist):', plausible_answers[i])\n","print('Label:', labels[i]) "],"execution_count":13,"outputs":[{"output_type":"stream","text":["Input id: 153\n","Question: What did the UN Peacebuliding Commission decide on Jan 8, 2008?\n","Paragraph: In 2006, due to ongoing violence, over 50,000 people in the country's northwest were at risk of starvation but this was averted due to assistance from the United Nations.[citation needed] On 8 January 2008, the UN Secretary-General Ban Ki-Moon declared that the Central African Republic was eligible to receive assistance from the Peacebuilding Fund. Three priority areas were identified: first, the reform of the security sector; second, the promotion of good governance and the rule of law; and third, the revitalization of communities affected by conflicts. On 12 June 2008, the Central African Republic requested assistance from the UN Peacebuilding Commission, which was set up in 2005 to help countries emerging from conflict avoid devolving back into war or chaos.\n","Answer: no answer\n","Plausible answer (if answer doesnt exist): the Central African Republic was eligible to receive assistance from the Peacebuilding Fund\n","Label: True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3F1sf5r59l6e"},"source":["Now we define a function which will return train and validation dataloaders. The breakdown is 95-5."]},{"cell_type":"code","metadata":{"id":"kMdQZUjO-MI7","executionInfo":{"status":"ok","timestamp":1606749048016,"user_tz":-180,"elapsed":4555,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["def generate_squad_dataloaders(batch_size):\n","  # ----------------------\n","  # TRAIN/VAL/TEST DATALOADERS\n","  # ----------------------\n","\n","  # TensorDataset from training examples. \".cuda()\" puts the corresponding tensor on gpu\n","  squad_train_dataset = TensorDataset(torch.tensor(input_ids, dtype=torch.long).cuda(),\n","                                torch.tensor(attention_mask, dtype=torch.long).cuda(),  \n","                                torch.tensor(token_type_ids, dtype=torch.long).cuda(), \n","                                1 - torch.tensor(labels, dtype=torch.long).cuda(), #label is 0 if there is an answer in the original dataset\n","                                torch.tensor(answer_mask, dtype=torch.long).cuda(),\n","                                torch.tensor(indexing, dtype=torch.long).cuda(),\n","                                torch.tensor(answer_starts).cuda(),\n","                                torch.tensor(answer_ends).cuda())\n","  \n","  squad_val_dataset = TensorDataset(torch.tensor(val_input_ids, dtype=torch.long).cuda(),\n","                                torch.tensor(val_attention_mask, dtype=torch.long).cuda(),  \n","                                torch.tensor(val_token_type_ids, dtype=torch.long).cuda(), \n","                                1 - torch.tensor(val_labels, dtype=torch.long).cuda(), #label is 0 if there is an answer in the original dataset\n","                                torch.tensor(val_answer_mask, dtype=torch.long).cuda(),\n","                                torch.tensor(val_indexing, dtype=torch.long).cuda(),\n","                                torch.tensor(val_answer_starts).cuda(),\n","                                torch.tensor(val_answer_ends).cuda())\n","  \n","  # test is not actually used yet\n","  \"\"\"squad_test_dataset = TensorDataset(torch.tensor(input_ids[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(),\n","                                torch.tensor(attention_mask[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(),  \n","                                torch.tensor(token_type_ids[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(), \n","                                1 - torch.tensor(labels[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(), #label is 0 if there is an answer in the original dataset\n","                                torch.tensor(answer_mask[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(),\n","                                torch.tensor(indexing[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda())\"\"\"\n","\n","  print('Train set size:', len(labels))\n","  print('Validation set size:', len(val_labels))\n","\n","  # train loader\n","  train_sampler = RandomSampler(squad_train_dataset)\n","  squad_train_dataloader = DataLoader(squad_train_dataset, sampler = train_sampler, batch_size = batch_size)\n","\n","  # val loader\n","  val_sampler = SequentialSampler(squad_val_dataset)\n","  squad_val_dataloader = DataLoader(squad_val_dataset, sampler = val_sampler, batch_size = batch_size, shuffle = False)\n","\n","  # test loader\n","  #test_sampler = RandomSampler(squad_test_dataset)\n","  #squad_test_dataloader = DataLoader(squad_test_dataset, sampler=test_sampler, batch_size = batch_size)\n"," \n","  return squad_train_dataloader, squad_val_dataloader#, squad_test_dataloader"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mvqBwNVaZzh2"},"source":["Defining the model from BERT paper with start and end vector"]},{"cell_type":"code","metadata":{"id":"u5oywwv6Py7u","executionInfo":{"status":"ok","timestamp":1606749048016,"user_tz":-180,"elapsed":3679,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["## TODO: imports up\n","import torch.nn.functional as F\n","import pytorch_lightning as pl\n","from torch import nn\n","\n","'''\n","a -- question cls\n","b -- paragraph cls\n","t -- number of bilinear products\n","'''\n","\n","class SQUADBERTY(pl.LightningModule):\n","\n","    def __init__(self, proj_dim, num_inner_products, batch_size, weight =2., answer_punishment_coeff=1.):\n","        super(SQUADBERTY, self).__init__() \n","        self.bert = bert.cuda()\n","        self.bert_dim = bert.config.hidden_size #768\n","        self.weight = weight\n","        self.answer_punishment_coeff = answer_punishment_coeff\n","        self.batch_size = batch_size\n","        self.max_len = 256\n","        self.proj_dim = proj_dim\n","\n","        self.Proj = nn.Linear(self.bert_dim, self.proj_dim)\n","        self.Proj_cls = nn.Linear(self.bert_dim, self.proj_dim)\n","        self.BL = nn.Bilinear(self.proj_dim, self.proj_dim, num_inner_products) # l scalar products of 2 vectors of dim d\n","        self.L = nn.Linear(num_inner_products, 2)\n","        self.CLS = nn.Linear(self.bert_dim, 2) #(a,b) e^a/(e^a+e^b)\n","\n","        self.squad_train_dataloader, self.squad_val_dataloader = generate_squad_dataloaders(batch_size)\n","\n","    def my_forward_pass(self, cls_bert_output, bert_output_full):\n","        current_batch_size = bert_output_full.shape[0]\n","        bert_output_full = torch.reshape(bert_output_full, (current_batch_size * self.max_len, self.bert_dim))\n","        proj_output_full = self.Proj(bert_output_full)\n","        proj_cls = self.Proj_cls(cls_bert_output)\n","        proj_cls = torch.cat([proj_cls]*self.max_len) # replicated proj_cls to make it the same shape as proj_output_full\n","        long_logits = self.BL(proj_cls, proj_output_full)\n","        long_logits = nn.ReLU6()(long_logits)\n","        long_logits = self.L(long_logits)\n","        long_logits = torch.reshape(long_logits, (current_batch_size, self.max_len, 2))\n","        return long_logits\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","      \n","        bert_output_full, cls_pooler_output = self.bert(input_ids=input_ids, \n","                         attention_mask=attention_mask, \n","                         token_type_ids=token_type_ids)\n","        # bert_output_full.shape = (batch_size, max_len, bert_dim) -- one vector of dim=bert_dim for each token\n","        # cls_pooler_output of shape (batch_size, bert_dim) -- Last layer hidden-state of the first token of the sequence (classification token) \n","        # further processed by a Linear layer and a Tanh activation function. \n","        # The Linear layer weights are trained from the next sentence prediction (classification) objective during pretraining.\n","\n","        cls_bert_output = bert_output_full[:, 0, :] # vector corresponding to CLS token\n","\n","        # long_logits will have shape (batch_size, max_len, 2)\n","        # each output of bert is projected to smaller dimension, then take a few inner products with projection of the cls vector,\n","        # then another dense layer to get logits\n","        long_logits = self.my_forward_pass(cls_bert_output, bert_output_full)\n","        cls_logits = self.CLS(cls_pooler_output)\n","\n","        return cls_logits, long_logits\n","\n","    def training_step(self, batch, batch_nb):\n","        # batch\n","        input_ids, attention_mask, token_type_ids, label, answer_mask, indexing, answer_starts, answer_ends = batch\n","         \n","        # fwd\n","        cls_logits, long_logits = self.forward(input_ids, attention_mask, token_type_ids)\n","        \n","        # loss\n","        # loss for not guessing if there is an answer\n","        loss1 = F.cross_entropy(cls_logits, label, weight = torch.Tensor([2.,1.]))\n","\n","        # loss for each individual word -- is it in the answer?\n","        # TODO: need to insert weight -- around 90 bc of mismatch of 0s and 1s -- only 1% are 1s\n","        loss2 = F.cross_entropy(torch.reshape(long_logits, (long_logits.shape[0] * long_logits.shape[1], long_logits.shape[2])), \n","                                torch.reshape(answer_mask, (answer_mask.shape[0] * answer_mask.shape[1],)), weight = torch.Tensor([1.,50.]))\n","        # total loss\n","        # TODO: experiment with punishment coeff\n","        loss = self.answer_punishment_coeff*loss1 + loss2\n","        self.log('loss', loss, prog_bar=True)\n","        # logs\n","        tensorboard_logs = {'train_loss': loss}\n","\n","        return {'loss': loss, 'log': tensorboard_logs}\n","\n","    def validation_step(self, batch, batch_nb):\n","        # batch\n","        input_ids, attention_mask, token_type_ids, label, answer_mask, indexing, answer_starts, answer_ends = batch\n","         \n","        # fwd\n","        cls_logits, long_logits = self.forward(input_ids, attention_mask, token_type_ids)\n","        \n","        # loss\n","        # loss for not guessing if there is an answer\n","        loss1 = F.cross_entropy(cls_logits, label, weight = torch.Tensor([2.,1.]))\n","\n","        # loss for each individual word -- is it in the answer?\n","        # TODO: need to insert weight -- around 90 bc of mismatch of 0s and 1s -- only 1% are 1s\n","        loss2 = F.cross_entropy(torch.reshape(long_logits, (long_logits.shape[0] * long_logits.shape[1], long_logits.shape[2])), \n","                                torch.reshape(answer_mask, (answer_mask.shape[0] * answer_mask.shape[1],)))#, weight = torch.Tensor([1.,self.weight]))\n","        # total loss\n","        # TODO: experiment with punishment coeff\n","        loss = self.answer_punishment_coeff*loss1 + loss2\n","\n","        # compute accuracy \n","        # TODO: compute precision/recall on individual words, accuracy of start, end, exact match\n","\n","        # ну хоть одна переменная должна нормально называться\n","        a, y1 = torch.max(cls_logits, dim=1)\n","        label_acc = torch.sum(y1 == label) / label.shape[0]\n","        self.log('label_acc', label_acc, prog_bar=True)\n","\n","        return {'val_loss' : loss, 'label_acc' : label_acc}\n","        \n","    def dics_average(self, dics, name):\n","        d = dict()\n","        for key in dics[0].keys():\n","          d[name + key] = torch.stack([x[key] for x in dics]).mean()\n","        return d\n","    \n","    def validation_end(self, outputs):\n","        #'found_pos' : found_pos, 'pos_val' : pos_val, 'pos_res' : pos_res\n","        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n","\n","        \"\"\"pre_dics = [x['pre_guess'] for x in outputs]\n","        post_dics = [x['post_guess'] for x in outputs]\n","        pre_d = self.dics_average(pre_dics, 'pre_avg_')\n","        post_d = self.dics_average(post_dics, 'post_avg_')\n","        #print('\\n validation5 \\n')\n","        tensorboard_logs = {'val_loss': avg_loss, 'pre_guess': pre_d, 'smart_guess': post_d}\n","        #print('\\n validation6 \\n')\"\"\"\n","        self.log('validation_loss', avg_loss, prog_bar=True)\n","        #self.log('pre', pre_d, prog_bar=True)\n","        label_acc = torch.stack([x['label_acc'] for x in outputs]).mean()\n","        self.log('val_label_acc', label_acc, prog_bar=True)\n","        #self.log('end_accuracy', end_acc, prog_bar=True)\n","        tensorboard_logs = {'val_loss': avg_loss, 'val_label_acc' : label_acc}\n","        return {'avg_val_loss': avg_loss, 'progress_bar': tensorboard_logs}\n","\n","    '''\n","    def test_step(self, batch, batch_nb):\n","        input_ids, attention_mask, token_type_ids, label = batch\n","        \n","        y_hat, attn = self.forward(input_ids, attention_mask, token_type_ids)\n","        \n","        a, y_hat = torch.max(y_hat, dim=1)\n","        test_acc = accuracy_score(y_hat.cpu(), label.cpu())\n","        \n","        return {'test_acc': torch.tensor(test_acc)}\n","\n","    def test_end(self, outputs):\n","\n","        avg_test_acc = torch.stack([x['test_acc'] for x in outputs]).mean()\n","\n","        tensorboard_logs = {'avg_test_acc': avg_test_acc}\n","        return {'avg_test_acc': avg_test_acc, 'log': tensorboard_logs, 'progress_bar': tensorboard_logs}\n","    '''\n","    \n","    def configure_optimizers(self):\n","        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=5e-06, eps=1e-08)\n","\n","    def train_dataloader(self):\n","        return self.squad_train_dataloader\n","\n","    def val_dataloader(self):\n","        return self.squad_val_dataloader\n"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FHt8tgwa_DcM"},"source":["### Trainer\n","The trainer takes care of putting things in the correct GPU or not.\n","It handles all the engineering for you (such as automatic early stopping) so you just have to worry about the model and data!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"65Dm1DfilXvs","executionInfo":{"status":"ok","timestamp":1606734666774,"user_tz":-180,"elapsed":795,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"f29388dc-4377-4a12-c2b5-9b54118cd3f3"},"source":["from pytorch_lightning.callbacks import ModelCheckpoint\n","\n","checkpoint_callback = ModelCheckpoint(\n","    filepath=base_dir + '/saved_models/tensor_model_v1',\n","    save_top_k=2,\n","    verbose=True,\n","    monitor='val_loss',\n","    mode='min'\n",")"],"execution_count":19,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Checkpoint directory /content/gdrive/My Drive/ybshmmlchk/saved_models exists and is not empty. With save_top_k=2, all files in this directory will be deleted when a checkpoint is saved!\n","  warnings.warn(*args, **kwargs)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gMRMJ-Kd-oup","colab":{"base_uri":"https://localhost:8080/","height":715,"referenced_widgets":["aff8bfd7c51d40cab3188303db5a8482","809cba4c3f7b49f18e52102643bc77b4","f3ada1a3d5b04515beb3ffd960bfde78","85f5f83f67a3414e8a40c4f190b995f2","c93292397ee84755a59192f28eeefcf6","44dad2f9cef945bc9e31746f9b79452c","068d3eb9bc56453d9fa9787785f7a7d7","b7ab829272ef47abb7f47a413c3b1b76","55cbc50a95aa46bfb197babf0bbab9a6","67a79e0e8d574d449205f809772fc011","b8870bfeeb644f2fb691f96442da97fc","0089aeaf9f05435b9ad499213fd57664","d5eb6b9777614e3fbc6bbcabc5186866","1268a211f13e4c6ea10278c92cb9f258","e703a0d380a6446d9992b1420bf3002e","136847d02cee43cfb0673ee79b4ec002","9e0565e5046949be9653b6f3e59ef1c3","3f967ae484434294ad9a779897f5973c","d6381466b56f40c0934ec0c557379dcc","792749c961ab43bba49f7ef2bfb19a41","383162c25cc542b0a324075308d003be","efaef878f15544829dd3f4161db8ea69","fa415e2c1c79486a874ffb5cecc6e806","fd51ee14613242b28c8c971705b50ee6","b5ab1b3c15a6491da63985284ad7909c","3b6492cb1e234cf880e6e1c49176981d","939220510623439b995aff7d0275f782","2ede6fa96ea44b9aa8d03943ba85ce7c","bd170bbe751f405d99b161806581f03e","e04925d9f6cb474da475cba0851a1e99","164fbb358602480ca1d9ebbebfb6e1e7","7d64e2e759c243ea93f874d6344e64ff","c1e9cec26ad54b08831b35bba0c942db","eb4a8643b5bb4d8591dcb85e7cc2c707","6d3d7f8f0f56496e833945010517f5cb","c2b15fde8d3c4526bbd8e17c7335b88d","ac06d1468a1a4baca5e8f5ec01570e1b","8329c3137f67400180422bd0670e60d9","be35de1ef7b34c59a92a6bb06cff5774","bf67fd04d67f444aa3d14b6c54495593","376ae0bce0db4e32aba46f26e3b8b425","01e90c74cca04b38a1d983674d765298","8826d6e34a7f428bb335eac83b318df6","c0b376063a2c4b9e90f95ec30ad9d8dd","be67b451284e45809bb01884fd602b69","8f53a3bbb6ea4821ba881e7a2e8e8b7a","a307be437e014c7bb7bf5ab73cad188a","ec07cfda511c430e9fc7447db21deca7","0410d29ea72b4d90a88e6188168051af","5354b2ecd84f479d9e983c72f5d69385","ba529274a5604b40be7e2e8f49ca8cc7","9ca325089d2e40f0802672fba370cb09","da34ffe88e604875b6b43466b40cb50f","1b652742f8af4f87b4f495e153628389","711014d3992b46f0bb72103ea84ebd01","cb25b3b329124acfac60c1e4cd1e7145","9273b17bb1eb431d8b705555c6b157bd","c0a303363d48477a8aa9687de1f356cc","4664cccc811340f7b2d66b2c4309b064","56939e48cf424cf0829f135427c0e314","15fbf5363fb84c0a8c7a996da5973a68","4dfc46cc6eeb4f1197d0875f1b8324d2","52519e5aa06c480ba388500a8bbfead4","194911e280cd49d5aff77583eb843df1","276f60ba892c48efab1717cfacd8b2f8","5730bfe61760480fbbace064c5657e5d","efdd7a05aa1d43ae88583d3e7c0bbcca","6a1b83a2d01f4b99b880e3b47f07f0c8","2611f8388b834945bb078c408d0ab690","a442b7764b9444e2889658950bc921cf","83a5ce09cdf84e99a80881c3bf3ff191","ea5c9991ec5f4ef1b4e51f7b440dad70","37255a32de244da8bcbd0894b885096b","94149e17d02a49ec9e2c104fb151595c","2b709a7d0ded44f08da0d55066e51e7d","0bbea138241a4448a5d1462357aad077","5e751ebff53745c9bc95fe8a3fba8f39","893d96c0cb9443b0872fed09206555ce","32c914b726b3404d81221b0b6b06f2f5","68db58baa602428495987ff7225e6392"]},"executionInfo":{"status":"ok","timestamp":1606741673510,"user_tz":-180,"elapsed":7003981,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"6604128d-1456-4622-9364-2452b9f498d5"},"source":["torch.set_default_tensor_type('torch.cuda.FloatTensor')\n","model = SQUADBERTY(20, 5, 16)\n","# most basic trainer, uses good defaults (1 gpu)\n","trainer = pl.Trainer(gpus=1, amp_level='O2',precision=16, max_epochs = 2, val_check_interval=0.25, checkpoint_callback=checkpoint_callback)#, accelerator='ddp')#, progress_bar_refresh_rate = 20)#, val_check_interval=0.25)#checkpoint_callback=checkpoint_callback, max_nb_epochs = 2val_check_interval=1,)    \n","trainer.fit(model) "],"execution_count":20,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n","  warnings.warn(*args, **kwargs)\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Using native 16bit precision.\n","\n","  | Name     | Type        | Params\n","-----------------------------------------\n","0 | bert     | AlbertModel | 11.7 M\n","1 | Proj     | Linear      | 15.4 K\n","2 | Proj_cls | Linear      | 15.4 K\n","3 | BL       | Bilinear    | 2.0 K \n","4 | L        | Linear      | 12    \n","5 | CLS      | Linear      | 1.5 K \n"],"name":"stderr"},{"output_type":"stream","text":["Train set size: 111281\n","Validation set size: 5296\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  warnings.warn(*args, **kwargs)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aff8bfd7c51d40cab3188303db5a8482","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  warnings.warn(*args, **kwargs)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55cbc50a95aa46bfb197babf0bbab9a6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n","Please use self.log(...) inside the lightningModule instead.\n","\n","# log on a step or aggregate epoch metric to the logger and/or progress bar\n","# (inside LightningModule)\n","self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n","  warnings.warn(*args, **kwargs)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e0565e5046949be9653b6f3e59ef1c3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 0: val_loss reached 0.60592 (best 0.60592), saving model to /content/gdrive/My Drive/ybshmmlchk/saved_models/tensor_model_v1-v3.ckpt as top 2\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5ab1b3c15a6491da63985284ad7909c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 0: val_loss reached 0.44254 (best 0.44254), saving model to /content/gdrive/My Drive/ybshmmlchk/saved_models/tensor_model_v1-v4.ckpt as top 2\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c1e9cec26ad54b08831b35bba0c942db","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 0: val_loss reached 0.37111 (best 0.37111), saving model to /content/gdrive/My Drive/ybshmmlchk/saved_models/tensor_model_v1-v5.ckpt as top 2\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"376ae0bce0db4e32aba46f26e3b8b425","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 0: val_loss was not in top 2\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0410d29ea72b4d90a88e6188168051af","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 1: val_loss was not in top 2\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9273b17bb1eb431d8b705555c6b157bd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 1: val_loss was not in top 2\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"276f60ba892c48efab1717cfacd8b2f8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 1: val_loss was not in top 2\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37255a32de244da8bcbd0894b885096b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 1: val_loss was not in top 2\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"t8XvjuyPWmAv"},"source":["**Saving**"]},{"cell_type":"code","metadata":{"id":"aFKxVdIyWut9","executionInfo":{"status":"ok","timestamp":1606741957890,"user_tz":-180,"elapsed":1249,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["model_name = 'tensor_model_v1_final'\n","trainer.save_checkpoint(base_dir + 'saved_models/' + model_name)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v-oJLdeFW2f6"},"source":["**Loading**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ZeKyNlkW7dm","executionInfo":{"status":"ok","timestamp":1606749063987,"user_tz":-180,"elapsed":14522,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"80683793-fe8b-4602-d2cf-b5ae8390e67f"},"source":["torch.set_default_tensor_type('torch.cuda.FloatTensor')\n","model = SQUADBERTY(20, 5, 16)\n","model_name = 'tensor_model_v1_final'\n","checkpoint = torch.load(base_dir + 'saved_models/' + model_name, map_location=lambda storage, loc: storage)\n","model.load_state_dict(checkpoint['state_dict'])\n","model.eval()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Train set size: 111281\n","Validation set size: 5296\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SQUADBERTY(\n","  (bert): AlbertModel(\n","    (embeddings): AlbertEmbeddings(\n","      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0, inplace=False)\n","    )\n","    (encoder): AlbertTransformer(\n","      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n","      (albert_layer_groups): ModuleList(\n","        (0): AlbertLayerGroup(\n","          (albert_layers): ModuleList(\n","            (0): AlbertLayer(\n","              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (attention): AlbertAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (attention_dropout): Dropout(p=0, inplace=False)\n","                (output_dropout): Dropout(p=0, inplace=False)\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              )\n","              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n","              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n","              (dropout): Dropout(p=0, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (pooler): Linear(in_features=768, out_features=768, bias=True)\n","    (pooler_activation): Tanh()\n","  )\n","  (Proj): Linear(in_features=768, out_features=20, bias=True)\n","  (Proj_cls): Linear(in_features=768, out_features=20, bias=True)\n","  (BL): Bilinear(in1_features=20, in2_features=20, out_features=5, bias=True)\n","  (L): Linear(in_features=5, out_features=2, bias=True)\n","  (CLS): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"s9A5HGrcX5kk"},"source":["**Results on validation/train**"]},{"cell_type":"markdown","metadata":{"id":"qrOCKwm8YIeA"},"source":["Helper functions"]},{"cell_type":"code","metadata":{"id":"2XPQPLHxYCeP","executionInfo":{"status":"ok","timestamp":1606749083649,"user_tz":-180,"elapsed":736,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["#returns \"probabilities\" of start and end. not actually probabilities, because this is before softmax\n","def predict(model, batch):\n","  input_ids, attention_mask, token_type_ids, label, answer_mask, indexing, answer_starts, answer_ends = batch\n","  with torch.no_grad():\n","    res =  model(input_ids, attention_mask, token_type_ids)\n","  return res\n","\n","# returns start and end vectors, just based on argmax taken individually\n","def convert_predictions(l1, l2):#, label, answer_mask):\n","  a, y1 = torch.max(l1, dim=1)\n","  a, y2 = torch.max(l2, dim=1)\n","  \n","  return y1, y2#, guess1, guess2, d_pre, d_post\n","\n","# returns start and end vectors taking into account that end>=start + start can't be before question end\n","def convert_predictions_improved(l1, l2, min_start):\n","  starts, ends = [], []\n","  for i in range(l1.shape[0]):\n","    p1, p2 = l1[i], l2[i]\n","    highest_prob = p1[0] + p2[0]\n","    start, end = 0, 0\n","    for k in range(min_start[i], 256):\n","      for j in range(k, 256):\n","        if p1[k] + p2[j] > highest_prob:\n","          highest_prob, start, end = p1[k] + p2[j], k, j\n","    starts.append(start)\n","    ends.append(end)\n","  return torch.Tensor(starts), torch.Tensor(ends)\n","\n","def npf(tt):\n","  return tt.detach().cpu().numpy()\n","\n","def convert_predictions_improved_v3(start_batch, end_batch, min_start=None):\n","  start_batch, end_batch, min_start = npf(start_batch), npf(end_batch), npf(min_start)\n","  #start_batch, end_batch = npf(start_batch), npf(end_batch)\n","  batch_size, max_len = start_batch.shape\n","  probs = start_batch.reshape(-1,max_len,1) + end_batch.reshape(-1,1,max_len) # array of shape: (batch_size, max_len, max_len), matrix of pairwise sums per each element of the batch\n","  if min_start is not None:\n","    mask = np.zeros(probs.shape)  # create a mask to avoid including cases where i > j or i > min_start or j > min_start\n","    for i,s in enumerate(min_start):\n","        mask[i,:s,:] = 1\n","        mask[i,:,:s] = 1\n","        mask[i][np.tril_indices(max_len,-1)] = 1\n","    mask[:,0,0] = 0               # we however leave i=j=0 to detect questions without answers\n","    probs = np.ma.array(probs,mask=mask)\n","    probs = np.ma.filled(probs,-np.inf)\n","  else:\n","    probs = np.triu(probs)\n","  max_probs = np.argmax(probs.reshape(batch_size,-1), axis=-1) # array of shape: (batch_size,), argmaxes of flattened matrices of pairwise sums\n","  starts, ends = np.unravel_index(max_probs, (max_len, max_len)) # two arrays of shape: (batch_size,), 'unflattenning' of max_probs\n","  return starts, ends"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3x7xlrxYYLMQ"},"source":["Validation itself"]},{"cell_type":"code","metadata":{"id":"-l-y4jPtYNQD","executionInfo":{"status":"ok","timestamp":1606749087243,"user_tz":-180,"elapsed":747,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["from pprint import pprint\n","def validate(model, s = 'val'):\n","  #iterator \n","  if s == 'train':\n","    a = (model.train_dataloader())\n","  else:\n","    a = (model.val_dataloader())\n","  #batch = True\n","  d = {\n","        'num_examples' : 0,\n","        'num_labels_guessed' : 0,\n","        'num_ends_guessed' : 0,\n","        'num_exact_matches_guessed' : 0,\n","        'num_starts_guessed_post' : 0,\n","        'num_ends_guessed_post' : 0,\n","        'num_exact_matches_guessed_post' : 0\n","      }\n","  for batch_ndx, batch in enumerate(a):\n","    #batch = iterator.next()\n","    l1, l2 = predict(model, batch)\n","    a, y1 = torch.max(l1, dim=1)\n","    #y1, y2 = convert_predictions(l1, l2)\n","    input_ids, attention_mask, token_type_ids, label, answer_mask, indexing, answer_starts, answer_ends = batch\n","    #start, end = answer_starts, answer_ends#get_start_end(answer_mask)\n","    d['num_examples'] += l1.shape[0]\n","    d['num_labels_guessed'] += torch.sum(y1==label)\n","    \"\"\"d['num_ends_guessed'] += torch.sum(end==y2)\n","    d['num_exact_matches_guessed'] += torch.sum(((start==y1).double()  + (end==y2).double() )==2.)\n","    _ , min_start = torch.max(token_type_ids, dim=1)\n","    \n","    y1, y2 = convert_predictions_improved_v3(l1, l2, min_start)\n","    #input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","    start, end = npf(start), npf(end)\n","    d['num_starts_guessed_post'] += np.sum(start==y1)\n","    d['num_ends_guessed_post'] += np.sum(end==y2)\n","    d['num_exact_matches_guessed_post'] += np.sum(((start==y1).astype(int)  + (end==y2).astype(int) )==2)\n","\n","    d['EM'] = d['num_exact_matches_guessed'] / d['num_examples']\n","    d['EM post'] = d['num_exact_matches_guessed_post'] / d['num_examples']\n","    if batch_ndx%300 == 0:\n","      print(batch_ndx)\n","      pprint(d)\"\"\"\n","  return d\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XEjNzdZ2YVQb","executionInfo":{"status":"ok","timestamp":1606749141008,"user_tz":-180,"elapsed":49883,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"ff2d751b-ef5c-4390-bc07-1192219bcb95"},"source":["validate(model, 'val')"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'num_ends_guessed': 0,\n"," 'num_ends_guessed_post': 0,\n"," 'num_exact_matches_guessed': 0,\n"," 'num_exact_matches_guessed_post': 0,\n"," 'num_examples': 5296,\n"," 'num_labels_guessed': tensor(4602),\n"," 'num_starts_guessed_post': 0}"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JUfjKCqByO6G","executionInfo":{"status":"ok","timestamp":1606745484864,"user_tz":-180,"elapsed":957,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"0ef03887-f365-4b7c-9296-e1587e466370"},"source":["4602/5296"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8689577039274925"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kqJnYUF3e9wh","executionInfo":{"status":"ok","timestamp":1606588873018,"user_tz":-180,"elapsed":1028214,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"450c5751-846a-4ed5-c725-8c95836c935f"},"source":["# should run this only if very interested -- takes a while\n","#validate(model, 'train')"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'num_ends_guessed': 0,\n"," 'num_ends_guessed_post': 0,\n"," 'num_exact_matches_guessed': 0,\n"," 'num_exact_matches_guessed_post': 0,\n"," 'num_examples': 111281,\n"," 'num_labels_guessed': tensor(105663),\n"," 'num_starts_guessed_post': 0}"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJl_nqprKUwm","executionInfo":{"status":"ok","timestamp":1606588921011,"user_tz":-180,"elapsed":960,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"e05cecec-4c6f-4065-efcf-2b188b795692"},"source":["105663/111281"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9495151912725442"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"5qXUESXVhQwF","executionInfo":{"status":"ok","timestamp":1606752364659,"user_tz":-180,"elapsed":1847,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["def get_stats_on_batch(model, batch):\n","    d = {}\n","    l1, l2 = predict(model, batch)\n","    print(l1.shape, l2.shape)\n","    #l1 = l1[:,1] - l1[:,0]\n","    l2 = l2[:,:,1] - l2[:,:,0]\n","    a, y1 = torch.max(l1, dim=1)\n","    #y2 = l2[(l2>0.).nonzero()]\n","    #y1, y2 = convert_predictions(l1, l2)\n","    input_ids, attention_mask, token_type_ids, label, answer_mask, indexing, answer_starts, answer_ends = batch\n","    start, end = answer_starts, answer_ends#get_start_end(answer_mask)\n","    d['num_examples'] = start.shape[0]\n","    #d['num_starts_guessed'] = torch.sum(start==y1)\n","    #d['num_ends_guessed'] = torch.sum(end==y2)\n","    #d['num_exact_matches_guessed'] = torch.sum(((start==y1).double()  + (end==y2).double() )==2.)\n","    #_ , min_start = torch.max(token_type_ids, dim=1)\n","    \n","    #predicted_start, predicted_end = convert_predictions_improved_v3(l1, l2, min_start)\n","    #input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","    #start, end = npf(start), npf(end)\n","\n","    #d['num_starts_guessed_post'] = np.sum(start==predicted_start)\n","    #d['num_ends_guessed_post'] = np.sum(end==predicted_end)\n","    #d['num_exact_matches_guessed_post'] = np.sum(((start==predicted_start).astype(int)  + (end==predicted_end).astype(int) )==2)\n","    predicted_label = npf(y1).astype(int)#predicted_start.copy().astype(int)\n","    #predicted_label[predicted_label!=0] = 1 \n","    label = npf(label).astype(int)\n","    d['num_labels_guessed'] = np.sum(label == predicted_label)\n","    d['label_prob'] = l1[:,1] - l1[:,0]\n","    #d['predicted_start'] = predicted_start\n","    #d['predicted_end'] = predicted_end\n","    d['predicted_label'] = predicted_label\n","    d['actual_start'] = answer_starts\n","    d['actual_end'] = answer_ends\n","    d['actual_label'] = label\n","    d['input_ids'] = input_ids\n","    d['indexing'] = indexing\n","    d['full_probs'] = l2\n","    #d['start_probs'] = l1\n","    #d['end_probs'] = l2\n","    return d\n","\n","def batch_by_number(model, i):\n","  dataloader = model.val_dataloader()\n","  for batch_ndx, batch in enumerate(dataloader):\n","    if batch_ndx == i:\n","      return batch\n","\n","def print_example(d, i):\n","  res = {}\n","  index = d['indexing'][i]\n","  #predicted_start = d['predicted_start'][i]\n","  #predicted_end = d['predicted_end'][i]\n","  input_ids = d['input_ids'][i]\n","  probs = d['full_probs'][i]\n","  res['predicted_answer'] = tokenizer.convert_ids_to_tokens(input_ids[probs>0])\n","  res['predicted_probs'] = probs[probs>0]\n","  res['actual_answer'] = val_actual_answers[index]\n","  #print(d['indexing'][i])\n","  res['actual_label'] = d['actual_label'][i]\n","  res['predicted_label'] = d['predicted_label'][i]\n","  res['text'] = val_full_paragraphs[index]\n","  res['question'] = val_full_questions[index]\n","  res['label_prob'] = d['label_prob'][i]\n","  return res"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ydvgoewQhQ1i","executionInfo":{"status":"ok","timestamp":1606754758518,"user_tz":-180,"elapsed":825,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"078649ef-63e2-4f88-8b65-858766fdc117"},"source":["# prints one example in a batch\n","# predicted answers -- all words with > 0 logarithmic probability of being in the answer\n","batch = batch_by_number(model, 5)\n","d = get_stats_on_batch(model, batch)\n","num_in_batch = 8\n","pprint(print_example(d, num_in_batch))"],"execution_count":74,"outputs":[{"output_type":"stream","text":["torch.Size([16, 2]) torch.Size([16, 256, 2])\n","{'actual_answer': '2nd',\n"," 'actual_label': 1,\n"," 'label_prob': tensor(3.4697),\n"," 'predicted_answer': ['▁3',\n","                      '.',\n","                      '36',\n","                      '▁2',\n","                      'nd',\n","                      '▁overall',\n","                      '▁for',\n","                      'pa',\n","                      '▁and',\n","                      '▁8',\n","                      'th',\n","                      '▁for',\n","                      '▁',\n","                      '\"',\n","                      '▁power',\n","                      '\"'],\n"," 'predicted_label': 1,\n"," 'predicted_probs': tensor([1.7600, 2.8010, 1.2794, 5.4778, 4.7394, 0.8682, 0.7064, 0.2389, 0.7846,\n","        2.7107, 2.7371, 0.7550, 0.5801, 0.3148, 0.5436, 0.1471]),\n"," 'question': \"What was Imperial's overall GPA rank according to the Times \"\n","             'Higher Education?',\n"," 'text': 'Imperial submitted a total of 1,257 staff across 14 units of '\n","         'assessment to the 2014 Research Excellence Framework (REF) '\n","         \"assessment. In the REF results 46% of Imperial's submitted research \"\n","         'was classified as 4*, 44% as 3*, 9% as 2* and 1% as 1*, giving an '\n","         'overall GPA of 3.36. In rankings produced by Times Higher Education '\n","         'based upon the REF results Imperial was ranked 2nd overall for GPA '\n","         'and 8th for \"research power\" (compared to 6th and 7th respectively '\n","         'in the equivalent rankings for the RAE 2008).'}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aM7ujFALyPtH"},"source":["**THIS IS THE END OF TRAINING CODE. THE CODE BELOW HASN'T BEEN REVIEWED/REWRITTEN**\n"]},{"cell_type":"code","metadata":{"id":"7EPaaRY2hQ42"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_sug5SQ_Fwyc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f3XiObM4Fw54"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PoHcb1MmhQ8z"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DVWuTQ570bpy","colab":{"base_uri":"https://localhost:8080/","height":745},"outputId":"94196fca-1f79-43ee-fa96-393afdc08da3"},"source":["bert_finetuner"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SQUADBERT(\n","  (bert): AlbertModel(\n","    (embeddings): AlbertEmbeddings(\n","      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): AlbertTransformer(\n","      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n","      (albert_layer_groups): ModuleList(\n","        (0): AlbertLayerGroup(\n","          (albert_layers): ModuleList(\n","            (0): AlbertLayer(\n","              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (attention): AlbertAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              )\n","              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n","              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (pooler): Linear(in_features=768, out_features=768, bias=True)\n","    (pooler_activation): Tanh()\n","  )\n","  (A1): Linear(in_features=768, out_features=100, bias=True)\n","  (B1): Linear(in_features=768, out_features=100, bias=True)\n","  (LG1): Linear(in_features=10, out_features=2, bias=True)\n","  (A2): Linear(in_features=768, out_features=100, bias=True)\n","  (B2): Linear(in_features=768, out_features=100, bias=True)\n","  (LG2): Linear(in_features=10, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"bNR0ipTe0b1-"},"source":["def get_random_batch(model):\n","  iterator = iter(model.val_dataloader())\n","  batch = iterator.next()\n","  #for i in batch:\n","  #  i = i.to(torch.device('cuda',0))\n","  return (batch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3I-AErsq1F7t"},"source":["def predict(model, batch):\n","  input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","  return model(input_ids, attention_mask, token_type_ids)\n","\n","def convert_predictions(l1, l2, label, answer_mask):\n","  a, y1 = torch.max(l1, dim=1)\n","  a, y2 = torch.max(l2, dim=2)\n","  guess1, guess2 = final_guess(l1, l2)\n","  \"\"\"if self.counter < 10:\n","    self.counter += 1\n","    self.dic_1[self.counter] = [l2, y2]\"\"\"\n","  d_pre = results_dic(y1, y2, label, answer_mask)\n","  d_post = results_dic(guess1, guess2, label, answer_mask)\n","  return y1, y2, guess1, guess2, d_pre, d_post"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AuwZv_Ng1GED"},"source":["batch =  get_random_batch(new_model)#(bert_finetuner)\n","input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","l1, l2 = predict(new_model, batch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zopOdSYalAgt","colab":{"base_uri":"https://localhost:8080/","height":87},"outputId":"3b721249-e3bf-4f35-cb3e-6b4462827b94"},"source":["print(indexing)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([  1709,  50257,  28607,  85809,  18089,  43168, 109889, 114528,  36480,\n","        105855,  90441,  58618,  93205, 103048,  66757,  74668,   6850,  47620,\n","         88623,  44466,  21506, 101689,  32743,  40006,  49163, 112892,  74904,\n","         62193,  44188,  93296, 116388,  26653])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZARZmoMN0b_R"},"source":["y1, y2, guess1, guess2, d1, d2 = convert_predictions(l1, l2, label, answer_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ck-huWF-SYW","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"1d14eff0-689b-41d2-d751-9fdf01f18b1e"},"source":["print(y1)\n","print(guess1.type(torch.IntTensor))\n","print(label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n","        1, 1, 1, 1, 0, 1, 1, 0])\n","tensor([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n","        1, 1, 1, 1, 0, 1, 1, 0], device='cpu', dtype=torch.int32)\n","tensor([0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n","        1, 1, 1, 0, 0, 1, 1, 0])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LCaGo_h8Uvn1","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"bce5ca45-cf14-49ff-99d7-63b2381238f1"},"source":["print(y1)\n","print(guess1.type(torch.IntTensor))\n","print(label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n","        1, 0, 0, 1, 1, 0, 1, 1])\n","tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n","        1, 0, 1, 1, 1, 0, 1, 1], device='cpu', dtype=torch.int32)\n","tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n","        1, 0, 1, 1, 1, 0, 1, 1])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bAJG51UM-A5d","colab":{"base_uri":"https://localhost:8080/","height":834},"outputId":"6fb66077-5a43-4839-90d5-4137d729b006"},"source":["i = 10\n","print(y2[i])\n","print(guess2[i].type(torch.IntTensor))\n","print(answer_mask[i])\n","index = indexing[i].item()\n","print(torch.IntTensor(plausible_answer_mask[index]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cpu',\n","       dtype=torch.int32)\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cpu',\n","       dtype=torch.int32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LnoqxsIM_xwM","colab":{"base_uri":"https://localhost:8080/","height":161},"outputId":"d8198c69-5829-417e-d9b8-8537bf94ffad"},"source":["print(get_answer(input_ids[i], answer_mask[i]))\n","\n","print(get_answer(input_ids[i], guess2[i]))\n","index = indexing[i].item()\n","print(index)\n","print(full_answers[index])\n","print(full_questions[index])\n","print(full_paragraphs[index])\n","print(get_answer(input_ids[i], torch.Tensor(plausible_answer_mask[index])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['▁arab']\n","None\n","90441\n","Arab\n","What race was the majority in Palestine in the 1940s?\n","The British Mandate of Palestine, where an Arab majority lived alongside a Jewish minority, presented the British with a similar problem to that of India. The matter was complicated by large numbers of Jewish refugees seeking to be admitted to Palestine following the Holocaust, while Arabs were opposed to the creation of a Jewish state. Frustrated by the intractability of the problem, attacks by Jewish paramilitary organisations and the increasing cost of maintaining its military presence, Britain announced in 1947 that it would withdraw in 1948 and leave the matter to the United Nations to solve. The UN General Assembly subsequently voted for a plan to partition Palestine into a Jewish and an Arab state.\n","['▁arab']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I2J50MNEAhOQ"},"source":["def get_answer(input_id, answer):\n","  indices = (numpy.nonzero(answer)).tolist()\n","  #print(indices)\n","  #  indices.append(l[0])\n","  if indices:\n","    tokens = tokenizer.convert_ids_to_tokens(input_id)\n","    return tokens[indices[0][0]:indices[-1][0]+1]\n","  else:\n","    return None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WB9GOlzXld7M"},"source":["def get_probabilities_individual(l, answer):\n","  indices = (numpy.nonzero(answer)).tolist()\n","  if indices:\n","    res = l[indices[0][0]:indices[-1][0]+1]\n","    return res[:,1] - res[:,0]\n","  else:\n","    return None\n","\n","def get_probability_label(l):\n","  return l[1] - l[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oVEDXob-l4fm","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"d1abef62-8ddb-4575-8975-69a8cec86a01"},"source":["print(get_probabilities_individual(l2[i], guess2[i]))\n","print(get_probability_label(l1[i]))\n","print(guess1[i] - label[i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["None\n","tensor(-0.8393, grad_fn=<SubBackward0>)\n","tensor(-1.)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"55yY-rZ6Dr3A"},"source":["def get_wrong_guesses(guesses, lbls):\n","  wrong_guesses = []\n","  for x in (guesses - lbls).nonzero().cpu().numpy().tolist():\n","    wrong_guesses.append(x[0])\n","  return wrong_guesses"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ThmCMhScEqBY","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"52664d18-6788-467e-d927-924858fb8b95"},"source":["wrong_guesses = get_wrong_guesses(y1, label)\n","print(wrong_guesses)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[10, 26]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fhV42t3I0KOw","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"248107bd-b38a-413f-ab51-f378f979daad"},"source":["i = 26\n","print(get_probabilities_individual(l2[i], guess2[i]))\n","print(get_probabilities_individual(l2[i], answer_mask[i]))\n","index = indexing[i].item()\n","print(get_probabilities_individual(l2[i], torch.Tensor(plausible_answer_mask[index])))\n","print(get_probability_label(l1[i]))\n","#print(guess1[i] - label[i])\n","print(guess1[i], label[i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([3.1200, 2.9809, 2.7662, 3.3491, 0.1146, 0.0939, 0.4229],\n","       grad_fn=<SubBackward0>)\n","tensor([3.1200, 2.9809, 2.7662, 3.3491], grad_fn=<SubBackward0>)\n","tensor([3.1200, 2.9809, 2.7662, 3.3491], grad_fn=<SubBackward0>)\n","tensor(-0.6872, grad_fn=<SubBackward0>)\n","tensor(1.) tensor(1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zVbJ_YSXlq6X","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b62e26cd-1418-4907-f85f-fa6a5ce421d1"},"source":["l1.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 2])"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tQ4whqxy3JLg","executionInfo":{"status":"ok","timestamp":1606684555665,"user_tz":-180,"elapsed":722,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"153c6f06-7071-494c-b45d-af340eda1541"},"source":["32*256*768*12*32/8/1024/1024"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["288.0"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"0s8xPk_s8SLd","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"dfaf627e-e448-4348-863c-025de107bd2b"},"source":["d1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answerable_actual': tensor(0.5625),\n"," 'answerable_result': tensor(0.5625),\n"," 'guessed_answerable': tensor(0.4375),\n"," 'guessed_ones': tensor(0.0115),\n"," 'ones_percentage_actual': tensor(0.0122),\n"," 'ones_percentage_guessed': tensor(0.0454),\n"," 'val_acc_individual': tensor(0.9653),\n"," 'val_acc_labels': tensor(0.7500)}"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"tHx6EqxVU30Q","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"241f371d-734a-4df7-b582-29a6cdcd24fb"},"source":["d1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answerable_actual': tensor(0.5625),\n"," 'answerable_result': tensor(0.5625),\n"," 'guessed_answerable': tensor(0.4375),\n"," 'guessed_ones': tensor(0.0115),\n"," 'ones_percentage_actual': tensor(0.0122),\n"," 'ones_percentage_guessed': tensor(0.0454),\n"," 'val_acc_individual': tensor(0.9653),\n"," 'val_acc_labels': tensor(0.7500)}"]},"metadata":{"tags":[]},"execution_count":147}]},{"cell_type":"code","metadata":{"id":"NAND2ZW88XMd","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"ec84b873-39db-4ada-952e-ab03073eebc9"},"source":["d2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answerable_actual': tensor(0.5625),\n"," 'answerable_result': tensor(0.5625),\n"," 'guessed_answerable': tensor(0.4375),\n"," 'guessed_ones': tensor(0.0112),\n"," 'ones_percentage_actual': tensor(0.0122),\n"," 'ones_percentage_guessed': tensor(0.0270),\n"," 'val_acc_individual': tensor(0.9833),\n"," 'val_acc_labels': tensor(0.7500)}"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"lVqPQ8u3VJ5t","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"711895e1-6ef7-4527-d4e5-54fe9caea34a"},"source":["d2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answerable_actual': tensor(0.5625),\n"," 'answerable_result': tensor(0.6875),\n"," 'guessed_answerable': tensor(0.5312),\n"," 'guessed_ones': tensor(0.0112),\n"," 'ones_percentage_actual': tensor(0.0122),\n"," 'ones_percentage_guessed': tensor(0.0270),\n"," 'val_acc_individual': tensor(0.9833),\n"," 'val_acc_labels': tensor(0.8125)}"]},"metadata":{"tags":[]},"execution_count":148}]},{"cell_type":"markdown","metadata":{"id":"tcrUfpD0X6nF"},"source":["##Saving"]},{"cell_type":"code","metadata":{"id":"T8i5psJPYCRY","colab":{"base_uri":"https://localhost:8080/","height":292},"outputId":"63fb2a35-ab66-43a4-8771-180c121a9b8a"},"source":["#bert_finetuner.save_checkpoint(base_dir + './saved_models_albert')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-152-22c3859db120>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_finetuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'./saved_models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'SQUADBERT' object has no attribute 'save_checkpoint'"]}]},{"cell_type":"code","metadata":{"id":"x6NEGHMBZGze"},"source":["#bert_finetuner."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bepR4KwgZyIo"},"source":["trainer.save_checkpoint(base_dir + 'saved_models/new')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LlBeUTTJYCaz","colab":{"base_uri":"https://localhost:8080/","height":316},"outputId":"e0b1b7b9-8ef0-4956-e957-0bc72b7ab90f"},"source":["#input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","#ll1, ll2 = predict(new_model, batch)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-175-e88a2b27191f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mll1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-144-abd96af2e684>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-cd8f6805240c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m    108\u001b[0m         q, _, attn = self.bert(input_ids=input_ids, \n\u001b[1;32m    109\u001b[0m                          \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                          token_type_ids=token_type_ids)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mq_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         )\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                 \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_idx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers_per_group\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgroup_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers_per_group\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m             )\n\u001b[1;32m    346\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_group_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malbert_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malbert_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mprojected_context_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bfnd,ndh->bfh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mprojected_context_layer_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojected_context_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mlayernormed_context_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprojected_context_layer_dropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayernormed_context_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_probs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_attentions\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayernormed_context_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 15.90 GiB total capacity; 15.14 GiB already allocated; 11.81 MiB free; 15.19 GiB reserved in total by PyTorch)"]}]},{"cell_type":"code","metadata":{"id":"rZew7826YCi3","colab":{"base_uri":"https://localhost:8080/","height":781},"outputId":"c2a72ba1-d41e-4678-fc60-c66c13b89bb8"},"source":["torch.set_default_tensor_type('torch.cuda.FloatTensor')\n","new_model = SQUADBERT({\"d1\": 10, 'l1' : 10, 'd2' : 10, 'l2' : 10}, batch_size = 32, weight = 20.)\n","#new_model = SQUADBERT.load_from_checkpoint(base_dir + 'saved_models/new')\n","checkpoint = torch.load(base_dir + 'saved_models/new', map_location=lambda storage, loc: storage)\n","new_model.load_state_dict(checkpoint['state_dict'])\n","new_model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train, validation, test --  114245 1166 1166\n","NEW\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SQUADBERT(\n","  (bert): AlbertModel(\n","    (embeddings): AlbertEmbeddings(\n","      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): AlbertTransformer(\n","      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n","      (albert_layer_groups): ModuleList(\n","        (0): AlbertLayerGroup(\n","          (albert_layers): ModuleList(\n","            (0): AlbertLayer(\n","              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (attention): AlbertAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              )\n","              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n","              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (pooler): Linear(in_features=768, out_features=768, bias=True)\n","    (pooler_activation): Tanh()\n","  )\n","  (A1): Linear(in_features=768, out_features=100, bias=True)\n","  (B1): Linear(in_features=768, out_features=100, bias=True)\n","  (LG1): Linear(in_features=10, out_features=2, bias=True)\n","  (A2): Linear(in_features=768, out_features=100, bias=True)\n","  (B2): Linear(in_features=768, out_features=100, bias=True)\n","  (LG2): Linear(in_features=10, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"PXiE35_AlMrg"},"source":["def predicte(model, batch):\n","  input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","  #input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = input_ids.cpu(), attention_mask.cpu(), token_type_ids.cpu(), label.cpu(), answer_mask.cpu(), indexing.cpu()\n","  return model(input_ids, attention_mask, token_type_ids)\n","\n","def convert_predictions(l1, l2, label, answer_mask):\n","  a, y1 = torch.max(l1, dim=1)\n","  a, y2 = torch.max(l2, dim=2)\n","  guess1, guess2 = final_guess(l1, l2)\n","  \"\"\"if self.counter < 10:\n","    self.counter += 1\n","    self.dic_1[self.counter] = [l2, y2]\"\"\"\n","  d_pre = results_dic(y1, y2, label, answer_mask)\n","  d_post = results_dic(guess1, guess2, label, answer_mask)\n","  return y1, y2, guess1, guess2, d_pre, d_post"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGMkfO5TZux6"},"source":["test = torch.tensor(input_ids[153:155], dtype=torch.long).cuda(), torch.tensor(attention_mask[153:155], dtype=torch.long).cuda(), torch.tensor(token_type_ids[153:155], dtype=torch.long).cuda()\n","#                               1 - torch.tensor(labels, dtype=torch.long).cuda(), #label is 0 if there is an answer in the original dataset\n","#                                torch.tensor(answer_mask, dtype=torch.long).cuda(),\n","#                                torch.tensor(indexing, dtype=torch.long).cuda())\n","test_input_ids, test_attention_mask, test_token_type_ids = test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MzZlA05zab7s"},"source":["l1, l2 = bert_finetuner(test_input_ids, test_attention_mask, test_token_type_ids)\n","#v1, v2 = bert_finetuner(test_input_ids, test_attention_mask, test_token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z2GcGa67YCq1"},"source":["\"\"\"model = SQUADBERT('ProjectionModuleLong', {\"d1\": 8, 'l1' : 20, 'd2' : 8, 'l2' : 40}, batch_size = 32, weight = 60.)\n","checkpoint = torch.load(base_dir + \"/Checkpoints/_ckpt_epoch_2.ckpt\", map_location=lambda storage, loc: storage)\n","model.load_state_dict(checkpoint['state_dict'])\"\"\"\n","ll1, ll2 = new_model(test_input_ids, test_attention_mask, test_token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_7x4aQIxczUE","colab":{"base_uri":"https://localhost:8080/","height":283},"outputId":"135c322a-edfd-442a-fad6-62736fc6fe87"},"source":["l2-ll2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0., 0.],\n","         [0., 0.],\n","         [0., 0.],\n","         ...,\n","         [0., 0.],\n","         [0., 0.],\n","         [0., 0.]],\n","\n","        [[0., 0.],\n","         [0., 0.],\n","         [0., 0.],\n","         ...,\n","         [0., 0.],\n","         [0., 0.],\n","         [0., 0.]]], grad_fn=<SubBackward0>)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"kojxrYbPdO7f"},"source":["l1, _, l2 = bert_finetuner.bert(input_ids=test_input_ids, \n","                         attention_mask=test_attention_mask, \n","                         token_type_ids=test_token_type_ids)\n","ll1, _, ll2 = new_model.bert(input_ids=test_input_ids, \n","                         attention_mask=test_attention_mask, \n","                         token_type_ids=test_token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v10uVLUDn4e5"},"source":["lll1, _, lll2 = berty.cuda()(input_ids=test_input_ids, \n","                         attention_mask=test_attention_mask, \n","                         token_type_ids=test_token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oXZTvY3is0GN"},"source":["berty = AlbertModel.from_pretrained('albert-base-v1', output_attentions=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICb2xAhYs-ep"},"source":["berty = berty.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ve5EFiTp2saa","colab":{"base_uri":"https://localhost:8080/","height":692},"outputId":"3cc4576d-215e-4bd4-cb52-196a27d7c5db"},"source":["print(\"Model's state_dict:\")\n","for param_tensor in bert_finetuner.state_dict():\n","    print(param_tensor, \"\\t\", bert_finetuner.state_dict()[param_tensor].size())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model's state_dict:\n","bert.embeddings.word_embeddings.weight \t torch.Size([30000, 128])\n","bert.embeddings.position_embeddings.weight \t torch.Size([512, 128])\n","bert.embeddings.token_type_embeddings.weight \t torch.Size([2, 128])\n","bert.embeddings.LayerNorm.weight \t torch.Size([128])\n","bert.embeddings.LayerNorm.bias \t torch.Size([128])\n","bert.encoder.embedding_hidden_mapping_in.weight \t torch.Size([768, 128])\n","bert.encoder.embedding_hidden_mapping_in.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight \t torch.Size([3072, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias \t torch.Size([3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight \t torch.Size([768, 3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias \t torch.Size([768])\n","bert.pooler.weight \t torch.Size([768, 768])\n","bert.pooler.bias \t torch.Size([768])\n","A1.weight \t torch.Size([100, 768])\n","A1.bias \t torch.Size([100])\n","B1.weight \t torch.Size([100, 768])\n","B1.bias \t torch.Size([100])\n","LG1.weight \t torch.Size([2, 10])\n","LG1.bias \t torch.Size([2])\n","A2.weight \t torch.Size([100, 768])\n","A2.bias \t torch.Size([100])\n","B2.weight \t torch.Size([100, 768])\n","B2.bias \t torch.Size([100])\n","LG2.weight \t torch.Size([2, 10])\n","LG2.bias \t torch.Size([2])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WVc-MsFieptn","colab":{"base_uri":"https://localhost:8080/","height":478},"outputId":"6f3c7fb0-7462-4a46-f6f6-f5e0d6a19dfe"},"source":["print(\"Model's state_dict:\")\n","for param_tensor in bert_finetuner.state_dict():\n","    print(param_tensor, \"\\t\", bert_finetuner.state_dict()[param_tensor].size())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model's state_dict:\n","bert.embeddings.word_embeddings.weight \t torch.Size([30000, 128])\n","bert.embeddings.position_embeddings.weight \t torch.Size([512, 128])\n","bert.embeddings.token_type_embeddings.weight \t torch.Size([2, 128])\n","bert.embeddings.LayerNorm.weight \t torch.Size([128])\n","bert.embeddings.LayerNorm.bias \t torch.Size([128])\n","bert.encoder.embedding_hidden_mapping_in.weight \t torch.Size([768, 128])\n","bert.encoder.embedding_hidden_mapping_in.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight \t torch.Size([3072, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias \t torch.Size([3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight \t torch.Size([768, 3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias \t torch.Size([768])\n","bert.pooler.weight \t torch.Size([768, 768])\n","bert.pooler.bias \t torch.Size([768])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mUD0IG1xftWz","colab":{"base_uri":"https://localhost:8080/","height":478},"outputId":"3de4effe-1893-4312-87cc-485b0d520833"},"source":["print(\"Model's state_dict:\")\n","for param_tensor in new_model.state_dict():\n","    print(param_tensor, \"\\t\", new_model.state_dict()[param_tensor].size())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model's state_dict:\n","bert.embeddings.word_embeddings.weight \t torch.Size([30000, 128])\n","bert.embeddings.position_embeddings.weight \t torch.Size([512, 128])\n","bert.embeddings.token_type_embeddings.weight \t torch.Size([2, 128])\n","bert.embeddings.LayerNorm.weight \t torch.Size([128])\n","bert.embeddings.LayerNorm.bias \t torch.Size([128])\n","bert.encoder.embedding_hidden_mapping_in.weight \t torch.Size([768, 128])\n","bert.encoder.embedding_hidden_mapping_in.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight \t torch.Size([3072, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias \t torch.Size([3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight \t torch.Size([768, 3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias \t torch.Size([768])\n","bert.pooler.weight \t torch.Size([768, 768])\n","bert.pooler.bias \t torch.Size([768])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zGez9s2PuF3F"},"source":["input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Du2ImLt5uGAb"},"source":["q, _, _ = new_model.bert(input_ids=input_ids, \n","                         attention_mask=attention_mask, \n","                         token_type_ids=token_type_ids)\n","\n","qq, _, _ = berty(input_ids=input_ids, \n","                         attention_mask=attention_mask, \n","                         token_type_ids=token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kX39hwn6yDUc","colab":{"base_uri":"https://localhost:8080/","height":167},"outputId":"71477994-4954-4cf6-8042-ec33200a708b"},"source":[""],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-b862d2305077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_finetuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: summarize() missing 1 required positional argument: 'mode'"]}]},{"cell_type":"code","metadata":{"id":"CQ2Bw7FhYCyx"},"source":["import pickle\n","with open(base_dir + r\"l1l2\", \"wb\") as f:\n","    pickle.dump([l1, l2], f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xh4le09AYC6I"},"source":["with open(base_dir + r\"l1l2\", \"rb\") as f:\n","    [l1, l2] = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DthsMjZrYDCF"},"source":["with open(base_dir + r\"batch\", \"wb\") as f:\n","    pickle.dump(batch, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LzxZpx_fYDJo"},"source":["with open(base_dir + r\"batch\", \"rb\") as f:\n","    batch = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHjVXlyDgo9Z","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"76574056-8238-40f6-dabb-a5bb7a4165c2"},"source":["for i in range(len(batch)):\n","  print((batch[i] - batchh[i]).sum())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(0)\n","tensor(0)\n","tensor(0)\n","tensor(0)\n","tensor(0)\n","tensor(0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ie9HtHcwg_6u","colab":{"base_uri":"https://localhost:8080/","height":585},"outputId":"10a8f18a-4bf6-46d4-bcb6-13fb9b4e4747"},"source":["l1 - ll1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.3311, -1.1707],\n","        [-1.1836,  0.5233],\n","        [-0.3844, -0.3816],\n","        [-0.8956, -0.1006],\n","        [ 0.0560, -0.4223],\n","        [ 0.1867, -0.2628],\n","        [ 1.3606, -1.6090],\n","        [-1.6539,  0.3736],\n","        [-0.6360,  0.2532],\n","        [ 0.4264, -0.8577],\n","        [-1.4590,  0.6360],\n","        [ 0.0429, -0.3946],\n","        [-1.3437,  0.4152],\n","        [-1.2637,  0.2589],\n","        [-0.6773, -0.2426],\n","        [-0.4709,  0.0996],\n","        [ 0.6763, -0.9663],\n","        [ 0.6074, -0.9704],\n","        [ 1.3427, -0.6838],\n","        [-0.4018, -0.3278],\n","        [-0.7176,  0.1280],\n","        [-0.6025, -0.2789],\n","        [-1.1873,  0.7783],\n","        [-0.4975, -0.0069],\n","        [-1.1089, -0.0882],\n","        [-1.2815,  0.2321],\n","        [-0.0177, -0.4595],\n","        [-1.4720,  0.4155],\n","        [ 0.4455, -0.4733],\n","        [-0.6149, -0.2658],\n","        [-1.4690,  0.5316],\n","        [ 0.2757, -0.8703]], grad_fn=<SubBackward0>)"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"tyEp0rWqRTY7","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"f3f70f51-e687-4485-9e39-21d4f37990da"},"source":["'''\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","\n","# DEFAULTS used by the Trainer\n","checkpoint_callback = ModelCheckpoint(\n","    filepath='./saved_models',\n","    save_best_only=True,\n","    verbose=True,\n","    monitor='val_loss',\n","    mode='min',\n","    prefix=''\n",")\n","\n","#trainer = Trainer(checkpoint_callback=checkpoint_callback)\n","'''\n","#!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nfrom pytorch_lightning.callbacks import ModelCheckpoint\\n\\n# DEFAULTS used by the Trainer\\ncheckpoint_callback = ModelCheckpoint(\\n    filepath='./saved_models',\\n    save_best_only=True,\\n    verbose=True,\\n    monitor='val_loss',\\n    mode='min',\\n    prefix=''\\n)\\n\\n#trainer = Trainer(checkpoint_callback=checkpoint_callback)\\n\""]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"E6kuinpEU17b"},"source":["#!pip install apex\n","#import apex"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0UT3mRNoot1"},"source":["#import apex"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NZ1X94Lw-5pB"},"source":["## Summary\n","\n","That's it! Checkout [PyTorch Lightning](https://github.com/williamFalcon/pytorch-lightning/) which works with any machine learning approach that uses PyTorch."]},{"cell_type":"code","metadata":{"id":"4ARIT37rDdIZ"},"source":["from pprint import pprint as pp\n","pp(bert_finetuner.dic_1[1][1].cpu().numpy()[:5,:20])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pytSP8OxOrr1"},"source":["print(bert)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GHbKj70yOs3D"},"source":["bert_finetuner.dic_1[1][1].shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YfZpDAhMUwQO"},"source":["type(torch.Tensor(answer_mask).type(torch.cuda.FloatTensor))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_VPqM8BRa72r"},"source":["#dict_data = {\"input_ids\": input_ids, \"token_type_ids\": token_type_ids, \"labels\": labels, \"attention_mask\": attention_mask}\n","with open(base_dir + r\"albert256_tensor3model20.pickle\", \"wb\") as f:\n","    pickle.dump(bert_finetuner, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_1wxNwtIb64P"},"source":["torch.save(bert_finetuner, (base_dir + r\"albert256_tensor3model20\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gk9iV6KFdYxP"},"source":["trainer.default_save_path = base_dir + r'albert_model256'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HN-zi80lecp0"},"source":["try:\n","    from apex import amp\n","\n","    APEX_AVAILABLE = True\n","except ImportError:\n","    APEX_AVAILABLE = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a75UtTTYVC8G"},"source":["APEX_AVAILABLE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_YqJZx5VEY6"},"source":["a = torch.Tensor([[1,2,3],[4,5,6]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4goV0SYr8qqV"},"source":["torch.reshape(a,(2,2,2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rMJ4fE3N8ub-"},"source":["a.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q_Jhdys19Hwp"},"source":["torch.cat([a]*5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gtcok93D9gvq"},"source":["a = torch.Tensor([[1,0,1],[0,1,0]])\n","print(a.shape)\n","b = torch.Tensor([[1,0,0], [1, 0, 0]])\n","print(a*b)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p0P2I2KMT6jy"},"source":["print(torch.mul(a, b))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AmSXS5hqUQF5"},"source":["print((a==b).type(torch.cuda.FloatTensor).mean())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IG3Xpnc9Uatc"},"source":[""],"execution_count":null,"outputs":[]}]}