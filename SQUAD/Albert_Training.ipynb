{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Albert_Training.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"56ec0329def54aed8564d9650c25fa9a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c0602044a1194cb0a0dffc391014526d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4e60f7f1522145e496ed5550c38709fb","IPY_MODEL_8017997494394e6f990e69668daffcc8"]}},"c0602044a1194cb0a0dffc391014526d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"4e60f7f1522145e496ed5550c38709fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_57bc30bfa5a64e81912230807da88a7c","_dom_classes":[],"description":"Validation sanity check: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a6a04cd1ee6d48a29f465478c7dea4ad"}},"8017997494394e6f990e69668daffcc8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a84df3917367417c9ecdacafe6aa34c3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2/2 [00:00&lt;00:00, 20.37it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_358d52f85cbd4448894b2f440920baea"}},"57bc30bfa5a64e81912230807da88a7c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a6a04cd1ee6d48a29f465478c7dea4ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a84df3917367417c9ecdacafe6aa34c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"358d52f85cbd4448894b2f440920baea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"49e245763a3b436aa3dc261d0c3a8f0d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0792195b7540466db6f57ccadc54535c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_da40cf700a244207b982d0d75d0a41be","IPY_MODEL_006b0d0c625e43b89fb562950113d5c0"]}},"0792195b7540466db6f57ccadc54535c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"da40cf700a244207b982d0d75d0a41be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fa5e7780b16f48a78a4335e49c9561e3","_dom_classes":[],"description":"Epoch 1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":3644,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3644,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8164c34f1395440f8922f6aab4746113"}},"006b0d0c625e43b89fb562950113d5c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b388a8d7899c4a8994fb79f7f07911ff","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3644/3644 [47:37&lt;00:00,  1.28it/s, loss=1.167, v_num=2, start_acc=0.704, end_acc=0.789]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_84170a7996b9405d8fcb1bdc95e7d4b6"}},"fa5e7780b16f48a78a4335e49c9561e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8164c34f1395440f8922f6aab4746113":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b388a8d7899c4a8994fb79f7f07911ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"84170a7996b9405d8fcb1bdc95e7d4b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"29dae6f9bf0a43fcbf472a4d4d61904d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_46624de722ba42019b824405a6f9e863","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fb06e198a7c84a6d83765f626652e49e","IPY_MODEL_680a6de4fedb4fd48b37a78e29179054"]}},"46624de722ba42019b824405a6f9e863":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"fb06e198a7c84a6d83765f626652e49e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ffda25e9ca34410f9ab29822d38f5c34","_dom_classes":[],"description":"Validating: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c8814cf000fc4495ae86b3be4a56d9fe"}},"680a6de4fedb4fd48b37a78e29179054":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c824df342e3b47b6bdb2917775415bb8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 166/166 [00:48&lt;00:00,  3.42it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ccafac9141884335ae920cd9096f9b18"}},"ffda25e9ca34410f9ab29822d38f5c34":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c8814cf000fc4495ae86b3be4a56d9fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c824df342e3b47b6bdb2917775415bb8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ccafac9141884335ae920cd9096f9b18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d09e2bc982c4547b1298ae41c27f048":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a1f9dbff37d84942a617ab6c227049cb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_af2c9073661d4c749d955577bffe93b5","IPY_MODEL_4e31999b0b44400d9dbcf1c1ef257b18"]}},"a1f9dbff37d84942a617ab6c227049cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"af2c9073661d4c749d955577bffe93b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f0ff7fa85bda4726a8dbffa563e43c4a","_dom_classes":[],"description":"Validating: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ff6aa16aa79740ada5bf7dbd10a794a7"}},"4e31999b0b44400d9dbcf1c1ef257b18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_78d41ec4ea8444f7991484daa1baba7e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 166/166 [00:48&lt;00:00,  3.42it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_87f275b3fddd4fe3a68844c2c268e6d3"}},"f0ff7fa85bda4726a8dbffa563e43c4a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ff6aa16aa79740ada5bf7dbd10a794a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78d41ec4ea8444f7991484daa1baba7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"87f275b3fddd4fe3a68844c2c268e6d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"GatZ6ZiXFzVh"},"source":["![image.png](data:image/png;base64,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)"]},{"cell_type":"markdown","metadata":{"id":"goRmGIRI5cfC"},"source":["# ALBERT for Question Answering\n","\n","We are using a tensor model on top of ALBERT for the SQUAD 2.0 dataset\n"]},{"cell_type":"markdown","metadata":{"id":"jKj5lgdr5j48"},"source":["## Setup  \n","First, let's check the GPU we got. If memory < 11GB, I'd suggest to do factory reset runtime. Ideally, try to get 16GB"]},{"cell_type":"code","metadata":{"id":"iesFMrWGTx3Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606638408503,"user_tz":-180,"elapsed":1873,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"0ad2d51e-2a1c-4c2d-acd7-4baf4602f4ec"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Sun Nov 29 08:26:47 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yhf9UjQ3okV8"},"source":["Installing all necessary libraries -- Pytorch Lightning, transformers and tensorflow"]},{"cell_type":"code","metadata":{"id":"UGjilEHk4vb7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606638431110,"user_tz":-180,"elapsed":18179,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"24d14402-7741-49f8-ab00-de17bec0a8fc"},"source":["%tensorflow_version 1.x\n","!pip install -q pytorch-lightning\n","!pip install -q transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","\u001b[K     |████████████████████████████████| 563kB 5.8MB/s \n","\u001b[K     |████████████████████████████████| 92kB 9.8MB/s \n","\u001b[K     |████████████████████████████████| 10.6MB 18.0MB/s \n","\u001b[K     |████████████████████████████████| 276kB 56.8MB/s \n","\u001b[K     |████████████████████████████████| 829kB 53.1MB/s \n","\u001b[?25h  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: tensorflow 1.15.2 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 1.15.2 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.4.0 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 1.3MB 4.3MB/s \n","\u001b[K     |████████████████████████████████| 890kB 16.7MB/s \n","\u001b[K     |████████████████████████████████| 2.9MB 16.9MB/s \n","\u001b[K     |████████████████████████████████| 1.1MB 41.9MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"X5omrSOMpRDK"},"source":["Some more importing"]},{"cell_type":"code","metadata":{"id":"orKOA-dmpU1j","executionInfo":{"status":"ok","timestamp":1606643475357,"user_tz":-180,"elapsed":3102,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["import os\n","import pickle, json\n","import torch\n","import numpy as np\n","from tqdm import tqdm, trange\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler, DataLoader, random_split\n","import pytorch_lightning as pl\n","from transformers import AlbertModel, AlbertTokenizer"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S8NuAKW9o7hj"},"source":["## Data download \n","\n","Mount the drive to get access to reading and writing files"]},{"cell_type":"code","metadata":{"id":"C5WA386uEpS8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606643494528,"user_tz":-180,"elapsed":1129,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"760433f1-5255-430d-df30-344f980eb5fb"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","root_dir = \"/content/gdrive/My Drive/\"\n","base_dir = root_dir + 'ybshmmlchk/'"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yuUwBKpn-TIK"},"source":["#### Loading preprocessed data. For the preprocessing part -- see Albert_Preprocessing.ipynb\n"]},{"cell_type":"markdown","metadata":{"id":"c0E8SxTYvH2k"},"source":["Define your configuration -- bert model version and max_len"]},{"cell_type":"code","metadata":{"id":"fNHSSHxguiMP","executionInfo":{"status":"ok","timestamp":1606643501491,"user_tz":-180,"elapsed":933,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["conf = {\n","    'model': 'albert', ## options for now-- albert, bert\n","    'model_version' : 'base-v2',\n","    'max_len' : 256\n","}"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"YNlPCaDpuzia","executionInfo":{"status":"ok","timestamp":1606643534300,"user_tz":-180,"elapsed":1248,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["#returns tokenizer and model from configuration\n","def nlp_model_tokenizer(conf):\n","  if conf['model'] == 'albert':\n","    from transformers import AlbertTokenizer as your_tokenizer, AlbertModel as your_nlp_model\n","  elif conf['model'] == 'bert':\n","    from transformers import BertTokenizer as your_tokenizer, BertModel as your_nlp_model\n","  else:\n","    print('Please select a different model or rewrite the code for this function to add your model')\n","    return False\n","  try:\n","    return your_tokenizer.from_pretrained(conf['model'] + '-' + conf['model_version']), your_nlp_model.from_pretrained(conf['model'] + '-' + conf['model_version'])\n","  except:\n","    print('Wrong model version. Please select a valid one')\n","    return False\n","\n","tokenizer, bert = nlp_model_tokenizer(conf)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"7dowEmZrEbl_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606643554451,"user_tz":-180,"elapsed":8147,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"aad9a29b-8136-4409-8043-116621b81897"},"source":["# load train dataset\n","pickle_prefix = conf['model'] + '-' + conf['model_version'] + '-' + str(conf['max_len'])\n","try:\n","  with open(root_dir + 'ybshmmlchk/' + pickle_prefix + '-train.pickle', 'rb') as f:\n","      train_data = pickle.load(f)\n","except:\n","  print('Training data hasnt been processed with your choice of model yet. Please go to preprocessing notebook first and run it with your configuration')  \n","input_ids = train_data[\"input_ids\"]\n","token_type_ids = train_data[\"token_type_ids\"]\n","labels = train_data[\"labels\"]\n","attention_mask = train_data[\"attention_mask\"]\n","answer_mask = train_data['answer_mask']\n","plausible_answer_mask = train_data['plausible_answer_mask']\n","actual_answers = train_data['actual_answers']\n","plausible_answers = train_data['plausible_answers']\n","answer_starts = train_data['answer_starts']\n","answer_ends = train_data['answer_ends']\n","full_questions = train_data['full_questions']\n","full_paragraphs = train_data['full_paragraphs']\n","indexing = list(range(0, len(labels)))\n","print('Number of train input ids:'.ljust(30), len(input_ids))\n","# print('Number of train token type ids:'.ljust(30), len(token_type_ids))\n","# print('Number of train labels:'.ljust(30), len(labels))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Number of train input ids:     111281\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RaUsGJo-w0Tl","executionInfo":{"status":"ok","timestamp":1606643561971,"user_tz":-180,"elapsed":881,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"f7bb7280-8160-4d3a-8052-51a631906f50"},"source":["# load val dataset\n","pickle_prefix = conf['model'] + '-' + conf['model_version'] + '-' + str(conf['max_len'])\n","try:\n","  with open(root_dir + 'ybshmmlchk/' + pickle_prefix + '-val.pickle', 'rb') as f:\n","      val_data = pickle.load(f)\n","except:\n","  print('Training data hasnt been processed with your choice of model yet. Please go to preprocessing notebook first and run it with your configuration') \n","    \n","val_input_ids = val_data[\"input_ids\"]\n","val_token_type_ids = val_data[\"token_type_ids\"]\n","val_labels = val_data[\"labels\"]\n","val_attention_mask = val_data[\"attention_mask\"]\n","val_answer_mask = val_data['answer_mask']\n","val_plausible_answer_mask = val_data['plausible_answer_mask']\n","val_actual_answers = val_data['actual_answers']\n","val_plausible_answers = val_data['plausible_answers']\n","val_answer_starts = val_data['answer_starts']\n","val_answer_ends = val_data['answer_ends']\n","val_full_questions = val_data['full_questions']\n","val_full_paragraphs = val_data['full_paragraphs']\n","val_indexing = list(range(0, len(val_labels)))\n","print('Number of val input ids:'.ljust(30), len(val_input_ids))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Number of val input ids:       5296\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QoKj1WLzyLEU"},"source":["The fraction of unanswerable questions is about 33%, so about 66% have an answer. The average number of tokens that are in the answer is about 1%. Since the length of our \"sentences\" is 256, the average length of answers is about 3 tokens."]},{"cell_type":"code","metadata":{"id":"P7CfHp4Kyu6k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606604760071,"user_tz":-180,"elapsed":3185,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"f8e403b1-f1c1-4fa2-c13d-782b9f1b1187"},"source":["print('Fraction of unaswerable questions:', np.mean(labels))\n","print('Average fraction of answer tokens in paragraph:',np.array([np.array(x).mean() for x in answer_mask]).mean())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fraction of unaswerable questions: 0.3361939594360223\n","Average fraction of answer tokens in paragraph: 0.011225874700083573\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_gfRvBMctUCD"},"source":["Here is an example of an entry in the dataset. Note that label is is_unanswerable, so True means there is no answer."]},{"cell_type":"code","metadata":{"id":"k8CHPkGNpt5u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606487374027,"user_tz":-180,"elapsed":712,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"a1e624c3-1947-4c86-d387-5b02e0f73897"},"source":["i = 153\n","print('Input id:', i)\n","print('Question:', full_questions[i])\n","print('Paragraph:', full_paragraphs[i])\n","print('Answer:', actual_answers[i])\n","print('Plausible answer (if answer doesnt exist):', plausible_answers[i])\n","print('Label:', labels[i]) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input id: 153\n","Question: What did the UN Peacebuliding Commission decide on Jan 8, 2008?\n","Paragraph: In 2006, due to ongoing violence, over 50,000 people in the country's northwest were at risk of starvation but this was averted due to assistance from the United Nations.[citation needed] On 8 January 2008, the UN Secretary-General Ban Ki-Moon declared that the Central African Republic was eligible to receive assistance from the Peacebuilding Fund. Three priority areas were identified: first, the reform of the security sector; second, the promotion of good governance and the rule of law; and third, the revitalization of communities affected by conflicts. On 12 June 2008, the Central African Republic requested assistance from the UN Peacebuilding Commission, which was set up in 2005 to help countries emerging from conflict avoid devolving back into war or chaos.\n","Answer: no answer\n","Plausible answer (if answer doesnt exist): the Central African Republic was eligible to receive assistance from the Peacebuilding Fund\n","Label: True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3F1sf5r59l6e"},"source":["Now we define a function which will return train and validation dataloaders. The breakdown is 95-5."]},{"cell_type":"code","metadata":{"id":"kMdQZUjO-MI7","executionInfo":{"status":"ok","timestamp":1606643575531,"user_tz":-180,"elapsed":644,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["def generate_squad_dataloaders(batch_size):\n","  # ----------------------\n","  # TRAIN/VAL/TEST DATALOADERS\n","  # ----------------------\n","\n","  # TensorDataset from training examples. \".cuda()\" puts the corresponding tensor on gpu\n","  squad_train_dataset = TensorDataset(torch.tensor(input_ids, dtype=torch.long).cuda(),\n","                                torch.tensor(attention_mask, dtype=torch.long).cuda(),  \n","                                torch.tensor(token_type_ids, dtype=torch.long).cuda(), \n","                                1 - torch.tensor(labels, dtype=torch.long).cuda(), #label is 0 if there is an answer in the original dataset\n","                                torch.tensor(answer_mask, dtype=torch.long).cuda(),\n","                                torch.tensor(indexing, dtype=torch.long).cuda(),\n","                                torch.tensor(answer_starts).cuda(),\n","                                torch.tensor(answer_ends).cuda())\n","  \n","  squad_val_dataset = TensorDataset(torch.tensor(val_input_ids, dtype=torch.long).cuda(),\n","                                torch.tensor(val_attention_mask, dtype=torch.long).cuda(),  \n","                                torch.tensor(val_token_type_ids, dtype=torch.long).cuda(), \n","                                1 - torch.tensor(val_labels, dtype=torch.long).cuda(), #label is 0 if there is an answer in the original dataset\n","                                torch.tensor(val_answer_mask, dtype=torch.long).cuda(),\n","                                torch.tensor(val_indexing, dtype=torch.long).cuda(),\n","                                torch.tensor(val_answer_starts).cuda(),\n","                                torch.tensor(val_answer_ends).cuda())\n","  \n","  # test is not actually used yet\n","  \"\"\"squad_test_dataset = TensorDataset(torch.tensor(input_ids[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(),\n","                                torch.tensor(attention_mask[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(),  \n","                                torch.tensor(token_type_ids[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(), \n","                                1 - torch.tensor(labels[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(), #label is 0 if there is an answer in the original dataset\n","                                torch.tensor(answer_mask[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(),\n","                                torch.tensor(indexing[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda())\"\"\"\n","\n","  print('Train set size:', len(labels))\n","  print('Validation set size:', len(val_labels))\n","\n","  # train loader\n","  train_sampler = RandomSampler(squad_train_dataset)\n","  squad_train_dataloader = DataLoader(squad_train_dataset, sampler = train_sampler, batch_size = batch_size)\n","\n","  # val loader\n","  val_sampler = SequentialSampler(squad_val_dataset)\n","  squad_val_dataloader = DataLoader(squad_val_dataset, sampler = val_sampler, batch_size = batch_size, shuffle = False)\n","\n","  # test loader\n","  #test_sampler = RandomSampler(squad_test_dataset)\n","  #squad_test_dataloader = DataLoader(squad_test_dataset, sampler=test_sampler, batch_size = batch_size)\n"," \n","  return squad_train_dataloader, squad_val_dataloader#, squad_test_dataloader"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mvqBwNVaZzh2"},"source":["Defining the model from BERT paper with start and end vector"]},{"cell_type":"code","metadata":{"id":"gYY21m6tgCEr","executionInfo":{"status":"ok","timestamp":1606643585766,"user_tz":-180,"elapsed":645,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["class SQUADBERT(pl.LightningModule):\n","\n","    def __init__(self, batch_size):\n","        super(SQUADBERT, self).__init__()\n","        # initializing BERT, parameters, dataloaders\n","        self.bert = bert.cuda()\n","        self.n = bert.config.hidden_size\n","        self.max_len = 256\n","        self.batch_size = batch_size\n","        self.squad_train_dataloader, self.squad_val_dataloader = generate_squad_dataloaders(self.batch_size)\n","        # initializing additional layers -- start and end vectors\n","        self.Start = nn.Linear(self.n, 1)\n","        self.End = nn.Linear(self.n, 1)\n","\n","    def new_layers(self, q, new_layer):\n","        logits_wrong_shape = new_layer(torch.reshape(q, (q.shape[0]*q.shape[1], q.shape[2])))\n","        logits = torch.reshape(logits_wrong_shape, (q.shape[0], q.shape[1]))\n","        return logits\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        #apply BERT\n","        q, _ = self.bert(input_ids=input_ids, \n","                         attention_mask=attention_mask, \n","                         token_type_ids=token_type_ids)\n","        # shape of q will be (batch_size, max_len, bert_dim) = (batch_size, 256, 768)\n","        # take inner products of output vectors with trainable start and end vectors\n","        start_logits = self.new_layers(q, self.Start)\n","        end_logits = self.new_layers(q, self.End)\n","\n","        return start_logits, end_logits\n","\n","    # this is the main function of pl modules. defines architecture and loss function. training loop comes for free -- implemented inside PL\n","    def training_step(self, batch, batch_nb):\n","        # batch\n","        input_ids, attention_mask, token_type_ids, label, answer_mask, indexing, answer_starts, answer_ends = batch\n","         \n","        # fwd\n","        start_logits, end_logits = self.forward(input_ids, attention_mask, token_type_ids)\n","        \n","        # LOSS\n","        # get start and end positions from answer_mask\n","        start, end = answer_starts, answer_ends#get_start_end(answer_mask)\n","\n","        # compute cross_entropy loss between predictions and actual labels for start and end \n","        loss1 = F.cross_entropy(start_logits, start)\n","        loss2 = F.cross_entropy(end_logits, end)\n","        loss = loss1 + loss2\n","\n","        self.log('loss', loss, prog_bar=True)\n","        # logs\n","        tensorboard_logs = {'train_loss': loss}\n","        return {'loss': loss, 'log': tensorboard_logs}\n","\n","    def validation_step(self, batch, batch_nb):\n","        # batch\n","        input_ids, attention_mask, token_type_ids, label, answer_mask, indexing, answer_starts, answer_ends = batch\n","\n","        # fwd\n","        start_logits, end_logits = self.forward(input_ids, attention_mask, token_type_ids)\n","\n","        # loss\n","        start, end = answer_starts, answer_ends#get_start_end(answer_mask)\n","\n","        loss1 = F.cross_entropy(start_logits, start)\n","        loss2 = F.cross_entropy(end_logits, end)\n","        loss = loss1 + loss2\n","\n","        # ^^^^ the code above is the same as for training step, but we also add accuracy computation for validation below\n","\n","        # acc\n","        a, y1 = torch.max(start_logits, dim=1)\n","        a, y2 = torch.max(end_logits, dim=1)\n","        \n","        start_acc = torch.sum(y1 == start) / self.batch_size\n","        end_acc = torch.sum(y2 == end) / self.batch_size\n","        self.log('start_acc', start_acc, prog_bar=True)\n","        self.log('end_acc', end_acc, prog_bar=True)\n","        return {'val_loss' : loss, 'start_acc' : start_acc, 'end_acc' : end_acc}\n","\n","    def validation_end(self, outputs):\n","        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n","        start_acc = torch.stack([x['start_acc'] for x in outputs]).mean()\n","        end_acc = torch.stack([x['end_acc'] for x in outputs]).mean()\n","\n","        self.log('validation_loss', avg_loss, prog_bar=True)\n","        self.log('start_accuracy', start_acc, prog_bar=True)\n","        self.log('end_accuracy', end_acc, prog_bar=True)\n","        tensorboard_logs = {'val_loss': avg_loss, 'start_acc' : start_acc, 'end_acc' : end_acc}\n","        return {'avg_val_loss': avg_loss, 'progress_bar': tensorboard_logs}\n","    \n","    def configure_optimizers(self):\n","        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=3e-05, eps=1e-08)\n","\n","    def train_dataloader(self):\n","        return self.squad_train_dataloader\n","\n","    def val_dataloader(self):\n","        return self.squad_val_dataloader\n"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FHt8tgwa_DcM"},"source":["### Trainer\n","The trainer takes care of putting things in the correct GPU or not.\n","It handles all the engineering for you (such as automatic early stopping) so you just have to worry about the model and data!"]},{"cell_type":"code","metadata":{"id":"gMRMJ-Kd-oup","colab":{"base_uri":"https://localhost:8080/","height":562,"referenced_widgets":["56ec0329def54aed8564d9650c25fa9a","c0602044a1194cb0a0dffc391014526d","4e60f7f1522145e496ed5550c38709fb","8017997494394e6f990e69668daffcc8","57bc30bfa5a64e81912230807da88a7c","a6a04cd1ee6d48a29f465478c7dea4ad","a84df3917367417c9ecdacafe6aa34c3","358d52f85cbd4448894b2f440920baea","49e245763a3b436aa3dc261d0c3a8f0d","0792195b7540466db6f57ccadc54535c","da40cf700a244207b982d0d75d0a41be","006b0d0c625e43b89fb562950113d5c0","fa5e7780b16f48a78a4335e49c9561e3","8164c34f1395440f8922f6aab4746113","b388a8d7899c4a8994fb79f7f07911ff","84170a7996b9405d8fcb1bdc95e7d4b6","29dae6f9bf0a43fcbf472a4d4d61904d","46624de722ba42019b824405a6f9e863","fb06e198a7c84a6d83765f626652e49e","680a6de4fedb4fd48b37a78e29179054","ffda25e9ca34410f9ab29822d38f5c34","c8814cf000fc4495ae86b3be4a56d9fe","c824df342e3b47b6bdb2917775415bb8","ccafac9141884335ae920cd9096f9b18","0d09e2bc982c4547b1298ae41c27f048","a1f9dbff37d84942a617ab6c227049cb","af2c9073661d4c749d955577bffe93b5","4e31999b0b44400d9dbcf1c1ef257b18","f0ff7fa85bda4726a8dbffa563e43c4a","ff6aa16aa79740ada5bf7dbd10a794a7","78d41ec4ea8444f7991484daa1baba7e","87f275b3fddd4fe3a68844c2c268e6d3"]},"executionInfo":{"status":"ok","timestamp":1606495132615,"user_tz":-180,"elapsed":5722195,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"eeab8dd5-8c3c-4899-d85d-0d3898318437"},"source":["torch.set_default_tensor_type('torch.cuda.FloatTensor')\n","model = SQUADBERT(32)\n","# most basic trainer, uses good defaults (1 gpu)\n","trainer = pl.Trainer(gpus=1, amp_level='O2',precision=16, max_epochs = 2)#, val_check_interval=0.25)#checkpoint_callback=checkpoint_callback, max_nb_epochs = 2val_check_interval=1,)    \n","trainer.fit(model) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n","  warnings.warn(*args, **kwargs)\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Using native 16bit precision.\n","\n","  | Name  | Type        | Params\n","--------------------------------------\n","0 | bert  | AlbertModel | 11.7 M\n","1 | Start | Linear      | 769   \n","2 | End   | Linear      | 769   \n"],"name":"stderr"},{"output_type":"stream","text":["Train set size: 111281\n","Validation set size: 5296\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for validation and test dataloaders.\n","  warnings.warn(*args, **kwargs)\n","/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  warnings.warn(*args, **kwargs)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56ec0329def54aed8564d9650c25fa9a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  warnings.warn(*args, **kwargs)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49e245763a3b436aa3dc261d0c3a8f0d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n","Please use self.log(...) inside the lightningModule instead.\n","\n","# log on a step or aggregate epoch metric to the logger and/or progress bar\n","# (inside LightningModule)\n","self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n","  warnings.warn(*args, **kwargs)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29dae6f9bf0a43fcbf472a4d4d61904d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d09e2bc982c4547b1298ae41c27f048","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"t8XvjuyPWmAv"},"source":["**Saving**"]},{"cell_type":"code","metadata":{"id":"aFKxVdIyWut9"},"source":["model_name = '2epochs_base_albert'\n","trainer.save_checkpoint(base_dir + 'saved_models/' + model_name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v-oJLdeFW2f6"},"source":["**Loading**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ZeKyNlkW7dm","executionInfo":{"status":"ok","timestamp":1606643614550,"user_tz":-180,"elapsed":6587,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"67d597b3-1bb0-4211-e57a-caf114fa330f"},"source":["torch.set_default_tensor_type('torch.cuda.FloatTensor')\n","model = SQUADBERT(16)\n","model_name = '2epochs_base_albert'\n","checkpoint = torch.load(base_dir + 'saved_models/' + model_name, map_location=lambda storage, loc: storage)\n","model.load_state_dict(checkpoint['state_dict'])\n","model.eval()"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Train set size: 111281\n","Validation set size: 5296\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SQUADBERT(\n","  (bert): AlbertModel(\n","    (embeddings): AlbertEmbeddings(\n","      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0, inplace=False)\n","    )\n","    (encoder): AlbertTransformer(\n","      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n","      (albert_layer_groups): ModuleList(\n","        (0): AlbertLayerGroup(\n","          (albert_layers): ModuleList(\n","            (0): AlbertLayer(\n","              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (attention): AlbertAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (attention_dropout): Dropout(p=0, inplace=False)\n","                (output_dropout): Dropout(p=0, inplace=False)\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              )\n","              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n","              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n","              (dropout): Dropout(p=0, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (pooler): Linear(in_features=768, out_features=768, bias=True)\n","    (pooler_activation): Tanh()\n","  )\n","  (Start): Linear(in_features=768, out_features=1, bias=True)\n","  (End): Linear(in_features=768, out_features=1, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"s9A5HGrcX5kk"},"source":["**Results on validation/train**"]},{"cell_type":"markdown","metadata":{"id":"qrOCKwm8YIeA"},"source":["Helper functions"]},{"cell_type":"code","metadata":{"id":"2XPQPLHxYCeP","executionInfo":{"status":"ok","timestamp":1606645365422,"user_tz":-180,"elapsed":857,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["#returns \"probabilities\" of start and end. not actually probabilities, because this is before softmax\n","def predict(model, batch):\n","  input_ids, attention_mask, token_type_ids, label, answer_mask, indexing, answer_starts, answer_ends = batch\n","  with torch.no_grad():\n","    res = model(input_ids, attention_mask, token_type_ids)\n","  return res\n","\n","# returns start and end vectors, just based on argmax taken individually\n","def convert_predictions(l1, l2):#, label, answer_mask):\n","  a, y1 = torch.max(l1, dim=1)\n","  a, y2 = torch.max(l2, dim=1)\n","  \n","  return y1, y2#, guess1, guess2, d_pre, d_post\n","\n","# returns start and end vectors taking into account that end>=start + start can't be before question end\n","def convert_predictions_improved(l1, l2, min_start):\n","  starts, ends = [], []\n","  for i in range(l1.shape[0]):\n","    p1, p2 = l1[i], l2[i]\n","    highest_prob = p1[0] + p2[0]\n","    start, end = 0, 0\n","    for k in range(min_start[i], 256):\n","      for j in range(k, 256):\n","        if p1[k] + p2[j] > highest_prob:\n","          highest_prob, start, end = p1[k] + p2[j], k, j\n","    starts.append(start)\n","    ends.append(end)\n","  return torch.Tensor(starts), torch.Tensor(ends)\n","\n","def npf(tt):\n","  return tt.detach().cpu().numpy()\n","\n","def convert_predictions_improved_v3(start_batch, end_batch, min_start=None):\n","  start_batch, end_batch, min_start = npf(start_batch), npf(end_batch), npf(min_start)\n","  #start_batch, end_batch = npf(start_batch), npf(end_batch)\n","  batch_size, max_len = start_batch.shape\n","  probs = start_batch.reshape(-1,max_len,1) + end_batch.reshape(-1,1,max_len) # array of shape: (batch_size, max_len, max_len), matrix of pairwise sums per each element of the batch\n","  if min_start is not None:\n","    mask = np.zeros(probs.shape)  # create a mask to avoid including cases where i > j or i > min_start or j > min_start\n","    for i,s in enumerate(min_start):\n","        mask[i,:s,:] = 1\n","        mask[i,:,:s] = 1\n","        mask[i][np.tril_indices(max_len,-1)] = 1\n","    mask[:,0,0] = 0               # we however leave i=j=0 to detect questions without answers\n","    probs = np.ma.array(probs,mask=mask)\n","    probs = np.ma.filled(probs,-np.inf)\n","  else:\n","    probs = np.triu(probs)\n","  max_probs = np.argmax(probs.reshape(batch_size,-1), axis=-1) # array of shape: (batch_size,), argmaxes of flattened matrices of pairwise sums\n","  starts, ends = np.unravel_index(max_probs, (max_len, max_len)) # two arrays of shape: (batch_size,), 'unflattenning' of max_probs\n","  return starts, ends"],"execution_count":47,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3x7xlrxYYLMQ"},"source":["Validation itself"]},{"cell_type":"code","metadata":{"id":"-l-y4jPtYNQD","executionInfo":{"status":"ok","timestamp":1606645367845,"user_tz":-180,"elapsed":800,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["# TODO: rewrite to return numbers not tensors\n","from pprint import pprint\n","\n","def get_stats_on_batch(model, batch):\n","    d = {}\n","    l1, l2 = predict(model, batch)\n","    y1, y2 = convert_predictions(l1, l2)\n","    input_ids, attention_mask, token_type_ids, label, answer_mask, indexing, answer_starts, answer_ends = batch\n","    start, end = answer_starts, answer_ends#get_start_end(answer_mask)\n","    d['num_examples'] = start.shape[0]\n","    d['num_starts_guessed'] = torch.sum(start==y1)\n","    d['num_ends_guessed'] = torch.sum(end==y2)\n","    d['num_exact_matches_guessed'] = torch.sum(((start==y1).double()  + (end==y2).double() )==2.)\n","    _ , min_start = torch.max(token_type_ids, dim=1)\n","    \n","    predicted_start, predicted_end = convert_predictions_improved_v3(l1, l2, min_start)\n","    #input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","    start, end = npf(start), npf(end)\n","\n","    d['num_starts_guessed_post'] = np.sum(start==predicted_start)\n","    d['num_ends_guessed_post'] = np.sum(end==predicted_end)\n","    d['num_exact_matches_guessed_post'] = np.sum(((start==predicted_start).astype(int)  + (end==predicted_end).astype(int) )==2)\n","    predicted_label = predicted_start.copy().astype(int)\n","    predicted_label[predicted_label!=0] = 1 \n","    label = npf(label).astype(int)\n","    d['num_labels_guessed'] = np.sum(label == predicted_label)\n","    d['predicted_start'] = predicted_start\n","    d['predicted_end'] = predicted_end\n","    d['predicted_label'] = predicted_label\n","    d['actual_start'] = answer_starts\n","    d['actual_end'] = answer_ends\n","    d['actual_label'] = label\n","    d['input_ids'] = input_ids\n","    d['indexing'] = indexing\n","    d['start_probs'] = l1\n","    d['end_probs'] = l2\n","    return d\n","\n","def add_dicts(d1, d2):\n","  for key in set(d1.keys()).intersection(set(d2.keys())):\n","    d1[key]+=d2[key]\n","  return d1\n","\n","def validate(model, s = 'val'):\n","  # choose the right dataloader\n","  if s == 'train':\n","    a = (model.train_dataloader())\n","  else:\n","    a = (model.val_dataloader())\n","\n","  d = {\n","        'num_examples' : 0,\n","        'num_starts_guessed' : 0,\n","        'num_ends_guessed' : 0,\n","        'num_exact_matches_guessed' : 0,\n","        'num_starts_guessed_post' : 0,\n","        'num_ends_guessed_post' : 0,\n","        'num_exact_matches_guessed_post' : 0.,\n","        'num_labels_guessed' : 0\n","      }\n","\n","  # iterate over batches\n","  for batch_ndx, batch in enumerate(a):\n","    batch_stats = get_stats_on_batch(model, batch)\n","    d = add_dicts(d, batch_stats)\n","    d['EM'] = d['num_exact_matches_guessed'] / d['num_examples']\n","    d['EM post'] = d['num_exact_matches_guessed_post'] / d['num_examples']\n","    if batch_ndx%300 == 0:\n","      print(batch_ndx)\n","      pprint(d)\n","  return d\n"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0UUHWm1GL3Zi","executionInfo":{"status":"ok","timestamp":1606640782753,"user_tz":-180,"elapsed":57718,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"df2b00a5-d78b-475f-dc05-b3f92a43ec50"},"source":["validate(model, 'val')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["0\n","{'EM': tensor(0.9375),\n"," 'EM post': 0.9375,\n"," 'num_ends_guessed': tensor(15),\n"," 'num_ends_guessed_post': 15,\n"," 'num_exact_matches_guessed': tensor(15),\n"," 'num_exact_matches_guessed_post': 15.0,\n"," 'num_examples': 16,\n"," 'num_labels_guessed': 15,\n"," 'num_starts_guessed': tensor(15),\n"," 'num_starts_guessed_post': 15}\n","300\n","{'EM': tensor(0.6661),\n"," 'EM post': 0.6808554817275747,\n"," 'num_ends_guessed': tensor(3820),\n"," 'num_ends_guessed_post': 3821,\n"," 'num_exact_matches_guessed': tensor(3208),\n"," 'num_exact_matches_guessed_post': 3279.0,\n"," 'num_examples': 4816,\n"," 'num_labels_guessed': 4107,\n"," 'num_starts_guessed': tensor(3390),\n"," 'num_starts_guessed_post': 3395}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'EM': tensor(0.6667),\n"," 'EM post': 0.6816465256797583,\n"," 'num_ends_guessed': tensor(4187),\n"," 'num_ends_guessed_post': 4190,\n"," 'num_exact_matches_guessed': tensor(3531),\n"," 'num_exact_matches_guessed_post': 3610.0,\n"," 'num_examples': 5296,\n"," 'num_labels_guessed': 4504,\n"," 'num_starts_guessed': tensor(3733),\n"," 'num_starts_guessed_post': 3736}"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kqJnYUF3e9wh","executionInfo":{"status":"ok","timestamp":1606606953982,"user_tz":-180,"elapsed":1139187,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"b7f00eb3-62bb-4e76-dc0d-081bb65458c9"},"source":["validate(model, 'train')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n","{'EM': tensor(0.8750),\n"," 'EM post': 0.9375,\n"," 'num_ends_guessed': tensor(14),\n"," 'num_ends_guessed_post': 15,\n"," 'num_exact_matches_guessed': tensor(14),\n"," 'num_exact_matches_guessed_post': 15.0,\n"," 'num_examples': 16,\n"," 'num_labels_guessed': 16,\n"," 'num_starts_guessed': tensor(15),\n"," 'num_starts_guessed_post': 15}\n","300\n","{'EM': tensor(0.7749),\n"," 'EM post': 0.7882059800664452,\n"," 'num_ends_guessed': tensor(4239),\n"," 'num_ends_guessed_post': 4244,\n"," 'num_exact_matches_guessed': tensor(3732),\n"," 'num_exact_matches_guessed_post': 3796.0,\n"," 'num_examples': 4816,\n"," 'num_labels_guessed': 4481,\n"," 'num_starts_guessed': tensor(3925),\n"," 'num_starts_guessed_post': 3931}\n","600\n","{'EM': tensor(0.7688),\n"," 'EM post': 0.7825499168053245,\n"," 'num_ends_guessed': tensor(8432),\n"," 'num_ends_guessed_post': 8438,\n"," 'num_exact_matches_guessed': tensor(7393),\n"," 'num_exact_matches_guessed_post': 7525.0,\n"," 'num_examples': 9616,\n"," 'num_labels_guessed': 8931,\n"," 'num_starts_guessed': tensor(7778),\n"," 'num_starts_guessed_post': 7792}\n","900\n","{'EM': tensor(0.7689),\n"," 'EM post': 0.781562153163152,\n"," 'num_ends_guessed': tensor(12650),\n"," 'num_ends_guessed_post': 12670,\n"," 'num_exact_matches_guessed': tensor(11085),\n"," 'num_exact_matches_guessed_post': 11267.0,\n"," 'num_examples': 14416,\n"," 'num_labels_guessed': 13381,\n"," 'num_starts_guessed': tensor(11646),\n"," 'num_starts_guessed_post': 11657}\n","1200\n","{'EM': tensor(0.7705),\n"," 'EM post': 0.7823688592839301,\n"," 'num_ends_guessed': tensor(16885),\n"," 'num_ends_guessed_post': 16906,\n"," 'num_exact_matches_guessed': tensor(14806),\n"," 'num_exact_matches_guessed_post': 15034.0,\n"," 'num_examples': 19216,\n"," 'num_labels_guessed': 17860,\n"," 'num_starts_guessed': tensor(15534),\n"," 'num_starts_guessed_post': 15538}\n","1500\n","{'EM': tensor(0.7707),\n"," 'EM post': 0.7828530979347101,\n"," 'num_ends_guessed': tensor(21121),\n"," 'num_ends_guessed_post': 21146,\n"," 'num_exact_matches_guessed': tensor(18510),\n"," 'num_exact_matches_guessed_post': 18801.0,\n"," 'num_examples': 24016,\n"," 'num_labels_guessed': 22338,\n"," 'num_starts_guessed': tensor(19408),\n"," 'num_starts_guessed_post': 19424}\n","1800\n","{'EM': tensor(0.7719),\n"," 'EM post': 0.7837312604108828,\n"," 'num_ends_guessed': tensor(25348),\n"," 'num_ends_guessed_post': 25370,\n"," 'num_exact_matches_guessed': tensor(22243),\n"," 'num_exact_matches_guessed_post': 22584.0,\n"," 'num_examples': 28816,\n"," 'num_labels_guessed': 26805,\n"," 'num_starts_guessed': tensor(23304),\n"," 'num_starts_guessed_post': 23324}\n","2100\n","{'EM': tensor(0.7730),\n"," 'EM post': 0.7847453593526892,\n"," 'num_ends_guessed': tensor(29581),\n"," 'num_ends_guessed_post': 29605,\n"," 'num_exact_matches_guessed': tensor(25986),\n"," 'num_exact_matches_guessed_post': 26380.0,\n"," 'num_examples': 33616,\n"," 'num_labels_guessed': 31258,\n"," 'num_starts_guessed': tensor(27225),\n"," 'num_starts_guessed_post': 27232}\n","2400\n","{'EM': tensor(0.7716),\n"," 'EM post': 0.7835276967930029,\n"," 'num_ends_guessed': tensor(33744),\n"," 'num_ends_guessed_post': 33788,\n"," 'num_exact_matches_guessed': tensor(29640),\n"," 'num_exact_matches_guessed_post': 30100.0,\n"," 'num_examples': 38416,\n"," 'num_labels_guessed': 35696,\n"," 'num_starts_guessed': tensor(31090),\n"," 'num_starts_guessed_post': 31087}\n","2700\n","{'EM': tensor(0.7723),\n"," 'EM post': 0.7839457608293224,\n"," 'num_ends_guessed': tensor(37990),\n"," 'num_ends_guessed_post': 38032,\n"," 'num_exact_matches_guessed': tensor(33375),\n"," 'num_exact_matches_guessed_post': 33879.0,\n"," 'num_examples': 43216,\n"," 'num_labels_guessed': 40163,\n"," 'num_starts_guessed': tensor(34991),\n"," 'num_starts_guessed_post': 34981}\n","3000\n","{'EM': tensor(0.7732),\n"," 'EM post': 0.7847384205264911,\n"," 'num_ends_guessed': tensor(42230),\n"," 'num_ends_guessed_post': 42276,\n"," 'num_exact_matches_guessed': tensor(37128),\n"," 'num_exact_matches_guessed_post': 37680.0,\n"," 'num_examples': 48016,\n"," 'num_labels_guessed': 44636,\n"," 'num_starts_guessed': tensor(38918),\n"," 'num_starts_guessed_post': 38908}\n","3300\n","{'EM': tensor(0.7731),\n"," 'EM post': 0.7844024538018782,\n"," 'num_ends_guessed': tensor(46471),\n"," 'num_ends_guessed_post': 46517,\n"," 'num_exact_matches_guessed': tensor(40833),\n"," 'num_exact_matches_guessed_post': 41429.0,\n"," 'num_examples': 52816,\n"," 'num_labels_guessed': 49119,\n"," 'num_starts_guessed': tensor(42804),\n"," 'num_starts_guessed_post': 42787}\n","3600\n","{'EM': tensor(0.7734),\n"," 'EM post': 0.7846257983893363,\n"," 'num_ends_guessed': tensor(50710),\n"," 'num_ends_guessed_post': 50755,\n"," 'num_exact_matches_guessed': tensor(44559),\n"," 'num_exact_matches_guessed_post': 45207.0,\n"," 'num_examples': 57616,\n"," 'num_labels_guessed': 53585,\n"," 'num_starts_guessed': tensor(46704),\n"," 'num_starts_guessed_post': 46692}\n","3900\n","{'EM': tensor(0.7734),\n"," 'EM post': 0.7846225326839272,\n"," 'num_ends_guessed': tensor(54934),\n"," 'num_ends_guessed_post': 54982,\n"," 'num_exact_matches_guessed': tensor(48274),\n"," 'num_exact_matches_guessed_post': 48973.0,\n"," 'num_examples': 62416,\n"," 'num_labels_guessed': 58029,\n"," 'num_starts_guessed': tensor(50603),\n"," 'num_starts_guessed_post': 50590}\n","4200\n","{'EM': tensor(0.7737),\n"," 'EM post': 0.7846941204475125,\n"," 'num_ends_guessed': tensor(59181),\n"," 'num_ends_guessed_post': 59218,\n"," 'num_exact_matches_guessed': tensor(52003),\n"," 'num_exact_matches_guessed_post': 52744.0,\n"," 'num_examples': 67216,\n"," 'num_labels_guessed': 62513,\n"," 'num_starts_guessed': tensor(54519),\n"," 'num_starts_guessed_post': 54496}\n","4500\n","{'EM': tensor(0.7735),\n"," 'EM post': 0.7844784492335036,\n"," 'num_ends_guessed': tensor(63401),\n"," 'num_ends_guessed_post': 63437,\n"," 'num_exact_matches_guessed': tensor(55705),\n"," 'num_exact_matches_guessed_post': 56495.0,\n"," 'num_examples': 72016,\n"," 'num_labels_guessed': 66966,\n"," 'num_starts_guessed': tensor(58401),\n"," 'num_starts_guessed_post': 58369}\n","4800\n","{'EM': tensor(0.7734),\n"," 'EM post': 0.7843678400333264,\n"," 'num_ends_guessed': tensor(67616),\n"," 'num_ends_guessed_post': 67654,\n"," 'num_exact_matches_guessed': tensor(59411),\n"," 'num_exact_matches_guessed_post': 60252.0,\n"," 'num_examples': 76816,\n"," 'num_labels_guessed': 71412,\n"," 'num_starts_guessed': tensor(62280),\n"," 'num_starts_guessed_post': 62247}\n","5100\n","{'EM': tensor(0.7735),\n"," 'EM post': 0.7844417761223289,\n"," 'num_ends_guessed': tensor(71821),\n"," 'num_ends_guessed_post': 71868,\n"," 'num_exact_matches_guessed': tensor(63129),\n"," 'num_exact_matches_guessed_post': 64023.0,\n"," 'num_examples': 81616,\n"," 'num_labels_guessed': 75875,\n"," 'num_starts_guessed': tensor(66186),\n"," 'num_starts_guessed_post': 66146}\n","5400\n","{'EM': tensor(0.7732),\n"," 'EM post': 0.7842529161266432,\n"," 'num_ends_guessed': tensor(76061),\n"," 'num_ends_guessed_post': 76112,\n"," 'num_exact_matches_guessed': tensor(66820),\n"," 'num_exact_matches_guessed_post': 67772.0,\n"," 'num_examples': 86416,\n"," 'num_labels_guessed': 80339,\n"," 'num_starts_guessed': tensor(70057),\n"," 'num_starts_guessed_post': 70018}\n","5700\n","{'EM': tensor(0.7733),\n"," 'EM post': 0.7843470443781793,\n"," 'num_ends_guessed': tensor(80289),\n"," 'num_ends_guessed_post': 80335,\n"," 'num_exact_matches_guessed': tensor(70538),\n"," 'num_exact_matches_guessed_post': 71545.0,\n"," 'num_examples': 91216,\n"," 'num_labels_guessed': 84801,\n"," 'num_starts_guessed': tensor(73939),\n"," 'num_starts_guessed_post': 73906}\n","6000\n","{'EM': tensor(0.7735),\n"," 'EM post': 0.7845775704049325,\n"," 'num_ends_guessed': tensor(84518),\n"," 'num_ends_guessed_post': 84575,\n"," 'num_exact_matches_guessed': tensor(74271),\n"," 'num_exact_matches_guessed_post': 75332.0,\n"," 'num_examples': 96016,\n"," 'num_labels_guessed': 89269,\n"," 'num_starts_guessed': tensor(77848),\n"," 'num_starts_guessed_post': 77816}\n","6300\n","{'EM': tensor(0.7737),\n"," 'EM post': 0.7848853356610062,\n"," 'num_ends_guessed': tensor(88801),\n"," 'num_ends_guessed_post': 88855,\n"," 'num_exact_matches_guessed': tensor(78005),\n"," 'num_exact_matches_guessed_post': 79129.0,\n"," 'num_examples': 100816,\n"," 'num_labels_guessed': 93762,\n"," 'num_starts_guessed': tensor(81754),\n"," 'num_starts_guessed_post': 81729}\n","6600\n","{'EM': tensor(0.7736),\n"," 'EM post': 0.7847769277382215,\n"," 'num_ends_guessed': tensor(93029),\n"," 'num_ends_guessed_post': 93075,\n"," 'num_exact_matches_guessed': tensor(81702),\n"," 'num_exact_matches_guessed_post': 82885.0,\n"," 'num_examples': 105616,\n"," 'num_labels_guessed': 98222,\n"," 'num_starts_guessed': tensor(85614),\n"," 'num_starts_guessed_post': 85611}\n","6900\n","{'EM': tensor(0.7731),\n"," 'EM post': 0.7844334154470367,\n"," 'num_ends_guessed': tensor(97217),\n"," 'num_ends_guessed_post': 97266,\n"," 'num_exact_matches_guessed': tensor(85366),\n"," 'num_exact_matches_guessed_post': 86614.0,\n"," 'num_examples': 110416,\n"," 'num_labels_guessed': 102677,\n"," 'num_starts_guessed': tensor(89484),\n"," 'num_starts_guessed_post': 89491}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'EM': tensor(0.7731),\n"," 'EM post': 0.7844016498773375,\n"," 'num_ends_guessed': tensor(97982),\n"," 'num_ends_guessed_post': 98033,\n"," 'num_exact_matches_guessed': tensor(86033),\n"," 'num_exact_matches_guessed_post': 87289.0,\n"," 'num_examples': 111281,\n"," 'num_labels_guessed': 103486,\n"," 'num_starts_guessed': tensor(90183),\n"," 'num_starts_guessed_post': 90190}"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"aM7ujFALyPtH"},"source":["**THIS IS THE END OF TRAINING CODE. THE CODE BELOW HASN'T BEEN REVIEWED/REWRITTEN**\n"]},{"cell_type":"code","metadata":{"id":"bNR0ipTe0b1-","executionInfo":{"status":"ok","timestamp":1606645376787,"user_tz":-180,"elapsed":1023,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["#from random import randint\n","def batch_by_number(model, i):\n","  dataloader = model.val_dataloader()\n","  for batch_ndx, batch in enumerate(dataloader):\n","    if batch_ndx == i:\n","      return batch\n","\n","def print_example(d, i):\n","  res = {}\n","  index = d['indexing'][i]\n","  predicted_start = d['predicted_start'][i]\n","  predicted_end = d['predicted_end'][i]\n","  input_ids = d['input_ids'][i]\n","  res['predicted_answer'] = tokenizer.convert_ids_to_tokens(input_ids[predicted_start : predicted_end+1])\n","  res['actual_answer'] = val_actual_answers[index]\n","  #print(d['indexing'][i])\n","  res['actual_label'] = d['actual_label'][i]\n","  res['predicted_label'] = d['predicted_label'][i]\n","  res['text'] = val_full_paragraphs[index]\n","  res['question'] = val_full_questions[index]\n","  return res"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Orum4DYDKTVI","executionInfo":{"status":"ok","timestamp":1606645985511,"user_tz":-180,"elapsed":690,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"2b953ecd-008c-4676-9876-3d7452af8f81"},"source":["batch = batch_by_number(model, 1)\n","d = get_stats_on_batch(model, batch)\n","num_in_batch = 4\n","pprint(print_example(d, num_in_batch))"],"execution_count":63,"outputs":[{"output_type":"stream","text":["{'actual_answer': 'Atkinson–Shiffrin model.',\n"," 'actual_label': 1,\n"," 'predicted_answer': ['▁brain'],\n"," 'predicted_label': 1,\n"," 'question': 'What did KF disprove during this study?',\n"," 'text': 'The model also shows all the memory stores as being a single unit '\n","         'whereas research into this shows differently. For example, '\n","         'short-term memory can be broken up into different units such as '\n","         'visual information and acoustic information. In a study by Zlonoga '\n","         \"and Gerber (1986), patient 'KF' demonstrated certain deviations from \"\n","         'the Atkinson–Shiffrin model. Patient KF was brain damaged, '\n","         'displaying difficulties regarding short-term memory. Recognition of '\n","         'sounds such as spoken numbers, letters, words and easily '\n","         'identifiable noises (such as doorbells and cats meowing) were all '\n","         'impacted. Interestingly, visual short-term memory was unaffected, '\n","         'suggesting a dichotomy between visual and audial memory.'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9usy_BK6WBap","executionInfo":{"status":"ok","timestamp":1606646088249,"user_tz":-180,"elapsed":739,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"20144a37-8986-4197-835d-27768a6d8863"},"source":["start_probs = d['start_probs'][num_in_batch]\n","end_probs = d['end_probs'][num_in_batch]\n","input_ids = d['input_ids'][num_in_batch]\n","values,indices = start_probs.topk(5)\n","print(values, indices, tokenizer.convert_ids_to_tokens(input_ids[indices]))\n","values,indices = end_probs.topk(5)\n","print(values, indices, tokenizer.convert_ids_to_tokens(input_ids[indices]))"],"execution_count":64,"outputs":[{"output_type":"stream","text":["tensor([5.3611, 4.6863, 4.3896, 2.9389, 2.2025]) tensor([ 93, 104,   0, 106, 109]) ['▁brain', '▁recognition', '[CLS]', '▁sounds', '▁spoken']\n","tensor([5.7149, 4.8908, 4.7431, 3.7488, 3.2231]) tensor([ 93,   0, 118, 106, 130]) ['▁brain', '[CLS]', '▁noises', '▁sounds', ')']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137},"id":"yli7HPaYbjVu","executionInfo":{"status":"ok","timestamp":1606645405182,"user_tz":-180,"elapsed":712,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"31b116b3-26c5-43f6-c6fa-c2f075e0800f"},"source":["torch.cuda.memory_summary()"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |     961 MB |    6381 MB |   49321 MB |   48360 MB |\\n|       from large pool |     957 MB |    6376 MB |   49308 MB |   48351 MB |\\n|       from small pool |       4 MB |       5 MB |      13 MB |       8 MB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |     961 MB |    6381 MB |   49321 MB |   48360 MB |\\n|       from large pool |     957 MB |    6376 MB |   49308 MB |   48351 MB |\\n|       from small pool |       4 MB |       5 MB |      13 MB |       8 MB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    6466 MB |    6466 MB |    6754 MB |  294912 KB |\\n|       from large pool |    6460 MB |    6460 MB |    6748 MB |  294912 KB |\\n|       from small pool |       6 MB |       6 MB |       6 MB |       0 KB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   20814 KB |   53501 KB |  222198 KB |  201384 KB |\\n|       from large pool |   19176 KB |   51944 KB |  209128 KB |  189952 KB |\\n|       from small pool |    1638 KB |    2535 KB |   13070 KB |   11432 KB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |      59    |     311    |    2316    |    2257    |\\n|       from large pool |      16    |     210    |    1726    |    1710    |\\n|       from small pool |      43    |     109    |     590    |     547    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |      59    |     311    |    2316    |    2257    |\\n|       from large pool |      16    |     210    |    1726    |    1710    |\\n|       from small pool |      43    |     109    |     590    |     547    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     204    |     204    |     216    |      12    |\\n|       from large pool |     201    |     201    |     213    |      12    |\\n|       from small pool |       3    |       3    |       3    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      15    |      22    |     268    |     253    |\\n|       from large pool |       7    |      10    |      30    |      23    |\\n|       from small pool |       8    |      13    |     238    |     230    |\\n|===========================================================================|\\n'"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25MpnU2UH4aL","executionInfo":{"status":"ok","timestamp":1606639172962,"user_tz":-180,"elapsed":809,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"5bddf6b4-63d2-4230-862c-48adbab2af1f"},"source":["batch_by_number(model, 5) #* 16"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"AiknZVqe2rGU"},"source":["32*256*768*12*32/8/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3I-AErsq1F7t"},"source":["def predict(model, batch):\n","  input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","  return model(input_ids, attention_mask, token_type_ids)\n","\n","def convert_predictions(l1, l2, label, answer_mask):\n","  a, y1 = torch.max(l1, dim=1)\n","  a, y2 = torch.max(l2, dim=2)\n","  guess1, guess2 = final_guess(l1, l2)\n","  \"\"\"if self.counter < 10:\n","    self.counter += 1\n","    self.dic_1[self.counter] = [l2, y2]\"\"\"\n","  d_pre = results_dic(y1, y2, label, answer_mask)\n","  d_post = results_dic(guess1, guess2, label, answer_mask)\n","  return y1, y2, guess1, guess2, d_pre, d_post"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AuwZv_Ng1GED"},"source":["batch =  get_random_batch(new_model)#(bert_finetuner)\n","input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","l1, l2 = predict(new_model, batch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zopOdSYalAgt","colab":{"base_uri":"https://localhost:8080/","height":87},"outputId":"3b721249-e3bf-4f35-cb3e-6b4462827b94"},"source":["print(indexing)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([  1709,  50257,  28607,  85809,  18089,  43168, 109889, 114528,  36480,\n","        105855,  90441,  58618,  93205, 103048,  66757,  74668,   6850,  47620,\n","         88623,  44466,  21506, 101689,  32743,  40006,  49163, 112892,  74904,\n","         62193,  44188,  93296, 116388,  26653])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZARZmoMN0b_R"},"source":["y1, y2, guess1, guess2, d1, d2 = convert_predictions(l1, l2, label, answer_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ck-huWF-SYW","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"1d14eff0-689b-41d2-d751-9fdf01f18b1e"},"source":["print(y1)\n","print(guess1.type(torch.IntTensor))\n","print(label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n","        1, 1, 1, 1, 0, 1, 1, 0])\n","tensor([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n","        1, 1, 1, 1, 0, 1, 1, 0], device='cpu', dtype=torch.int32)\n","tensor([0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n","        1, 1, 1, 0, 0, 1, 1, 0])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LCaGo_h8Uvn1","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"bce5ca45-cf14-49ff-99d7-63b2381238f1"},"source":["print(y1)\n","print(guess1.type(torch.IntTensor))\n","print(label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n","        1, 0, 0, 1, 1, 0, 1, 1])\n","tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n","        1, 0, 1, 1, 1, 0, 1, 1], device='cpu', dtype=torch.int32)\n","tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n","        1, 0, 1, 1, 1, 0, 1, 1])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bAJG51UM-A5d","colab":{"base_uri":"https://localhost:8080/","height":834},"outputId":"6fb66077-5a43-4839-90d5-4137d729b006"},"source":["i = 10\n","print(y2[i])\n","print(guess2[i].type(torch.IntTensor))\n","print(answer_mask[i])\n","index = indexing[i].item()\n","print(torch.IntTensor(plausible_answer_mask[index]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cpu',\n","       dtype=torch.int32)\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cpu',\n","       dtype=torch.int32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LnoqxsIM_xwM","colab":{"base_uri":"https://localhost:8080/","height":161},"outputId":"d8198c69-5829-417e-d9b8-8537bf94ffad"},"source":["print(get_answer(input_ids[i], answer_mask[i]))\n","\n","print(get_answer(input_ids[i], guess2[i]))\n","index = indexing[i].item()\n","print(index)\n","print(full_answers[index])\n","print(full_questions[index])\n","print(full_paragraphs[index])\n","print(get_answer(input_ids[i], torch.Tensor(plausible_answer_mask[index])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['▁arab']\n","None\n","90441\n","Arab\n","What race was the majority in Palestine in the 1940s?\n","The British Mandate of Palestine, where an Arab majority lived alongside a Jewish minority, presented the British with a similar problem to that of India. The matter was complicated by large numbers of Jewish refugees seeking to be admitted to Palestine following the Holocaust, while Arabs were opposed to the creation of a Jewish state. Frustrated by the intractability of the problem, attacks by Jewish paramilitary organisations and the increasing cost of maintaining its military presence, Britain announced in 1947 that it would withdraw in 1948 and leave the matter to the United Nations to solve. The UN General Assembly subsequently voted for a plan to partition Palestine into a Jewish and an Arab state.\n","['▁arab']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I2J50MNEAhOQ"},"source":["def get_answer(input_id, answer):\n","  indices = (numpy.nonzero(answer)).tolist()\n","  #print(indices)\n","  #  indices.append(l[0])\n","  if indices:\n","    tokens = tokenizer.convert_ids_to_tokens(input_id)\n","    return tokens[indices[0][0]:indices[-1][0]+1]\n","  else:\n","    return None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WB9GOlzXld7M"},"source":["def get_probabilities_individual(l, answer):\n","  indices = (numpy.nonzero(answer)).tolist()\n","  if indices:\n","    res = l[indices[0][0]:indices[-1][0]+1]\n","    return res[:,1] - res[:,0]\n","  else:\n","    return None\n","\n","def get_probability_label(l):\n","  return l[1] - l[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oVEDXob-l4fm","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"d1abef62-8ddb-4575-8975-69a8cec86a01"},"source":["print(get_probabilities_individual(l2[i], guess2[i]))\n","print(get_probability_label(l1[i]))\n","print(guess1[i] - label[i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["None\n","tensor(-0.8393, grad_fn=<SubBackward0>)\n","tensor(-1.)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"55yY-rZ6Dr3A"},"source":["def get_wrong_guesses(guesses, lbls):\n","  wrong_guesses = []\n","  for x in (guesses - lbls).nonzero().cpu().numpy().tolist():\n","    wrong_guesses.append(x[0])\n","  return wrong_guesses"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ThmCMhScEqBY","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"52664d18-6788-467e-d927-924858fb8b95"},"source":["wrong_guesses = get_wrong_guesses(y1, label)\n","print(wrong_guesses)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[10, 26]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fhV42t3I0KOw","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"248107bd-b38a-413f-ab51-f378f979daad"},"source":["i = 26\n","print(get_probabilities_individual(l2[i], guess2[i]))\n","print(get_probabilities_individual(l2[i], answer_mask[i]))\n","index = indexing[i].item()\n","print(get_probabilities_individual(l2[i], torch.Tensor(plausible_answer_mask[index])))\n","print(get_probability_label(l1[i]))\n","#print(guess1[i] - label[i])\n","print(guess1[i], label[i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([3.1200, 2.9809, 2.7662, 3.3491, 0.1146, 0.0939, 0.4229],\n","       grad_fn=<SubBackward0>)\n","tensor([3.1200, 2.9809, 2.7662, 3.3491], grad_fn=<SubBackward0>)\n","tensor([3.1200, 2.9809, 2.7662, 3.3491], grad_fn=<SubBackward0>)\n","tensor(-0.6872, grad_fn=<SubBackward0>)\n","tensor(1.) tensor(1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zVbJ_YSXlq6X","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b62e26cd-1418-4907-f85f-fa6a5ce421d1"},"source":["l1.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 2])"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"0s8xPk_s8SLd","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"dfaf627e-e448-4348-863c-025de107bd2b"},"source":["d1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answerable_actual': tensor(0.5625),\n"," 'answerable_result': tensor(0.5625),\n"," 'guessed_answerable': tensor(0.4375),\n"," 'guessed_ones': tensor(0.0115),\n"," 'ones_percentage_actual': tensor(0.0122),\n"," 'ones_percentage_guessed': tensor(0.0454),\n"," 'val_acc_individual': tensor(0.9653),\n"," 'val_acc_labels': tensor(0.7500)}"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"tHx6EqxVU30Q","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"241f371d-734a-4df7-b582-29a6cdcd24fb"},"source":["d1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answerable_actual': tensor(0.5625),\n"," 'answerable_result': tensor(0.5625),\n"," 'guessed_answerable': tensor(0.4375),\n"," 'guessed_ones': tensor(0.0115),\n"," 'ones_percentage_actual': tensor(0.0122),\n"," 'ones_percentage_guessed': tensor(0.0454),\n"," 'val_acc_individual': tensor(0.9653),\n"," 'val_acc_labels': tensor(0.7500)}"]},"metadata":{"tags":[]},"execution_count":147}]},{"cell_type":"code","metadata":{"id":"NAND2ZW88XMd","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"ec84b873-39db-4ada-952e-ab03073eebc9"},"source":["d2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answerable_actual': tensor(0.5625),\n"," 'answerable_result': tensor(0.5625),\n"," 'guessed_answerable': tensor(0.4375),\n"," 'guessed_ones': tensor(0.0112),\n"," 'ones_percentage_actual': tensor(0.0122),\n"," 'ones_percentage_guessed': tensor(0.0270),\n"," 'val_acc_individual': tensor(0.9833),\n"," 'val_acc_labels': tensor(0.7500)}"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"lVqPQ8u3VJ5t","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"711895e1-6ef7-4527-d4e5-54fe9caea34a"},"source":["d2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answerable_actual': tensor(0.5625),\n"," 'answerable_result': tensor(0.6875),\n"," 'guessed_answerable': tensor(0.5312),\n"," 'guessed_ones': tensor(0.0112),\n"," 'ones_percentage_actual': tensor(0.0122),\n"," 'ones_percentage_guessed': tensor(0.0270),\n"," 'val_acc_individual': tensor(0.9833),\n"," 'val_acc_labels': tensor(0.8125)}"]},"metadata":{"tags":[]},"execution_count":148}]},{"cell_type":"markdown","metadata":{"id":"tcrUfpD0X6nF"},"source":["##Saving"]},{"cell_type":"code","metadata":{"id":"T8i5psJPYCRY","colab":{"base_uri":"https://localhost:8080/","height":292},"outputId":"63fb2a35-ab66-43a4-8771-180c121a9b8a"},"source":["#bert_finetuner.save_checkpoint(base_dir + './saved_models_albert')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-152-22c3859db120>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_finetuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'./saved_models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'SQUADBERT' object has no attribute 'save_checkpoint'"]}]},{"cell_type":"code","metadata":{"id":"x6NEGHMBZGze"},"source":["#bert_finetuner."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bepR4KwgZyIo"},"source":["trainer.save_checkpoint(base_dir + 'saved_models/new')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LlBeUTTJYCaz","colab":{"base_uri":"https://localhost:8080/","height":316},"outputId":"e0b1b7b9-8ef0-4956-e957-0bc72b7ab90f"},"source":["#input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","#ll1, ll2 = predict(new_model, batch)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-175-e88a2b27191f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mll1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-144-abd96af2e684>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-cd8f6805240c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m    108\u001b[0m         q, _, attn = self.bert(input_ids=input_ids, \n\u001b[1;32m    109\u001b[0m                          \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                          token_type_ids=token_type_ids)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mq_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         )\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                 \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_idx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers_per_group\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgroup_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers_per_group\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m             )\n\u001b[1;32m    346\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_group_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malbert_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malbert_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mprojected_context_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bfnd,ndh->bfh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mprojected_context_layer_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojected_context_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mlayernormed_context_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprojected_context_layer_dropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayernormed_context_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_probs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_attentions\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayernormed_context_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 15.90 GiB total capacity; 15.14 GiB already allocated; 11.81 MiB free; 15.19 GiB reserved in total by PyTorch)"]}]},{"cell_type":"code","metadata":{"id":"rZew7826YCi3","colab":{"base_uri":"https://localhost:8080/","height":781},"outputId":"c2a72ba1-d41e-4678-fc60-c66c13b89bb8"},"source":["torch.set_default_tensor_type('torch.cuda.FloatTensor')\n","new_model = SQUADBERT({\"d1\": 10, 'l1' : 10, 'd2' : 10, 'l2' : 10}, batch_size = 32, weight = 20.)\n","#new_model = SQUADBERT.load_from_checkpoint(base_dir + 'saved_models/new')\n","checkpoint = torch.load(base_dir + 'saved_models/new', map_location=lambda storage, loc: storage)\n","new_model.load_state_dict(checkpoint['state_dict'])\n","new_model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train, validation, test --  114245 1166 1166\n","NEW\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SQUADBERT(\n","  (bert): AlbertModel(\n","    (embeddings): AlbertEmbeddings(\n","      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): AlbertTransformer(\n","      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n","      (albert_layer_groups): ModuleList(\n","        (0): AlbertLayerGroup(\n","          (albert_layers): ModuleList(\n","            (0): AlbertLayer(\n","              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (attention): AlbertAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              )\n","              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n","              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (pooler): Linear(in_features=768, out_features=768, bias=True)\n","    (pooler_activation): Tanh()\n","  )\n","  (A1): Linear(in_features=768, out_features=100, bias=True)\n","  (B1): Linear(in_features=768, out_features=100, bias=True)\n","  (LG1): Linear(in_features=10, out_features=2, bias=True)\n","  (A2): Linear(in_features=768, out_features=100, bias=True)\n","  (B2): Linear(in_features=768, out_features=100, bias=True)\n","  (LG2): Linear(in_features=10, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"PXiE35_AlMrg"},"source":["def predicte(model, batch):\n","  input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","  #input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = input_ids.cpu(), attention_mask.cpu(), token_type_ids.cpu(), label.cpu(), answer_mask.cpu(), indexing.cpu()\n","  return model(input_ids, attention_mask, token_type_ids)\n","\n","def convert_predictions(l1, l2, label, answer_mask):\n","  a, y1 = torch.max(l1, dim=1)\n","  a, y2 = torch.max(l2, dim=2)\n","  guess1, guess2 = final_guess(l1, l2)\n","  \"\"\"if self.counter < 10:\n","    self.counter += 1\n","    self.dic_1[self.counter] = [l2, y2]\"\"\"\n","  d_pre = results_dic(y1, y2, label, answer_mask)\n","  d_post = results_dic(guess1, guess2, label, answer_mask)\n","  return y1, y2, guess1, guess2, d_pre, d_post"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGMkfO5TZux6"},"source":["test = torch.tensor(input_ids[153:155], dtype=torch.long).cuda(), torch.tensor(attention_mask[153:155], dtype=torch.long).cuda(), torch.tensor(token_type_ids[153:155], dtype=torch.long).cuda()\n","#                               1 - torch.tensor(labels, dtype=torch.long).cuda(), #label is 0 if there is an answer in the original dataset\n","#                                torch.tensor(answer_mask, dtype=torch.long).cuda(),\n","#                                torch.tensor(indexing, dtype=torch.long).cuda())\n","test_input_ids, test_attention_mask, test_token_type_ids = test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MzZlA05zab7s"},"source":["l1, l2 = bert_finetuner(test_input_ids, test_attention_mask, test_token_type_ids)\n","#v1, v2 = bert_finetuner(test_input_ids, test_attention_mask, test_token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z2GcGa67YCq1"},"source":["\"\"\"model = SQUADBERT('ProjectionModuleLong', {\"d1\": 8, 'l1' : 20, 'd2' : 8, 'l2' : 40}, batch_size = 32, weight = 60.)\n","checkpoint = torch.load(base_dir + \"/Checkpoints/_ckpt_epoch_2.ckpt\", map_location=lambda storage, loc: storage)\n","model.load_state_dict(checkpoint['state_dict'])\"\"\"\n","ll1, ll2 = new_model(test_input_ids, test_attention_mask, test_token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_7x4aQIxczUE","colab":{"base_uri":"https://localhost:8080/","height":283},"outputId":"135c322a-edfd-442a-fad6-62736fc6fe87"},"source":["l2-ll2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0., 0.],\n","         [0., 0.],\n","         [0., 0.],\n","         ...,\n","         [0., 0.],\n","         [0., 0.],\n","         [0., 0.]],\n","\n","        [[0., 0.],\n","         [0., 0.],\n","         [0., 0.],\n","         ...,\n","         [0., 0.],\n","         [0., 0.],\n","         [0., 0.]]], grad_fn=<SubBackward0>)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"kojxrYbPdO7f"},"source":["l1, _, l2 = bert_finetuner.bert(input_ids=test_input_ids, \n","                         attention_mask=test_attention_mask, \n","                         token_type_ids=test_token_type_ids)\n","ll1, _, ll2 = new_model.bert(input_ids=test_input_ids, \n","                         attention_mask=test_attention_mask, \n","                         token_type_ids=test_token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v10uVLUDn4e5"},"source":["lll1, _, lll2 = berty.cuda()(input_ids=test_input_ids, \n","                         attention_mask=test_attention_mask, \n","                         token_type_ids=test_token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oXZTvY3is0GN"},"source":["berty = AlbertModel.from_pretrained('albert-base-v1', output_attentions=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICb2xAhYs-ep"},"source":["berty = berty.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ve5EFiTp2saa","colab":{"base_uri":"https://localhost:8080/","height":692},"outputId":"3cc4576d-215e-4bd4-cb52-196a27d7c5db"},"source":["print(\"Model's state_dict:\")\n","for param_tensor in bert_finetuner.state_dict():\n","    print(param_tensor, \"\\t\", bert_finetuner.state_dict()[param_tensor].size())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model's state_dict:\n","bert.embeddings.word_embeddings.weight \t torch.Size([30000, 128])\n","bert.embeddings.position_embeddings.weight \t torch.Size([512, 128])\n","bert.embeddings.token_type_embeddings.weight \t torch.Size([2, 128])\n","bert.embeddings.LayerNorm.weight \t torch.Size([128])\n","bert.embeddings.LayerNorm.bias \t torch.Size([128])\n","bert.encoder.embedding_hidden_mapping_in.weight \t torch.Size([768, 128])\n","bert.encoder.embedding_hidden_mapping_in.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight \t torch.Size([3072, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias \t torch.Size([3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight \t torch.Size([768, 3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias \t torch.Size([768])\n","bert.pooler.weight \t torch.Size([768, 768])\n","bert.pooler.bias \t torch.Size([768])\n","A1.weight \t torch.Size([100, 768])\n","A1.bias \t torch.Size([100])\n","B1.weight \t torch.Size([100, 768])\n","B1.bias \t torch.Size([100])\n","LG1.weight \t torch.Size([2, 10])\n","LG1.bias \t torch.Size([2])\n","A2.weight \t torch.Size([100, 768])\n","A2.bias \t torch.Size([100])\n","B2.weight \t torch.Size([100, 768])\n","B2.bias \t torch.Size([100])\n","LG2.weight \t torch.Size([2, 10])\n","LG2.bias \t torch.Size([2])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WVc-MsFieptn","colab":{"base_uri":"https://localhost:8080/","height":478},"outputId":"6f3c7fb0-7462-4a46-f6f6-f5e0d6a19dfe"},"source":["print(\"Model's state_dict:\")\n","for param_tensor in bert_finetuner.state_dict():\n","    print(param_tensor, \"\\t\", bert_finetuner.state_dict()[param_tensor].size())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model's state_dict:\n","bert.embeddings.word_embeddings.weight \t torch.Size([30000, 128])\n","bert.embeddings.position_embeddings.weight \t torch.Size([512, 128])\n","bert.embeddings.token_type_embeddings.weight \t torch.Size([2, 128])\n","bert.embeddings.LayerNorm.weight \t torch.Size([128])\n","bert.embeddings.LayerNorm.bias \t torch.Size([128])\n","bert.encoder.embedding_hidden_mapping_in.weight \t torch.Size([768, 128])\n","bert.encoder.embedding_hidden_mapping_in.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight \t torch.Size([3072, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias \t torch.Size([3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight \t torch.Size([768, 3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias \t torch.Size([768])\n","bert.pooler.weight \t torch.Size([768, 768])\n","bert.pooler.bias \t torch.Size([768])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mUD0IG1xftWz","colab":{"base_uri":"https://localhost:8080/","height":478},"outputId":"3de4effe-1893-4312-87cc-485b0d520833"},"source":["print(\"Model's state_dict:\")\n","for param_tensor in new_model.state_dict():\n","    print(param_tensor, \"\\t\", new_model.state_dict()[param_tensor].size())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model's state_dict:\n","bert.embeddings.word_embeddings.weight \t torch.Size([30000, 128])\n","bert.embeddings.position_embeddings.weight \t torch.Size([512, 128])\n","bert.embeddings.token_type_embeddings.weight \t torch.Size([2, 128])\n","bert.embeddings.LayerNorm.weight \t torch.Size([128])\n","bert.embeddings.LayerNorm.bias \t torch.Size([128])\n","bert.encoder.embedding_hidden_mapping_in.weight \t torch.Size([768, 128])\n","bert.encoder.embedding_hidden_mapping_in.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight \t torch.Size([3072, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias \t torch.Size([3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight \t torch.Size([768, 3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias \t torch.Size([768])\n","bert.pooler.weight \t torch.Size([768, 768])\n","bert.pooler.bias \t torch.Size([768])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zGez9s2PuF3F"},"source":["input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Du2ImLt5uGAb"},"source":["q, _, _ = new_model.bert(input_ids=input_ids, \n","                         attention_mask=attention_mask, \n","                         token_type_ids=token_type_ids)\n","\n","qq, _, _ = berty(input_ids=input_ids, \n","                         attention_mask=attention_mask, \n","                         token_type_ids=token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kX39hwn6yDUc","colab":{"base_uri":"https://localhost:8080/","height":167},"outputId":"71477994-4954-4cf6-8042-ec33200a708b"},"source":[""],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-b862d2305077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_finetuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: summarize() missing 1 required positional argument: 'mode'"]}]},{"cell_type":"code","metadata":{"id":"CQ2Bw7FhYCyx"},"source":["import pickle\n","with open(base_dir + r\"l1l2\", \"wb\") as f:\n","    pickle.dump([l1, l2], f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xh4le09AYC6I"},"source":["with open(base_dir + r\"l1l2\", \"rb\") as f:\n","    [l1, l2] = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DthsMjZrYDCF"},"source":["with open(base_dir + r\"batch\", \"wb\") as f:\n","    pickle.dump(batch, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LzxZpx_fYDJo"},"source":["with open(base_dir + r\"batch\", \"rb\") as f:\n","    batch = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHjVXlyDgo9Z","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"76574056-8238-40f6-dabb-a5bb7a4165c2"},"source":["for i in range(len(batch)):\n","  print((batch[i] - batchh[i]).sum())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(0)\n","tensor(0)\n","tensor(0)\n","tensor(0)\n","tensor(0)\n","tensor(0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ie9HtHcwg_6u","colab":{"base_uri":"https://localhost:8080/","height":585},"outputId":"10a8f18a-4bf6-46d4-bcb6-13fb9b4e4747"},"source":["l1 - ll1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.3311, -1.1707],\n","        [-1.1836,  0.5233],\n","        [-0.3844, -0.3816],\n","        [-0.8956, -0.1006],\n","        [ 0.0560, -0.4223],\n","        [ 0.1867, -0.2628],\n","        [ 1.3606, -1.6090],\n","        [-1.6539,  0.3736],\n","        [-0.6360,  0.2532],\n","        [ 0.4264, -0.8577],\n","        [-1.4590,  0.6360],\n","        [ 0.0429, -0.3946],\n","        [-1.3437,  0.4152],\n","        [-1.2637,  0.2589],\n","        [-0.6773, -0.2426],\n","        [-0.4709,  0.0996],\n","        [ 0.6763, -0.9663],\n","        [ 0.6074, -0.9704],\n","        [ 1.3427, -0.6838],\n","        [-0.4018, -0.3278],\n","        [-0.7176,  0.1280],\n","        [-0.6025, -0.2789],\n","        [-1.1873,  0.7783],\n","        [-0.4975, -0.0069],\n","        [-1.1089, -0.0882],\n","        [-1.2815,  0.2321],\n","        [-0.0177, -0.4595],\n","        [-1.4720,  0.4155],\n","        [ 0.4455, -0.4733],\n","        [-0.6149, -0.2658],\n","        [-1.4690,  0.5316],\n","        [ 0.2757, -0.8703]], grad_fn=<SubBackward0>)"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"tyEp0rWqRTY7","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"f3f70f51-e687-4485-9e39-21d4f37990da"},"source":["'''\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","\n","# DEFAULTS used by the Trainer\n","checkpoint_callback = ModelCheckpoint(\n","    filepath='./saved_models',\n","    save_best_only=True,\n","    verbose=True,\n","    monitor='val_loss',\n","    mode='min',\n","    prefix=''\n",")\n","\n","#trainer = Trainer(checkpoint_callback=checkpoint_callback)\n","'''\n","#!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nfrom pytorch_lightning.callbacks import ModelCheckpoint\\n\\n# DEFAULTS used by the Trainer\\ncheckpoint_callback = ModelCheckpoint(\\n    filepath='./saved_models',\\n    save_best_only=True,\\n    verbose=True,\\n    monitor='val_loss',\\n    mode='min',\\n    prefix=''\\n)\\n\\n#trainer = Trainer(checkpoint_callback=checkpoint_callback)\\n\""]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"E6kuinpEU17b"},"source":["#!pip install apex\n","#import apex"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0UT3mRNoot1"},"source":["#import apex"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NZ1X94Lw-5pB"},"source":["## Summary\n","\n","That's it! Checkout [PyTorch Lightning](https://github.com/williamFalcon/pytorch-lightning/) which works with any machine learning approach that uses PyTorch."]},{"cell_type":"code","metadata":{"id":"4ARIT37rDdIZ"},"source":["from pprint import pprint as pp\n","pp(bert_finetuner.dic_1[1][1].cpu().numpy()[:5,:20])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pytSP8OxOrr1"},"source":["print(bert)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GHbKj70yOs3D"},"source":["bert_finetuner.dic_1[1][1].shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YfZpDAhMUwQO"},"source":["type(torch.Tensor(answer_mask).type(torch.cuda.FloatTensor))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_VPqM8BRa72r"},"source":["#dict_data = {\"input_ids\": input_ids, \"token_type_ids\": token_type_ids, \"labels\": labels, \"attention_mask\": attention_mask}\n","with open(base_dir + r\"albert256_tensor3model20.pickle\", \"wb\") as f:\n","    pickle.dump(bert_finetuner, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_1wxNwtIb64P"},"source":["torch.save(bert_finetuner, (base_dir + r\"albert256_tensor3model20\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gk9iV6KFdYxP"},"source":["trainer.default_save_path = base_dir + r'albert_model256'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HN-zi80lecp0"},"source":["try:\n","    from apex import amp\n","\n","    APEX_AVAILABLE = True\n","except ImportError:\n","    APEX_AVAILABLE = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a75UtTTYVC8G"},"source":["APEX_AVAILABLE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_YqJZx5VEY6"},"source":["a = torch.Tensor([[1,2,3],[4,5,6]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4goV0SYr8qqV"},"source":["torch.reshape(a,(2,2,2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rMJ4fE3N8ub-"},"source":["a.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q_Jhdys19Hwp"},"source":["torch.cat([a]*5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gtcok93D9gvq"},"source":["a = torch.Tensor([[1,0,1],[0,1,0]])\n","print(a.shape)\n","b = torch.Tensor([[1,0,0], [1, 0, 0]])\n","print(a*b)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p0P2I2KMT6jy"},"source":["print(torch.mul(a, b))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AmSXS5hqUQF5"},"source":["print((a==b).type(torch.cuda.FloatTensor).mean())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IG3Xpnc9Uatc"},"source":[""],"execution_count":null,"outputs":[]}]}