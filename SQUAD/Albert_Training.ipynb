{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Albert_Training.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"149a595d3023448d9b0f995eddf29963":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f6158dd7e0ab43f7948be01592e728e6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f799f371bb5f4ce99212702625adf1f0","IPY_MODEL_7337b345a02a4c84985d79106ec53800"]}},"f6158dd7e0ab43f7948be01592e728e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f799f371bb5f4ce99212702625adf1f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7ace1c2dbef44feba80f5e3ddc40eb73","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":760289,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":760289,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_19436e4a3cd64b0bb20031b7ac5d631f"}},"7337b345a02a4c84985d79106ec53800":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bbe9482dbdfa480da8bada78abb83feb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 760k/760k [01:56&lt;00:00, 6.53kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_290a3d624a8849108e0e29084e1298ab"}},"7ace1c2dbef44feba80f5e3ddc40eb73":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"19436e4a3cd64b0bb20031b7ac5d631f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bbe9482dbdfa480da8bada78abb83feb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"290a3d624a8849108e0e29084e1298ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ea234f33db9241dd98535d87e1bd51f1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_badd3f050240471292d3b572ad42f44b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d2a2ba74dc3648508d1942e822c7c092","IPY_MODEL_0330aee6e3ce4995a6b801cb7db6b551"]}},"badd3f050240471292d3b572ad42f44b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d2a2ba74dc3648508d1942e822c7c092":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c99e34ba05e242dbbcf836d3c192011e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":684,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":684,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_721201448d614400a0bbc2ad51eaf41f"}},"0330aee6e3ce4995a6b801cb7db6b551":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_42422a9f2e1d40798e47d70dedb93282","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 684/684 [00:01&lt;00:00, 409B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8323ae8442b849918dc4023f2a0c41a4"}},"c99e34ba05e242dbbcf836d3c192011e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"721201448d614400a0bbc2ad51eaf41f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"42422a9f2e1d40798e47d70dedb93282":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8323ae8442b849918dc4023f2a0c41a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"894862e0a41a4839816df746e1dfbf29":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bef181e9e94c4ef589cbdf39746370b5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_55b4a41b8a774162b736e86c1dcc1ed4","IPY_MODEL_76e83aac585b4b1088c9b9c53d972348"]}},"bef181e9e94c4ef589cbdf39746370b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"55b4a41b8a774162b736e86c1dcc1ed4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_170a8513359b406e936b70d0c25cb118","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":47376396,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":47376396,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c298e55855184448a11e185e934445b0"}},"76e83aac585b4b1088c9b9c53d972348":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b3294370f292443c81dcedf9f7105ad2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 47.4M/47.4M [00:01&lt;00:00, 36.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1b03699a9fd640edbf07d7417ee7671d"}},"170a8513359b406e936b70d0c25cb118":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c298e55855184448a11e185e934445b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b3294370f292443c81dcedf9f7105ad2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1b03699a9fd640edbf07d7417ee7671d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cfb5ba1021b443ce9dcfc4a52cb474cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bd9aede04406425da1be8f0aa8658462","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1f5ed92db00f4c77a5052e9855d10655","IPY_MODEL_694dfeaa88be4ee4962a3a409b8c161d"]}},"bd9aede04406425da1be8f0aa8658462":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"1f5ed92db00f4c77a5052e9855d10655":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1f1cc0f7c7794bc7bb666b8b90b975c0","_dom_classes":[],"description":"Validation sanity check: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_25c6caab5af54773bcb32daa87a14f53"}},"694dfeaa88be4ee4962a3a409b8c161d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2e221dc9a66240df8b8c2db6528f706b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2/2 [00:00&lt;00:00,  3.49it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_32655cb92dd142128730713e24816e6b"}},"1f1cc0f7c7794bc7bb666b8b90b975c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"25c6caab5af54773bcb32daa87a14f53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e221dc9a66240df8b8c2db6528f706b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"32655cb92dd142128730713e24816e6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ce1be5bc7df24dd69e6e019056b93a99":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2e5dabed892444349b9ccfc99cf545cf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8b476b7a4652482bb2ed0df03509a385","IPY_MODEL_805457c8396944578096ffc0a0dc8662"]}},"2e5dabed892444349b9ccfc99cf545cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"8b476b7a4652482bb2ed0df03509a385":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6fe5f535bb2946e4b67a8644bb849c50","_dom_classes":[],"description":"Epoch 1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":3644,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3644,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_29e0aff93c5949fbbd402811ecf4ccc8"}},"805457c8396944578096ffc0a0dc8662":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4a8f93e6663640a39bae78f099685876","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3644/3644 [34:10&lt;00:00,  1.78it/s, loss=1.285, v_num=4, start_acc=0.726, end_acc=0.807]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_647163edb75f4e6aaf458566553c0866"}},"6fe5f535bb2946e4b67a8644bb849c50":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"29e0aff93c5949fbbd402811ecf4ccc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4a8f93e6663640a39bae78f099685876":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"647163edb75f4e6aaf458566553c0866":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5853d2a5e47f41e9a8e67612d8c13027":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_91203e965b4f4a1b984355d0c5ad6cd1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ff4b3dfdb99845a48db39ad9f7e69cb0","IPY_MODEL_3790f954fce142deb0f189ee17b48e02"]}},"91203e965b4f4a1b984355d0c5ad6cd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"ff4b3dfdb99845a48db39ad9f7e69cb0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5f8681992d1744f59b5a268c7d2c6308","_dom_classes":[],"description":"Validating: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c34f763be7dd4c6bbd8e44c7a925147e"}},"3790f954fce142deb0f189ee17b48e02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f06582681d0842bcbce54eafefcbfc8e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 183/183 [00:43&lt;00:00,  4.18it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_69cf1ed9b04e4dc9ab64157898bc4b3f"}},"5f8681992d1744f59b5a268c7d2c6308":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c34f763be7dd4c6bbd8e44c7a925147e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f06582681d0842bcbce54eafefcbfc8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"69cf1ed9b04e4dc9ab64157898bc4b3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69c4f35f052f4445becf6d7a3e2aee55":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3c7cb4ebe6be4af890d48272e8960a99","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d9a6c43e65f0435e91de3db89f504745","IPY_MODEL_4efd66acf2344e29b0192f69cf573524"]}},"3c7cb4ebe6be4af890d48272e8960a99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"d9a6c43e65f0435e91de3db89f504745":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a90ec10fd1284bbebc7c1c4ee23c12b6","_dom_classes":[],"description":"Validating: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ffccb92c372b4d1c9153a74dec1ba4f9"}},"4efd66acf2344e29b0192f69cf573524":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bed29e96e6c846488885659d9cefadbb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 183/183 [00:43&lt;00:00,  4.23it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_12ec2c953c174d91adb7862a00a3db59"}},"a90ec10fd1284bbebc7c1c4ee23c12b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ffccb92c372b4d1c9153a74dec1ba4f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bed29e96e6c846488885659d9cefadbb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"12ec2c953c174d91adb7862a00a3db59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"GatZ6ZiXFzVh"},"source":["![image.png](data:image/png;base64,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)"]},{"cell_type":"markdown","metadata":{"id":"goRmGIRI5cfC"},"source":["# ALBERT for Question Answering\n","\n","We are using a tensor model on top of ALBERT for the SQUAD 2.0 dataset\n"]},{"cell_type":"markdown","metadata":{"id":"jKj5lgdr5j48"},"source":["## Setup  \n","First, let's check the GPU we got. If memory < 11GB, I'd suggest to do factory reset runtime. Ideally, try to get 16GB"]},{"cell_type":"code","metadata":{"id":"iesFMrWGTx3Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606484478974,"user_tz":-60,"elapsed":937,"user":{"displayName":"Eduard Duryev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcjI30OA3SfsxpQ0vayQV6Esn1Vymt5WSKQ8tY9A=s64","userId":"07358489747492670025"}},"outputId":"28cc1659-79b0-4ca9-ca1c-6b4ba2019092"},"source":["!nvidia-smi"],"execution_count":39,"outputs":[{"output_type":"stream","text":["Fri Nov 27 13:41:18 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P0    29W / 250W |     10MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yhf9UjQ3okV8"},"source":["Installing all necessary libraries -- Pytorch Lightning, transformers and tensorflow"]},{"cell_type":"code","metadata":{"id":"UGjilEHk4vb7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606477715688,"user_tz":-60,"elapsed":20677,"user":{"displayName":"Eduard Duryev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcjI30OA3SfsxpQ0vayQV6Esn1Vymt5WSKQ8tY9A=s64","userId":"07358489747492670025"}},"outputId":"175ec39c-2065-4566-cf07-3c54a408cbe3"},"source":["%tensorflow_version 1.x\n","!pip install -q pytorch-lightning\n","!pip install -q transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","\u001b[K     |████████████████████████████████| 563kB 6.7MB/s \n","\u001b[K     |████████████████████████████████| 829kB 10.6MB/s \n","\u001b[K     |████████████████████████████████| 276kB 17.7MB/s \n","\u001b[K     |████████████████████████████████| 10.6MB 19.6MB/s \n","\u001b[K     |████████████████████████████████| 92kB 8.9MB/s \n","\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: tensorflow 1.15.2 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 1.15.2 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.4.0 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 1.3MB 6.5MB/s \n","\u001b[K     |████████████████████████████████| 1.1MB 12.2MB/s \n","\u001b[K     |████████████████████████████████| 2.9MB 24.9MB/s \n","\u001b[K     |████████████████████████████████| 890kB 44.7MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"X5omrSOMpRDK"},"source":["Some more importing"]},{"cell_type":"code","metadata":{"id":"orKOA-dmpU1j","executionInfo":{"status":"ok","timestamp":1606485046044,"user_tz":-60,"elapsed":511,"user":{"displayName":"Eduard Duryev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcjI30OA3SfsxpQ0vayQV6Esn1Vymt5WSKQ8tY9A=s64","userId":"07358489747492670025"}}},"source":["import os\n","import pickle, json\n","import numpy as np\n","from tqdm import tqdm, trange\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler, DataLoader, random_split\n","import pytorch_lightning as pl\n","from transformers import AlbertModel, AlbertTokenizer"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S8NuAKW9o7hj"},"source":["## Data download \n","\n","Mount the drive to get access to reading and writing files"]},{"cell_type":"code","metadata":{"id":"C5WA386uEpS8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606480544829,"user_tz":-60,"elapsed":992,"user":{"displayName":"Eduard Duryev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcjI30OA3SfsxpQ0vayQV6Esn1Vymt5WSKQ8tY9A=s64","userId":"07358489747492670025"}},"outputId":"51d671d9-3967-476b-f2a3-0496b9ca1f0d"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","root_dir = \"/content/gdrive/My Drive/\"\n","base_dir = root_dir + 'ybshmmlchk/zatoboj/SQUAD/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yuUwBKpn-TIK"},"source":["#### Loading preprocessed data. For the preprocessing part -- see Albert_Preprocessing.ipynb\n"]},{"cell_type":"code","metadata":{"id":"7dowEmZrEbl_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606480564817,"user_tz":-60,"elapsed":14115,"user":{"displayName":"Eduard Duryev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcjI30OA3SfsxpQ0vayQV6Esn1Vymt5WSKQ8tY9A=s64","userId":"07358489747492670025"}},"outputId":"eb2fa0bc-20ec-4f95-e892-fefceb74e4f3"},"source":["# load train dataset\n","with open(root_dir + 'ybshmmlchk/albert256_train.pickle', 'rb') as f:\n","    train_data = pickle.load(f)\n","    \n","input_ids = train_data[\"input_ids\"]\n","token_type_ids = train_data[\"token_type_ids\"]\n","labels = train_data[\"labels\"]\n","attention_mask = train_data[\"attention_mask\"]\n","answer_mask = train_data['answer_mask']\n","plausible_answer_mask = train_data['plausible_answer_mask']\n","full_answers = train_data['full_answers']\n","full_questions = train_data['full_questions']\n","full_paragraphs = train_data['full_paragraphs']\n","indexing = list(range(0, len(labels)))\n","print('Number of train input ids:'.ljust(30), len(input_ids))\n","# print('Number of train token type ids:'.ljust(30), len(token_type_ids))\n","# print('Number of train labels:'.ljust(30), len(labels))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of input ids:           111281\n","Number of token type ids:      111281\n","Number of labels:              111281\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RaUsGJo-w0Tl","executionInfo":{"status":"ok","timestamp":1606481677223,"user_tz":-60,"elapsed":1121,"user":{"displayName":"Eduard Duryev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcjI30OA3SfsxpQ0vayQV6Esn1Vymt5WSKQ8tY9A=s64","userId":"07358489747492670025"}},"outputId":"ca0b41f3-61e2-4974-cd2a-590586695bfb"},"source":["# load test dataset\n","with open(root_dir + 'ybshmmlchk/albert256_test.pickle', 'rb') as f:\n","    test_data = pickle.load(f)\n","    \n","test_input_ids = test_data[\"input_ids\"]\n","test_token_type_ids = test_data[\"token_type_ids\"]\n","test_labels = test_data[\"labels\"]\n","test_attention_mask = test_data[\"attention_mask\"]\n","test_answer_mask = test_data['answer_mask']\n","test_plausible_answer_mask = test_data['plausible_answer_mask']\n","test_full_answers = test_data['full_answers']\n","test_full_questions = test_data['full_questions']\n","test_full_paragraphs = test_data['full_paragraphs']\n","test_indexing = list(range(0, len(test_labels)))\n","print('Number of input ids:'.ljust(30), len(test_input_ids))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of input ids:           5296\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QoKj1WLzyLEU"},"source":["The fraction of unanswerable questions is about 33%, so about 66% have an answer. The average number of tokens that are in the answer is about 1%. Since the length of our \"sentences\" is 256, the average length of answers is about 3 tokens."]},{"cell_type":"code","metadata":{"id":"P7CfHp4Kyu6k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606480576918,"user_tz":-60,"elapsed":3908,"user":{"displayName":"Eduard Duryev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcjI30OA3SfsxpQ0vayQV6Esn1Vymt5WSKQ8tY9A=s64","userId":"07358489747492670025"}},"outputId":"172a8d5b-bb22-428f-8398-08278dccc71b"},"source":["print('Fraction of unaswerable questions:', np.mean(labels))\n","print('Average fraction of answer tokens in paragraph:',np.array([np.array(x).mean() for x in answer_mask]).mean())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fraction of unaswerable questions: 0.3361939594360223\n","Average fraction of answer tokens in paragraph: 0.011225874700083573\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_gfRvBMctUCD"},"source":["Here is an example of an entry in the dataset. Note that the \"answer\" is a plausible answer, not the actual answer, which is showed by label=True."]},{"cell_type":"code","metadata":{"id":"k8CHPkGNpt5u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606481411745,"user_tz":-60,"elapsed":475,"user":{"displayName":"Eduard Duryev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcjI30OA3SfsxpQ0vayQV6Esn1Vymt5WSKQ8tY9A=s64","userId":"07358489747492670025"}},"outputId":"73bec358-9da3-4ab6-e87e-290259483bb9"},"source":["i = 153\n","print('Input id:', i)\n","print('Question:', full_questions[i])\n","print('Answer:', full_answers[i])\n","print('Paragraph:', full_paragraphs[i])\n","print('Label:', labels[i]) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input id: 153\n","Question: What did the UN Peacebuliding Commission decide on Jan 8, 2008?\n","Answer: the Central African Republic was eligible to receive assistance from the Peacebuilding Fund\n","Paragraph: In 2006, due to ongoing violence, over 50,000 people in the country's northwest were at risk of starvation but this was averted due to assistance from the United Nations.[citation needed] On 8 January 2008, the UN Secretary-General Ban Ki-Moon declared that the Central African Republic was eligible to receive assistance from the Peacebuilding Fund. Three priority areas were identified: first, the reform of the security sector; second, the promotion of good governance and the rule of law; and third, the revitalization of communities affected by conflicts. On 12 June 2008, the Central African Republic requested assistance from the UN Peacebuilding Commission, which was set up in 2005 to help countries emerging from conflict avoid devolving back into war or chaos.\n","Label: True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FAD2cNbt6F1k"},"source":["Helper functions to distinguish actual answers from plausible answers"]},{"cell_type":"code","metadata":{"id":"eBP6FeY18_Ck","colab":{"base_uri":"https://localhost:8080/","height":65,"referenced_widgets":["149a595d3023448d9b0f995eddf29963","f6158dd7e0ab43f7948be01592e728e6","f799f371bb5f4ce99212702625adf1f0","7337b345a02a4c84985d79106ec53800","7ace1c2dbef44feba80f5e3ddc40eb73","19436e4a3cd64b0bb20031b7ac5d631f","bbe9482dbdfa480da8bada78abb83feb","290a3d624a8849108e0e29084e1298ab"]},"executionInfo":{"status":"ok","timestamp":1606480832945,"user_tz":-60,"elapsed":1295,"user":{"displayName":"Eduard Duryev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcjI30OA3SfsxpQ0vayQV6Esn1Vymt5WSKQ8tY9A=s64","userId":"07358489747492670025"}},"outputId":"161cacba-796c-4c9b-da70-a22a350c034d"},"source":["tokenizer = AlbertTokenizer.from_pretrained('albert-base-v1')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"149a595d3023448d9b0f995eddf29963","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760289.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F52r7GUIqwZP"},"source":["# return a tokenized actual answer or None\n","def get_actual_ans(i):\n","  return get_answer(input_ids[i], answer_mask[i])\n","\n","# return a tokenized plausible answer\n","def get_plaus_ans(i):\n","  return get_answer(input_ids[i], plausible_answer_mask[i])\n","\n","# helper function to get an answer\n","def get_answer(input_id, answer):\n","  indices = (np.nonzero(answer)[0]).tolist()\n","  if indices:\n","    tokens = tokenizer.convert_ids_to_tokens(input_id)\n","    return tokens[indices[0]:indices[-1]+1]\n","  else:\n","    return None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EKCOKsO3qyHk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606481513082,"user_tz":-60,"elapsed":861,"user":{"displayName":"Eduard Duryev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcjI30OA3SfsxpQ0vayQV6Esn1Vymt5WSKQ8tY9A=s64","userId":"07358489747492670025"}},"outputId":"c99f0113-5a07-4f5e-ac81-28edfbab72b3"},"source":["i=22\n","print('Input id:',i)\n","print('Plausible answer:'.ljust(27), full_answers[i])\n","print('Tokenized plausible answer:'.ljust(27), get_plaus_ans(i))\n","print('Tokenized actual answer:'.ljust(27), get_actual_ans(i))\n","i=100\n","print('Input id:',i)\n","print('Plausible answer:'.ljust(27), full_answers[i])\n","print('Tokenized plausible answer:'.ljust(27), get_plaus_ans(i))\n","print('Tokenized actual answer:'.ljust(27), get_actual_ans(i))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input id: 22\n","Plausible answer:           1969\n","Tokenized plausible answer: ['▁1969']\n","Tokenized actual answer:    None\n","Input id: 100\n","Plausible answer:           Beautiful Day\n","Tokenized plausible answer: ['▁beautiful', '▁day']\n","Tokenized actual answer:    ['▁beautiful', '▁day']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3F1sf5r59l6e"},"source":["Now we define a function which will return train and validation dataloaders. The breakdown is 95-5."]},{"cell_type":"code","metadata":{"id":"kMdQZUjO-MI7","executionInfo":{"status":"ok","timestamp":1606485027197,"user_tz":-60,"elapsed":601,"user":{"displayName":"Eduard Duryev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcjI30OA3SfsxpQ0vayQV6Esn1Vymt5WSKQ8tY9A=s64","userId":"07358489747492670025"}}},"source":["def generate_squad_dataloaders(batch_size):\n","  # ----------------------\n","  # TRAIN/VAL/TEST DATALOADERS\n","  # ----------------------\n","\n","  # TensorDataset from training examples. \".cuda()\" puts the corresponding tensor on gpu\n","  squad_train_dataset = TensorDataset(torch.tensor(input_ids, dtype=torch.long).cuda(),\n","                                torch.tensor(attention_mask, dtype=torch.long).cuda(),  \n","                                torch.tensor(token_type_ids, dtype=torch.long).cuda(), \n","                                1 - torch.tensor(labels, dtype=torch.long).cuda(), #label is 0 if there is an answer in the original dataset\n","                                torch.tensor(answer_mask, dtype=torch.long).cuda(),\n","                                torch.tensor(indexing, dtype=torch.long).cuda())\n","  \n","  squad_val_dataset = TensorDataset(torch.tensor(test_input_ids, dtype=torch.long).cuda(),\n","                                torch.tensor(test_attention_mask, dtype=torch.long).cuda(),  \n","                                torch.tensor(test_token_type_ids, dtype=torch.long).cuda(), \n","                                1 - torch.tensor(test_labels, dtype=torch.long).cuda(), #label is 0 if there is an answer in the original dataset\n","                                torch.tensor(test_answer_mask, dtype=torch.long).cuda(),\n","                                torch.tensor(test_indexing, dtype=torch.long).cuda())\n","  \n","  # test is not actually used yet\n","  \"\"\"squad_test_dataset = TensorDataset(torch.tensor(input_ids[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(),\n","                                torch.tensor(attention_mask[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(),  \n","                                torch.tensor(token_type_ids[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(), \n","                                1 - torch.tensor(labels[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(), #label is 0 if there is an answer in the original dataset\n","                                torch.tensor(answer_mask[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(),\n","                                torch.tensor(indexing[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda())\"\"\"\n","\n","  print('Train set size:', len(labels))\n","  print('Validation set size:', len(test_labels))\n","\n","  # train loader\n","  train_sampler = RandomSampler(squad_train_dataset)\n","  squad_train_dataloader = DataLoader(squad_train_dataset, sampler = train_sampler, batch_size = batch_size)\n","\n","  # val loader\n","  val_sampler = RandomSampler(squad_val_dataset)\n","  squad_val_dataloader = DataLoader(squad_val_dataset, sampler = val_sampler, batch_size = batch_size, shuffle = False)\n","\n","  # test loader\n","  #test_sampler = RandomSampler(squad_test_dataset)\n","  #squad_test_dataloader = DataLoader(squad_test_dataset, sampler=test_sampler, batch_size = batch_size)\n"," \n","  return squad_train_dataloader, squad_val_dataloader#, squad_test_dataloader"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mvqBwNVaZzh2"},"source":["Defining the model from BERT paper with start and end vector"]},{"cell_type":"code","metadata":{"id":"WNdSQzsnt_io","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["ea234f33db9241dd98535d87e1bd51f1","badd3f050240471292d3b572ad42f44b","d2a2ba74dc3648508d1942e822c7c092","0330aee6e3ce4995a6b801cb7db6b551","c99e34ba05e242dbbcf836d3c192011e","721201448d614400a0bbc2ad51eaf41f","42422a9f2e1d40798e47d70dedb93282","8323ae8442b849918dc4023f2a0c41a4","894862e0a41a4839816df746e1dfbf29","bef181e9e94c4ef589cbdf39746370b5","55b4a41b8a774162b736e86c1dcc1ed4","76e83aac585b4b1088c9b9c53d972348","170a8513359b406e936b70d0c25cb118","c298e55855184448a11e185e934445b0","b3294370f292443c81dcedf9f7105ad2","1b03699a9fd640edbf07d7417ee7671d"]},"executionInfo":{"status":"ok","timestamp":1606485031028,"user_tz":-60,"elapsed":3217,"user":{"displayName":"Eduard Duryev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcjI30OA3SfsxpQ0vayQV6Esn1Vymt5WSKQ8tY9A=s64","userId":"07358489747492670025"}},"outputId":"ddbe5294-42dd-4d36-fe8d-f8e978ac7605"},"source":["bert = AlbertModel.from_pretrained('albert-base-v1', output_attentions=True)"],"execution_count":41,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea234f33db9241dd98535d87e1bd51f1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=684.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"894862e0a41a4839816df746e1dfbf29","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=47376396.0, style=ProgressStyle(descrip…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lIyXj8e5znH7","executionInfo":{"status":"ok","timestamp":1606485035148,"user_tz":-60,"elapsed":577,"user":{"displayName":"Eduard Duryev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcjI30OA3SfsxpQ0vayQV6Esn1Vymt5WSKQ8tY9A=s64","userId":"07358489747492670025"}}},"source":["# returns start and end of the answer. answer_mask is of shape (batch_size, max_len)\n","def get_start_end(answer_mask):\n","    start = torch.argmax(answer_mask, 1, keepdim=False)\n","    end = torch.argmax(answer_mask, 1, keepdim=False) + answer_mask.sum(dim=1) -1\n","    end[end==-1] = 0\n","    return start, end"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"gYY21m6tgCEr","executionInfo":{"status":"ok","timestamp":1606485063657,"user_tz":-60,"elapsed":715,"user":{"displayName":"Eduard Duryev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcjI30OA3SfsxpQ0vayQV6Esn1Vymt5WSKQ8tY9A=s64","userId":"07358489747492670025"}}},"source":["class SQUADBERT(pl.LightningModule):\n","\n","    def __init__(self, batch_size):\n","        super(SQUADBERT, self).__init__()\n","        # initializing BERT, parameters, dataloaders\n","        self.bert = bert.cuda()\n","        self.n = bert.config.hidden_size\n","        self.max_len = 256\n","        self.batch_size = batch_size\n","        self.squad_train_dataloader, self.squad_val_dataloader = generate_squad_dataloaders(self.batch_size)\n","        # initializing additional layers -- start and end vectors\n","        self.Start = nn.Linear(self.n, 1)\n","        self.End = nn.Linear(self.n, 1)\n","\n","    def new_layers(self, q, new_layer):\n","        logits_wrong_shape = new_layer(torch.reshape(q, (q.shape[0]*q.shape[1], q.shape[2])))\n","        logits = torch.reshape(logits_wrong_shape, (q.shape[0], q.shape[1]))\n","        return logits\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        #apply BERT\n","        q, _, attn = self.bert(input_ids=input_ids, \n","                         attention_mask=attention_mask, \n","                         token_type_ids=token_type_ids)\n","        # shape of q will be (batch_size, max_len, bert_dim) = (batch_size, 256, 768)\n","        # take inner products of output vectors with trainable start and end vectors\n","        start_logits = self.new_layers(q, self.Start)\n","        end_logits = self.new_layers(q, self.End)\n","\n","        return start_logits, end_logits\n","\n","    # this is the main function of pl modules. defines architecture and loss function. training loop comes for free -- implemented inside PL\n","    def training_step(self, batch, batch_nb):\n","        # batch\n","        input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","         \n","        # fwd\n","        start_logits, end_logits = self.forward(input_ids, attention_mask, token_type_ids)\n","        \n","        # LOSS\n","        # get start and end positions from answer_mask\n","        start, end = get_start_end(answer_mask)\n","\n","        # compute cross_entropy loss between predictions and actual labels for start and end \n","        loss1 = F.cross_entropy(start_logits, start)\n","        loss2 = F.cross_entropy(end_logits, end)\n","        loss = loss1 + loss2\n","\n","        self.log('loss', loss, prog_bar=True)\n","        # logs\n","        tensorboard_logs = {'train_loss': loss}\n","        return {'loss': loss, 'log': tensorboard_logs}\n","\n","    def validation_step(self, batch, batch_nb):\n","        # batch\n","        input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","\n","        # fwd\n","        start_logits, end_logits = self.forward(input_ids, attention_mask, token_type_ids)\n","\n","        # loss\n","        start, end = get_start_end(answer_mask)\n","\n","        loss1 = F.cross_entropy(start_logits, start)\n","        loss2 = F.cross_entropy(end_logits, end)\n","        loss = loss1 + loss2\n","\n","        # ^^^^ the code above is the same as for training step, but we also add accuracy computation for validation below\n","\n","        # acc\n","        a, y1 = torch.max(start_logits, dim=1)\n","        a, y2 = torch.max(end_logits, dim=1)\n","        \n","        start_acc = torch.sum(y1 == start) / self.batch_size\n","        end_acc = torch.sum(y2 == end) / self.batch_size\n","        self.log('start_acc', start_acc, prog_bar=True)\n","        self.log('end_acc', end_acc, prog_bar=True)\n","        return {'val_loss' : loss, 'start_acc' : start_acc, 'end_acc' : end_acc}\n","\n","    def validation_end(self, outputs):\n","        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n","        start_acc = torch.stack([x['start_acc'] for x in outputs]).mean()\n","        end_acc = torch.stack([x['end_acc'] for x in outputs]).mean()\n","\n","        self.log('validation_loss', avg_loss, prog_bar=True)\n","        self.log('start_accuracy', start_acc, prog_bar=True)\n","        self.log('end_accuracy', end_acc, prog_bar=True)\n","        tensorboard_logs = {'val_loss': avg_loss, 'start_acc' : start_acc, 'end_acc' : end_acc}\n","        return {'avg_val_loss': avg_loss, 'progress_bar': tensorboard_logs}\n","    \n","    def configure_optimizers(self):\n","        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=3e-05, eps=1e-08)\n","\n","    def train_dataloader(self):\n","        return self.squad_train_dataloader\n","\n","    def val_dataloader(self):\n","        return self.squad_val_dataloader\n"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nIDLP9hJ-MXx","executionInfo":{"status":"ok","timestamp":1606485096576,"user_tz":-60,"elapsed":12491,"user":{"displayName":"Eduard Duryev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcjI30OA3SfsxpQ0vayQV6Esn1Vymt5WSKQ8tY9A=s64","userId":"07358489747492670025"}},"outputId":"cb9d002c-a929-4333-e8e4-e47a2d35d005"},"source":["model = SQUADBERT(32)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Train set size: 111281\n","Validation set size: 5296\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10LwGXPC-Rad","executionInfo":{"status":"ok","timestamp":1606485856971,"user_tz":-60,"elapsed":858,"user":{"displayName":"Eduard Duryev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcjI30OA3SfsxpQ0vayQV6Esn1Vymt5WSKQ8tY9A=s64","userId":"07358489747492670025"}},"outputId":"7e67653a-1759-4485-9785-947b1abee149"},"source":["list(dict(bert.named_parameters()).keys())"],"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['embeddings.word_embeddings.weight',\n"," 'embeddings.position_embeddings.weight',\n"," 'embeddings.token_type_embeddings.weight',\n"," 'embeddings.LayerNorm.weight',\n"," 'embeddings.LayerNorm.bias',\n"," 'encoder.embedding_hidden_mapping_in.weight',\n"," 'encoder.embedding_hidden_mapping_in.bias',\n"," 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight',\n"," 'encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias',\n"," 'encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight',\n"," 'encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias',\n"," 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight',\n"," 'encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias',\n"," 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight',\n"," 'encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias',\n"," 'encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight',\n"," 'encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias',\n"," 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight',\n"," 'encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias',\n"," 'encoder.albert_layer_groups.0.albert_layers.0.ffn.weight',\n"," 'encoder.albert_layer_groups.0.albert_layers.0.ffn.bias',\n"," 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight',\n"," 'encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias',\n"," 'pooler.weight',\n"," 'pooler.bias']"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"markdown","metadata":{"id":"FHt8tgwa_DcM"},"source":["### Trainer\n","The trainer takes care of putting things in the correct GPU or not.\n","It handles all the engineering for you (such as automatic early stopping) so you just have to worry about the model and data!"]},{"cell_type":"code","metadata":{"id":"gMRMJ-Kd-oup","colab":{"base_uri":"https://localhost:8080/","height":511,"referenced_widgets":["cfb5ba1021b443ce9dcfc4a52cb474cd","bd9aede04406425da1be8f0aa8658462","1f5ed92db00f4c77a5052e9855d10655","694dfeaa88be4ee4962a3a409b8c161d","1f1cc0f7c7794bc7bb666b8b90b975c0","25c6caab5af54773bcb32daa87a14f53","2e221dc9a66240df8b8c2db6528f706b","32655cb92dd142128730713e24816e6b","ce1be5bc7df24dd69e6e019056b93a99","2e5dabed892444349b9ccfc99cf545cf","8b476b7a4652482bb2ed0df03509a385","805457c8396944578096ffc0a0dc8662","6fe5f535bb2946e4b67a8644bb849c50","29e0aff93c5949fbbd402811ecf4ccc8","4a8f93e6663640a39bae78f099685876","647163edb75f4e6aaf458566553c0866","5853d2a5e47f41e9a8e67612d8c13027","91203e965b4f4a1b984355d0c5ad6cd1","ff4b3dfdb99845a48db39ad9f7e69cb0","3790f954fce142deb0f189ee17b48e02","5f8681992d1744f59b5a268c7d2c6308","c34f763be7dd4c6bbd8e44c7a925147e","f06582681d0842bcbce54eafefcbfc8e","69cf1ed9b04e4dc9ab64157898bc4b3f","69c4f35f052f4445becf6d7a3e2aee55","3c7cb4ebe6be4af890d48272e8960a99","d9a6c43e65f0435e91de3db89f504745","4efd66acf2344e29b0192f69cf573524","a90ec10fd1284bbebc7c1c4ee23c12b6","ffccb92c372b4d1c9153a74dec1ba4f9","bed29e96e6c846488885659d9cefadbb","12ec2c953c174d91adb7862a00a3db59"]},"executionInfo":{"status":"ok","timestamp":1606143514653,"user_tz":-180,"elapsed":4124535,"user":{"displayName":"Za Toboj Pridet Transformer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4qcZtPaf6WD1pffjH9pOzJ-4kvXWntAFP3dc8=s64","userId":"00040326239993683564"}},"outputId":"b2d8322c-cf67-4309-b38e-8bf865a28b64"},"source":["torch.set_default_tensor_type('torch.cuda.FloatTensor')\n","bert_finetuner = SQUADBERT(32)\n","pl.Trainer()\n","# most basic trainer, uses good defaults (1 gpu)\n","trainer = pl.Trainer(gpus=1, amp_level='O2',precision=16, max_epochs = 2)#, val_check_interval=0.25)#checkpoint_callback=checkpoint_callback, max_nb_epochs = 2val_check_interval=1,)    \n","trainer.fit(bert_finetuner) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["GPU available: True, used: False\n","TPU available: False, using: 0 TPU cores\n","/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n","  warnings.warn(*args, **kwargs)\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Using native 16bit precision.\n","\n","  | Name  | Type        | Params\n","--------------------------------------\n","0 | bert  | AlbertModel | 11 M  \n","1 | Start | Linear      | 769   \n","2 | End   | Linear      | 769   \n"],"name":"stderr"},{"output_type":"stream","text":["train, validation size --  110748 5829\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for validation and test dataloaders.\n","  warnings.warn(*args, **kwargs)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cfb5ba1021b443ce9dcfc4a52cb474cd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce1be5bc7df24dd69e6e019056b93a99","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n","Please use self.log(...) inside the lightningModule instead.\n","\n","# log on a step or aggregate epoch metric to the logger and/or progress bar\n","# (inside LightningModule)\n","self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n","  warnings.warn(*args, **kwargs)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5853d2a5e47f41e9a8e67612d8c13027","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69c4f35f052f4445becf6d7a3e2aee55","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"t8XvjuyPWmAv"},"source":["**Saving**"]},{"cell_type":"code","metadata":{"id":"aFKxVdIyWut9"},"source":["model_name = '2epochs_base_albert'\n","trainer.save_checkpoint(base_dir + 'saved_models/' + model_name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v-oJLdeFW2f6"},"source":["**Loading**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ZeKyNlkW7dm","executionInfo":{"status":"ok","timestamp":1606406388403,"user_tz":-180,"elapsed":15113,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"f86988d8-d7cf-4a4e-e47e-5b532e168db4"},"source":["torch.set_default_tensor_type('torch.cuda.FloatTensor')\n","model = SQUADBERT(16)\n","model_name = '2epochs_base_albert'\n","checkpoint = torch.load(base_dir + 'saved_models/' + model_name, map_location=lambda storage, loc: storage)\n","model.load_state_dict(checkpoint['state_dict'])\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train, validation size --  110748 5829\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SQUADBERT(\n","  (bert): AlbertModel(\n","    (embeddings): AlbertEmbeddings(\n","      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): AlbertTransformer(\n","      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n","      (albert_layer_groups): ModuleList(\n","        (0): AlbertLayerGroup(\n","          (albert_layers): ModuleList(\n","            (0): AlbertLayer(\n","              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (attention): AlbertAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (attention_dropout): Dropout(p=0.1, inplace=False)\n","                (output_dropout): Dropout(p=0.1, inplace=False)\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              )\n","              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n","              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (pooler): Linear(in_features=768, out_features=768, bias=True)\n","    (pooler_activation): Tanh()\n","  )\n","  (Start): Linear(in_features=768, out_features=1, bias=True)\n","  (End): Linear(in_features=768, out_features=1, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"s9A5HGrcX5kk"},"source":["**Results on validation**"]},{"cell_type":"markdown","metadata":{"id":"qrOCKwm8YIeA"},"source":["Helper functions"]},{"cell_type":"code","metadata":{"id":"2XPQPLHxYCeP"},"source":["#returns \"probabilities\" of start and end. not actually probabilities, because this is before softmax\n","def predict(model, batch):\n","  input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","  return model(input_ids, attention_mask, token_type_ids)\n","\n","# returns start and end vectors, just based on argmax taken individually\n","def convert_predictions(l1, l2):#, label, answer_mask):\n","  a, y1 = torch.max(l1, dim=1)\n","  a, y2 = torch.max(l2, dim=1)\n","  \n","  return y1, y2#, guess1, guess2, d_pre, d_post\n","\n","# returns start and end vectors taking into account that end>=start + start can't be before question end\n","def convert_predictions_improved(l1, l2, min_start):\n","  starts, ends = [], []\n","  for i in range(l1.shape[0]):\n","    p1, p2 = l1[i], l2[i]\n","    highest_prob = p1[0] + p2[0]\n","    start, end = 0, 0\n","    for k in range(min_start[i], 256):\n","      for j in range(k, 256):\n","        if p1[k] + p2[j] > highest_prob:\n","          highest_prob, start, end = p1[k] + p2[j], k, j\n","    starts.append(start)\n","    ends.append(end)\n","  return torch.Tensor(starts), torch.Tensor(ends)\n","\n","def npf(tt):\n","  return tt.detach().cpu().numpy()\n","\n","def convert_predictions_improved_v3(start_batch, end_batch, min_start=None):\n","  start_batch, end_batch, min_start = npf(start_batch), npf(end_batch), npf(min_start)\n","  #start_batch, end_batch = npf(start_batch), npf(end_batch)\n","  batch_size, max_len = start_batch.shape\n","  probs = start_batch.reshape(-1,max_len,1) + end_batch.reshape(-1,1,max_len) # array of shape: (batch_size, max_len, max_len), matrix of pairwise sums per each element of the batch\n","  if min_start is not None:\n","    mask = np.zeros(probs.shape)  # create a mask to avoid including cases where i > j or i > min_start or j > min_start\n","    for i,s in enumerate(min_start):\n","        mask[i,:s,:] = 1\n","        mask[i,:,:s] = 1\n","        mask[i][np.tril_indices(max_len,-1)] = 1\n","    mask[:,0,0] = 0               # we however leave i=j=0 to detect questions without answers\n","    probs = np.ma.array(probs,mask=mask)\n","    probs = np.ma.filled(probs,-np.inf)\n","  else:\n","    probs = np.triu(probs)\n","  max_probs = np.argmax(probs.reshape(batch_size,-1), axis=-1) # array of shape: (batch_size,), argmaxes of flattened matrices of pairwise sums\n","  starts, ends = np.unravel_index(max_probs, (max_len, max_len)) # two arrays of shape: (batch_size,), 'unflattenning' of max_probs\n","  return starts, ends"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3x7xlrxYYLMQ"},"source":["Validation itself"]},{"cell_type":"code","metadata":{"id":"-l-y4jPtYNQD"},"source":["from pprint import pprint\n","def validate(model):\n","  #iterator \n","  a = (model.val_dataloader())\n","  #batch = True\n","  d = {\n","        'num_examples' : 0,\n","        'num_starts_guessed' : 0,\n","        'num_ends_guessed' : 0,\n","        'num_exact_matches_guessed' : 0,\n","        'num_starts_guessed_post' : 0,\n","        'num_ends_guessed_post' : 0,\n","        'num_exact_matches_guessed_post' : 0\n","      }\n","  for batch_ndx, batch in enumerate(a):\n","    #batch = iterator.next()\n","    l1, l2 = predict(model, batch)\n","    y1, y2 = convert_predictions(l1, l2)\n","    input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","    start, end = get_start_end(answer_mask)\n","    d['num_examples'] += start.shape[0]\n","    d['num_starts_guessed'] += torch.sum(start==y1)\n","    d['num_ends_guessed'] += torch.sum(end==y2)\n","    d['num_exact_matches_guessed'] += torch.sum(((start==y1).double()  + (end==y2).double() )==2.)\n","    _ , min_start = torch.max(token_type_ids, dim=1)\n","    \n","    y1, y2 = convert_predictions_improved_v3(l1, l2, min_start)\n","    #input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","    start, end = npf(start), npf(end)\n","    d['num_starts_guessed_post'] += np.sum(start==y1)\n","    d['num_ends_guessed_post'] += np.sum(end==y2)\n","    d['num_exact_matches_guessed_post'] += np.sum(((start==y1).astype(int)  + (end==y2).astype(int) )==2)\n","\n","    d['EM'] = d['num_exact_matches_guessed'] / d['num_examples']\n","    d['EM post'] = d['num_exact_matches_guessed_post'] / d['num_examples']\n","    if batch_ndx%300 == 0:\n","      print(batch_ndx)\n","      pprint(d)\n","  return d\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XEjNzdZ2YVQb","executionInfo":{"status":"ok","timestamp":1606406472100,"user_tz":-180,"elapsed":54505,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"fd7309bd-6f65-4d16-9e47-7bea6e4b6417"},"source":["validate(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n","{'EM': tensor(0.6250),\n"," 'EM post': 0.625,\n"," 'num_ends_guessed': tensor(11),\n"," 'num_ends_guessed_post': 11,\n"," 'num_exact_matches_guessed': tensor(10),\n"," 'num_exact_matches_guessed_post': 10,\n"," 'num_examples': 16,\n"," 'num_starts_guessed': tensor(11),\n"," 'num_starts_guessed_post': 11}\n","300\n","{'EM': tensor(0.6869),\n"," 'EM post': 0.696843853820598,\n"," 'num_ends_guessed': tensor(3897),\n"," 'num_ends_guessed_post': 3895,\n"," 'num_exact_matches_guessed': tensor(3308),\n"," 'num_exact_matches_guessed_post': 3356,\n"," 'num_examples': 4816,\n"," 'num_starts_guessed': tensor(3496),\n"," 'num_starts_guessed_post': 3490}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'EM': tensor(0.6874),\n"," 'EM post': 0.6973751930005146,\n"," 'num_ends_guessed': tensor(4709),\n"," 'num_ends_guessed_post': 4709,\n"," 'num_exact_matches_guessed': tensor(4007),\n"," 'num_exact_matches_guessed_post': 4065,\n"," 'num_examples': 5829,\n"," 'num_starts_guessed': tensor(4235),\n"," 'num_starts_guessed_post': 4228}"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"aM7ujFALyPtH"},"source":["**THIS IS THE END OF TRAINING CODE. THE CODE BELOW HASN'T BEEN REVIEWED/REWRITTEN**\n"]},{"cell_type":"code","metadata":{"id":"DVWuTQ570bpy","colab":{"base_uri":"https://localhost:8080/","height":745},"outputId":"94196fca-1f79-43ee-fa96-393afdc08da3"},"source":["bert_finetuner"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SQUADBERT(\n","  (bert): AlbertModel(\n","    (embeddings): AlbertEmbeddings(\n","      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): AlbertTransformer(\n","      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n","      (albert_layer_groups): ModuleList(\n","        (0): AlbertLayerGroup(\n","          (albert_layers): ModuleList(\n","            (0): AlbertLayer(\n","              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (attention): AlbertAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              )\n","              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n","              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (pooler): Linear(in_features=768, out_features=768, bias=True)\n","    (pooler_activation): Tanh()\n","  )\n","  (A1): Linear(in_features=768, out_features=100, bias=True)\n","  (B1): Linear(in_features=768, out_features=100, bias=True)\n","  (LG1): Linear(in_features=10, out_features=2, bias=True)\n","  (A2): Linear(in_features=768, out_features=100, bias=True)\n","  (B2): Linear(in_features=768, out_features=100, bias=True)\n","  (LG2): Linear(in_features=10, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"bNR0ipTe0b1-"},"source":["def get_random_batch(model):\n","  iterator = iter(model.val_dataloader())\n","  batch = iterator.next()\n","  #for i in batch:\n","  #  i = i.to(torch.device('cuda',0))\n","  return (batch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3I-AErsq1F7t"},"source":["def predict(model, batch):\n","  input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","  return model(input_ids, attention_mask, token_type_ids)\n","\n","def convert_predictions(l1, l2, label, answer_mask):\n","  a, y1 = torch.max(l1, dim=1)\n","  a, y2 = torch.max(l2, dim=2)\n","  guess1, guess2 = final_guess(l1, l2)\n","  \"\"\"if self.counter < 10:\n","    self.counter += 1\n","    self.dic_1[self.counter] = [l2, y2]\"\"\"\n","  d_pre = results_dic(y1, y2, label, answer_mask)\n","  d_post = results_dic(guess1, guess2, label, answer_mask)\n","  return y1, y2, guess1, guess2, d_pre, d_post"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AuwZv_Ng1GED"},"source":["batch =  get_random_batch(new_model)#(bert_finetuner)\n","input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","l1, l2 = predict(new_model, batch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zopOdSYalAgt","colab":{"base_uri":"https://localhost:8080/","height":87},"outputId":"3b721249-e3bf-4f35-cb3e-6b4462827b94"},"source":["print(indexing)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([  1709,  50257,  28607,  85809,  18089,  43168, 109889, 114528,  36480,\n","        105855,  90441,  58618,  93205, 103048,  66757,  74668,   6850,  47620,\n","         88623,  44466,  21506, 101689,  32743,  40006,  49163, 112892,  74904,\n","         62193,  44188,  93296, 116388,  26653])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZARZmoMN0b_R"},"source":["y1, y2, guess1, guess2, d1, d2 = convert_predictions(l1, l2, label, answer_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ck-huWF-SYW","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"1d14eff0-689b-41d2-d751-9fdf01f18b1e"},"source":["print(y1)\n","print(guess1.type(torch.IntTensor))\n","print(label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n","        1, 1, 1, 1, 0, 1, 1, 0])\n","tensor([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n","        1, 1, 1, 1, 0, 1, 1, 0], device='cpu', dtype=torch.int32)\n","tensor([0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n","        1, 1, 1, 0, 0, 1, 1, 0])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LCaGo_h8Uvn1","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"bce5ca45-cf14-49ff-99d7-63b2381238f1"},"source":["print(y1)\n","print(guess1.type(torch.IntTensor))\n","print(label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n","        1, 0, 0, 1, 1, 0, 1, 1])\n","tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n","        1, 0, 1, 1, 1, 0, 1, 1], device='cpu', dtype=torch.int32)\n","tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n","        1, 0, 1, 1, 1, 0, 1, 1])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bAJG51UM-A5d","colab":{"base_uri":"https://localhost:8080/","height":834},"outputId":"6fb66077-5a43-4839-90d5-4137d729b006"},"source":["i = 10\n","print(y2[i])\n","print(guess2[i].type(torch.IntTensor))\n","print(answer_mask[i])\n","index = indexing[i].item()\n","print(torch.IntTensor(plausible_answer_mask[index]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cpu',\n","       dtype=torch.int32)\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cpu',\n","       dtype=torch.int32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LnoqxsIM_xwM","colab":{"base_uri":"https://localhost:8080/","height":161},"outputId":"d8198c69-5829-417e-d9b8-8537bf94ffad"},"source":["print(get_answer(input_ids[i], answer_mask[i]))\n","\n","print(get_answer(input_ids[i], guess2[i]))\n","index = indexing[i].item()\n","print(index)\n","print(full_answers[index])\n","print(full_questions[index])\n","print(full_paragraphs[index])\n","print(get_answer(input_ids[i], torch.Tensor(plausible_answer_mask[index])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['▁arab']\n","None\n","90441\n","Arab\n","What race was the majority in Palestine in the 1940s?\n","The British Mandate of Palestine, where an Arab majority lived alongside a Jewish minority, presented the British with a similar problem to that of India. The matter was complicated by large numbers of Jewish refugees seeking to be admitted to Palestine following the Holocaust, while Arabs were opposed to the creation of a Jewish state. Frustrated by the intractability of the problem, attacks by Jewish paramilitary organisations and the increasing cost of maintaining its military presence, Britain announced in 1947 that it would withdraw in 1948 and leave the matter to the United Nations to solve. The UN General Assembly subsequently voted for a plan to partition Palestine into a Jewish and an Arab state.\n","['▁arab']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I2J50MNEAhOQ"},"source":["def get_answer(input_id, answer):\n","  indices = (numpy.nonzero(answer)).tolist()\n","  #print(indices)\n","  #  indices.append(l[0])\n","  if indices:\n","    tokens = tokenizer.convert_ids_to_tokens(input_id)\n","    return tokens[indices[0][0]:indices[-1][0]+1]\n","  else:\n","    return None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WB9GOlzXld7M"},"source":["def get_probabilities_individual(l, answer):\n","  indices = (numpy.nonzero(answer)).tolist()\n","  if indices:\n","    res = l[indices[0][0]:indices[-1][0]+1]\n","    return res[:,1] - res[:,0]\n","  else:\n","    return None\n","\n","def get_probability_label(l):\n","  return l[1] - l[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oVEDXob-l4fm","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"d1abef62-8ddb-4575-8975-69a8cec86a01"},"source":["print(get_probabilities_individual(l2[i], guess2[i]))\n","print(get_probability_label(l1[i]))\n","print(guess1[i] - label[i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["None\n","tensor(-0.8393, grad_fn=<SubBackward0>)\n","tensor(-1.)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"55yY-rZ6Dr3A"},"source":["def get_wrong_guesses(guesses, lbls):\n","  wrong_guesses = []\n","  for x in (guesses - lbls).nonzero().cpu().numpy().tolist():\n","    wrong_guesses.append(x[0])\n","  return wrong_guesses"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ThmCMhScEqBY","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"52664d18-6788-467e-d927-924858fb8b95"},"source":["wrong_guesses = get_wrong_guesses(y1, label)\n","print(wrong_guesses)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[10, 26]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fhV42t3I0KOw","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"248107bd-b38a-413f-ab51-f378f979daad"},"source":["i = 26\n","print(get_probabilities_individual(l2[i], guess2[i]))\n","print(get_probabilities_individual(l2[i], answer_mask[i]))\n","index = indexing[i].item()\n","print(get_probabilities_individual(l2[i], torch.Tensor(plausible_answer_mask[index])))\n","print(get_probability_label(l1[i]))\n","#print(guess1[i] - label[i])\n","print(guess1[i], label[i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([3.1200, 2.9809, 2.7662, 3.3491, 0.1146, 0.0939, 0.4229],\n","       grad_fn=<SubBackward0>)\n","tensor([3.1200, 2.9809, 2.7662, 3.3491], grad_fn=<SubBackward0>)\n","tensor([3.1200, 2.9809, 2.7662, 3.3491], grad_fn=<SubBackward0>)\n","tensor(-0.6872, grad_fn=<SubBackward0>)\n","tensor(1.) tensor(1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zVbJ_YSXlq6X","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b62e26cd-1418-4907-f85f-fa6a5ce421d1"},"source":["l1.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 2])"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"0s8xPk_s8SLd","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"dfaf627e-e448-4348-863c-025de107bd2b"},"source":["d1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answerable_actual': tensor(0.5625),\n"," 'answerable_result': tensor(0.5625),\n"," 'guessed_answerable': tensor(0.4375),\n"," 'guessed_ones': tensor(0.0115),\n"," 'ones_percentage_actual': tensor(0.0122),\n"," 'ones_percentage_guessed': tensor(0.0454),\n"," 'val_acc_individual': tensor(0.9653),\n"," 'val_acc_labels': tensor(0.7500)}"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"tHx6EqxVU30Q","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"241f371d-734a-4df7-b582-29a6cdcd24fb"},"source":["d1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answerable_actual': tensor(0.5625),\n"," 'answerable_result': tensor(0.5625),\n"," 'guessed_answerable': tensor(0.4375),\n"," 'guessed_ones': tensor(0.0115),\n"," 'ones_percentage_actual': tensor(0.0122),\n"," 'ones_percentage_guessed': tensor(0.0454),\n"," 'val_acc_individual': tensor(0.9653),\n"," 'val_acc_labels': tensor(0.7500)}"]},"metadata":{"tags":[]},"execution_count":147}]},{"cell_type":"code","metadata":{"id":"NAND2ZW88XMd","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"ec84b873-39db-4ada-952e-ab03073eebc9"},"source":["d2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answerable_actual': tensor(0.5625),\n"," 'answerable_result': tensor(0.5625),\n"," 'guessed_answerable': tensor(0.4375),\n"," 'guessed_ones': tensor(0.0112),\n"," 'ones_percentage_actual': tensor(0.0122),\n"," 'ones_percentage_guessed': tensor(0.0270),\n"," 'val_acc_individual': tensor(0.9833),\n"," 'val_acc_labels': tensor(0.7500)}"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"lVqPQ8u3VJ5t","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"711895e1-6ef7-4527-d4e5-54fe9caea34a"},"source":["d2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answerable_actual': tensor(0.5625),\n"," 'answerable_result': tensor(0.6875),\n"," 'guessed_answerable': tensor(0.5312),\n"," 'guessed_ones': tensor(0.0112),\n"," 'ones_percentage_actual': tensor(0.0122),\n"," 'ones_percentage_guessed': tensor(0.0270),\n"," 'val_acc_individual': tensor(0.9833),\n"," 'val_acc_labels': tensor(0.8125)}"]},"metadata":{"tags":[]},"execution_count":148}]},{"cell_type":"markdown","metadata":{"id":"tcrUfpD0X6nF"},"source":["##Saving"]},{"cell_type":"code","metadata":{"id":"T8i5psJPYCRY","colab":{"base_uri":"https://localhost:8080/","height":292},"outputId":"63fb2a35-ab66-43a4-8771-180c121a9b8a"},"source":["#bert_finetuner.save_checkpoint(base_dir + './saved_models_albert')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-152-22c3859db120>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_finetuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'./saved_models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'SQUADBERT' object has no attribute 'save_checkpoint'"]}]},{"cell_type":"code","metadata":{"id":"x6NEGHMBZGze"},"source":["#bert_finetuner."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bepR4KwgZyIo"},"source":["trainer.save_checkpoint(base_dir + 'saved_models/new')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LlBeUTTJYCaz","colab":{"base_uri":"https://localhost:8080/","height":316},"outputId":"e0b1b7b9-8ef0-4956-e957-0bc72b7ab90f"},"source":["#input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","#ll1, ll2 = predict(new_model, batch)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-175-e88a2b27191f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mll1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-144-abd96af2e684>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-cd8f6805240c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m    108\u001b[0m         q, _, attn = self.bert(input_ids=input_ids, \n\u001b[1;32m    109\u001b[0m                          \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                          token_type_ids=token_type_ids)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mq_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         )\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                 \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_idx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers_per_group\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgroup_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers_per_group\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m             )\n\u001b[1;32m    346\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_group_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malbert_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malbert_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mprojected_context_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bfnd,ndh->bfh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mprojected_context_layer_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojected_context_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mlayernormed_context_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprojected_context_layer_dropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayernormed_context_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_probs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_attentions\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayernormed_context_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 15.90 GiB total capacity; 15.14 GiB already allocated; 11.81 MiB free; 15.19 GiB reserved in total by PyTorch)"]}]},{"cell_type":"code","metadata":{"id":"rZew7826YCi3","colab":{"base_uri":"https://localhost:8080/","height":781},"outputId":"c2a72ba1-d41e-4678-fc60-c66c13b89bb8"},"source":["torch.set_default_tensor_type('torch.cuda.FloatTensor')\n","new_model = SQUADBERT({\"d1\": 10, 'l1' : 10, 'd2' : 10, 'l2' : 10}, batch_size = 32, weight = 20.)\n","#new_model = SQUADBERT.load_from_checkpoint(base_dir + 'saved_models/new')\n","checkpoint = torch.load(base_dir + 'saved_models/new', map_location=lambda storage, loc: storage)\n","new_model.load_state_dict(checkpoint['state_dict'])\n","new_model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train, validation, test --  114245 1166 1166\n","NEW\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SQUADBERT(\n","  (bert): AlbertModel(\n","    (embeddings): AlbertEmbeddings(\n","      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): AlbertTransformer(\n","      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n","      (albert_layer_groups): ModuleList(\n","        (0): AlbertLayerGroup(\n","          (albert_layers): ModuleList(\n","            (0): AlbertLayer(\n","              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (attention): AlbertAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              )\n","              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n","              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (pooler): Linear(in_features=768, out_features=768, bias=True)\n","    (pooler_activation): Tanh()\n","  )\n","  (A1): Linear(in_features=768, out_features=100, bias=True)\n","  (B1): Linear(in_features=768, out_features=100, bias=True)\n","  (LG1): Linear(in_features=10, out_features=2, bias=True)\n","  (A2): Linear(in_features=768, out_features=100, bias=True)\n","  (B2): Linear(in_features=768, out_features=100, bias=True)\n","  (LG2): Linear(in_features=10, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"PXiE35_AlMrg"},"source":["def predicte(model, batch):\n","  input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","  #input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = input_ids.cpu(), attention_mask.cpu(), token_type_ids.cpu(), label.cpu(), answer_mask.cpu(), indexing.cpu()\n","  return model(input_ids, attention_mask, token_type_ids)\n","\n","def convert_predictions(l1, l2, label, answer_mask):\n","  a, y1 = torch.max(l1, dim=1)\n","  a, y2 = torch.max(l2, dim=2)\n","  guess1, guess2 = final_guess(l1, l2)\n","  \"\"\"if self.counter < 10:\n","    self.counter += 1\n","    self.dic_1[self.counter] = [l2, y2]\"\"\"\n","  d_pre = results_dic(y1, y2, label, answer_mask)\n","  d_post = results_dic(guess1, guess2, label, answer_mask)\n","  return y1, y2, guess1, guess2, d_pre, d_post"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGMkfO5TZux6"},"source":["test = torch.tensor(input_ids[153:155], dtype=torch.long).cuda(), torch.tensor(attention_mask[153:155], dtype=torch.long).cuda(), torch.tensor(token_type_ids[153:155], dtype=torch.long).cuda()\n","#                               1 - torch.tensor(labels, dtype=torch.long).cuda(), #label is 0 if there is an answer in the original dataset\n","#                                torch.tensor(answer_mask, dtype=torch.long).cuda(),\n","#                                torch.tensor(indexing, dtype=torch.long).cuda())\n","test_input_ids, test_attention_mask, test_token_type_ids = test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MzZlA05zab7s"},"source":["l1, l2 = bert_finetuner(test_input_ids, test_attention_mask, test_token_type_ids)\n","#v1, v2 = bert_finetuner(test_input_ids, test_attention_mask, test_token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z2GcGa67YCq1"},"source":["\"\"\"model = SQUADBERT('ProjectionModuleLong', {\"d1\": 8, 'l1' : 20, 'd2' : 8, 'l2' : 40}, batch_size = 32, weight = 60.)\n","checkpoint = torch.load(base_dir + \"/Checkpoints/_ckpt_epoch_2.ckpt\", map_location=lambda storage, loc: storage)\n","model.load_state_dict(checkpoint['state_dict'])\"\"\"\n","ll1, ll2 = new_model(test_input_ids, test_attention_mask, test_token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_7x4aQIxczUE","colab":{"base_uri":"https://localhost:8080/","height":283},"outputId":"135c322a-edfd-442a-fad6-62736fc6fe87"},"source":["l2-ll2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0., 0.],\n","         [0., 0.],\n","         [0., 0.],\n","         ...,\n","         [0., 0.],\n","         [0., 0.],\n","         [0., 0.]],\n","\n","        [[0., 0.],\n","         [0., 0.],\n","         [0., 0.],\n","         ...,\n","         [0., 0.],\n","         [0., 0.],\n","         [0., 0.]]], grad_fn=<SubBackward0>)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"kojxrYbPdO7f"},"source":["l1, _, l2 = bert_finetuner.bert(input_ids=test_input_ids, \n","                         attention_mask=test_attention_mask, \n","                         token_type_ids=test_token_type_ids)\n","ll1, _, ll2 = new_model.bert(input_ids=test_input_ids, \n","                         attention_mask=test_attention_mask, \n","                         token_type_ids=test_token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v10uVLUDn4e5"},"source":["lll1, _, lll2 = berty.cuda()(input_ids=test_input_ids, \n","                         attention_mask=test_attention_mask, \n","                         token_type_ids=test_token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oXZTvY3is0GN"},"source":["berty = AlbertModel.from_pretrained('albert-base-v1', output_attentions=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICb2xAhYs-ep"},"source":["berty = berty.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ve5EFiTp2saa","colab":{"base_uri":"https://localhost:8080/","height":692},"outputId":"3cc4576d-215e-4bd4-cb52-196a27d7c5db"},"source":["print(\"Model's state_dict:\")\n","for param_tensor in bert_finetuner.state_dict():\n","    print(param_tensor, \"\\t\", bert_finetuner.state_dict()[param_tensor].size())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model's state_dict:\n","bert.embeddings.word_embeddings.weight \t torch.Size([30000, 128])\n","bert.embeddings.position_embeddings.weight \t torch.Size([512, 128])\n","bert.embeddings.token_type_embeddings.weight \t torch.Size([2, 128])\n","bert.embeddings.LayerNorm.weight \t torch.Size([128])\n","bert.embeddings.LayerNorm.bias \t torch.Size([128])\n","bert.encoder.embedding_hidden_mapping_in.weight \t torch.Size([768, 128])\n","bert.encoder.embedding_hidden_mapping_in.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight \t torch.Size([3072, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias \t torch.Size([3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight \t torch.Size([768, 3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias \t torch.Size([768])\n","bert.pooler.weight \t torch.Size([768, 768])\n","bert.pooler.bias \t torch.Size([768])\n","A1.weight \t torch.Size([100, 768])\n","A1.bias \t torch.Size([100])\n","B1.weight \t torch.Size([100, 768])\n","B1.bias \t torch.Size([100])\n","LG1.weight \t torch.Size([2, 10])\n","LG1.bias \t torch.Size([2])\n","A2.weight \t torch.Size([100, 768])\n","A2.bias \t torch.Size([100])\n","B2.weight \t torch.Size([100, 768])\n","B2.bias \t torch.Size([100])\n","LG2.weight \t torch.Size([2, 10])\n","LG2.bias \t torch.Size([2])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WVc-MsFieptn","colab":{"base_uri":"https://localhost:8080/","height":478},"outputId":"6f3c7fb0-7462-4a46-f6f6-f5e0d6a19dfe"},"source":["print(\"Model's state_dict:\")\n","for param_tensor in bert_finetuner.state_dict():\n","    print(param_tensor, \"\\t\", bert_finetuner.state_dict()[param_tensor].size())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model's state_dict:\n","bert.embeddings.word_embeddings.weight \t torch.Size([30000, 128])\n","bert.embeddings.position_embeddings.weight \t torch.Size([512, 128])\n","bert.embeddings.token_type_embeddings.weight \t torch.Size([2, 128])\n","bert.embeddings.LayerNorm.weight \t torch.Size([128])\n","bert.embeddings.LayerNorm.bias \t torch.Size([128])\n","bert.encoder.embedding_hidden_mapping_in.weight \t torch.Size([768, 128])\n","bert.encoder.embedding_hidden_mapping_in.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight \t torch.Size([3072, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias \t torch.Size([3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight \t torch.Size([768, 3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias \t torch.Size([768])\n","bert.pooler.weight \t torch.Size([768, 768])\n","bert.pooler.bias \t torch.Size([768])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mUD0IG1xftWz","colab":{"base_uri":"https://localhost:8080/","height":478},"outputId":"3de4effe-1893-4312-87cc-485b0d520833"},"source":["print(\"Model's state_dict:\")\n","for param_tensor in new_model.state_dict():\n","    print(param_tensor, \"\\t\", new_model.state_dict()[param_tensor].size())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model's state_dict:\n","bert.embeddings.word_embeddings.weight \t torch.Size([30000, 128])\n","bert.embeddings.position_embeddings.weight \t torch.Size([512, 128])\n","bert.embeddings.token_type_embeddings.weight \t torch.Size([2, 128])\n","bert.embeddings.LayerNorm.weight \t torch.Size([128])\n","bert.embeddings.LayerNorm.bias \t torch.Size([128])\n","bert.encoder.embedding_hidden_mapping_in.weight \t torch.Size([768, 128])\n","bert.encoder.embedding_hidden_mapping_in.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight \t torch.Size([3072, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias \t torch.Size([3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight \t torch.Size([768, 3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias \t torch.Size([768])\n","bert.pooler.weight \t torch.Size([768, 768])\n","bert.pooler.bias \t torch.Size([768])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zGez9s2PuF3F"},"source":["input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Du2ImLt5uGAb"},"source":["q, _, _ = new_model.bert(input_ids=input_ids, \n","                         attention_mask=attention_mask, \n","                         token_type_ids=token_type_ids)\n","\n","qq, _, _ = berty(input_ids=input_ids, \n","                         attention_mask=attention_mask, \n","                         token_type_ids=token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kX39hwn6yDUc","colab":{"base_uri":"https://localhost:8080/","height":167},"outputId":"71477994-4954-4cf6-8042-ec33200a708b"},"source":[""],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-b862d2305077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_finetuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: summarize() missing 1 required positional argument: 'mode'"]}]},{"cell_type":"code","metadata":{"id":"CQ2Bw7FhYCyx"},"source":["import pickle\n","with open(base_dir + r\"l1l2\", \"wb\") as f:\n","    pickle.dump([l1, l2], f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xh4le09AYC6I"},"source":["with open(base_dir + r\"l1l2\", \"rb\") as f:\n","    [l1, l2] = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DthsMjZrYDCF"},"source":["with open(base_dir + r\"batch\", \"wb\") as f:\n","    pickle.dump(batch, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LzxZpx_fYDJo"},"source":["with open(base_dir + r\"batch\", \"rb\") as f:\n","    batch = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHjVXlyDgo9Z","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"76574056-8238-40f6-dabb-a5bb7a4165c2"},"source":["for i in range(len(batch)):\n","  print((batch[i] - batchh[i]).sum())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(0)\n","tensor(0)\n","tensor(0)\n","tensor(0)\n","tensor(0)\n","tensor(0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ie9HtHcwg_6u","colab":{"base_uri":"https://localhost:8080/","height":585},"outputId":"10a8f18a-4bf6-46d4-bcb6-13fb9b4e4747"},"source":["l1 - ll1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.3311, -1.1707],\n","        [-1.1836,  0.5233],\n","        [-0.3844, -0.3816],\n","        [-0.8956, -0.1006],\n","        [ 0.0560, -0.4223],\n","        [ 0.1867, -0.2628],\n","        [ 1.3606, -1.6090],\n","        [-1.6539,  0.3736],\n","        [-0.6360,  0.2532],\n","        [ 0.4264, -0.8577],\n","        [-1.4590,  0.6360],\n","        [ 0.0429, -0.3946],\n","        [-1.3437,  0.4152],\n","        [-1.2637,  0.2589],\n","        [-0.6773, -0.2426],\n","        [-0.4709,  0.0996],\n","        [ 0.6763, -0.9663],\n","        [ 0.6074, -0.9704],\n","        [ 1.3427, -0.6838],\n","        [-0.4018, -0.3278],\n","        [-0.7176,  0.1280],\n","        [-0.6025, -0.2789],\n","        [-1.1873,  0.7783],\n","        [-0.4975, -0.0069],\n","        [-1.1089, -0.0882],\n","        [-1.2815,  0.2321],\n","        [-0.0177, -0.4595],\n","        [-1.4720,  0.4155],\n","        [ 0.4455, -0.4733],\n","        [-0.6149, -0.2658],\n","        [-1.4690,  0.5316],\n","        [ 0.2757, -0.8703]], grad_fn=<SubBackward0>)"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"tyEp0rWqRTY7","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"f3f70f51-e687-4485-9e39-21d4f37990da"},"source":["'''\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","\n","# DEFAULTS used by the Trainer\n","checkpoint_callback = ModelCheckpoint(\n","    filepath='./saved_models',\n","    save_best_only=True,\n","    verbose=True,\n","    monitor='val_loss',\n","    mode='min',\n","    prefix=''\n",")\n","\n","#trainer = Trainer(checkpoint_callback=checkpoint_callback)\n","'''\n","#!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nfrom pytorch_lightning.callbacks import ModelCheckpoint\\n\\n# DEFAULTS used by the Trainer\\ncheckpoint_callback = ModelCheckpoint(\\n    filepath='./saved_models',\\n    save_best_only=True,\\n    verbose=True,\\n    monitor='val_loss',\\n    mode='min',\\n    prefix=''\\n)\\n\\n#trainer = Trainer(checkpoint_callback=checkpoint_callback)\\n\""]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"E6kuinpEU17b"},"source":["#!pip install apex\n","#import apex"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0UT3mRNoot1"},"source":["#import apex"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NZ1X94Lw-5pB"},"source":["## Summary\n","\n","That's it! Checkout [PyTorch Lightning](https://github.com/williamFalcon/pytorch-lightning/) which works with any machine learning approach that uses PyTorch."]},{"cell_type":"code","metadata":{"id":"4ARIT37rDdIZ"},"source":["from pprint import pprint as pp\n","pp(bert_finetuner.dic_1[1][1].cpu().numpy()[:5,:20])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pytSP8OxOrr1"},"source":["print(bert)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GHbKj70yOs3D"},"source":["bert_finetuner.dic_1[1][1].shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YfZpDAhMUwQO"},"source":["type(torch.Tensor(answer_mask).type(torch.cuda.FloatTensor))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_VPqM8BRa72r"},"source":["#dict_data = {\"input_ids\": input_ids, \"token_type_ids\": token_type_ids, \"labels\": labels, \"attention_mask\": attention_mask}\n","with open(base_dir + r\"albert256_tensor3model20.pickle\", \"wb\") as f:\n","    pickle.dump(bert_finetuner, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_1wxNwtIb64P"},"source":["torch.save(bert_finetuner, (base_dir + r\"albert256_tensor3model20\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gk9iV6KFdYxP"},"source":["trainer.default_save_path = base_dir + r'albert_model256'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HN-zi80lecp0"},"source":["try:\n","    from apex import amp\n","\n","    APEX_AVAILABLE = True\n","except ImportError:\n","    APEX_AVAILABLE = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a75UtTTYVC8G"},"source":["APEX_AVAILABLE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_YqJZx5VEY6"},"source":["a = torch.Tensor([[1,2,3],[4,5,6]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4goV0SYr8qqV"},"source":["torch.reshape(a,(2,2,2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rMJ4fE3N8ub-"},"source":["a.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q_Jhdys19Hwp"},"source":["torch.cat([a]*5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gtcok93D9gvq"},"source":["a = torch.Tensor([[1,0,1],[0,1,0]])\n","print(a.shape)\n","b = torch.Tensor([[1,0,0], [1, 0, 0]])\n","print(a*b)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p0P2I2KMT6jy"},"source":["print(torch.mul(a, b))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AmSXS5hqUQF5"},"source":["print((a==b).type(torch.cuda.FloatTensor).mean())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IG3Xpnc9Uatc"},"source":[""],"execution_count":null,"outputs":[]}]}