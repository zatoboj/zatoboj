{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Combining 2 models.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"758bb5d3b2cf4298918c8b21dc4e31b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9bab99dc471f4d659a8afdfedc597555","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5db829307316435ead796b2d239779f5","IPY_MODEL_7d2732ef3c744065b43be94b28768470"]}},"9bab99dc471f4d659a8afdfedc597555":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5db829307316435ead796b2d239779f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_647c91d9c620455591a5315f2d7982ad","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":760289,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":760289,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ca8f61f44d8c4200aee4950af9f7b139"}},"7d2732ef3c744065b43be94b28768470":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f76244cd488047d8ada524f1bb7387be","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 760k/760k [00:00&lt;00:00, 3.14MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_da24a1328aaf4b6abc20e7fadae8a47e"}},"647c91d9c620455591a5315f2d7982ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ca8f61f44d8c4200aee4950af9f7b139":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f76244cd488047d8ada524f1bb7387be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"da24a1328aaf4b6abc20e7fadae8a47e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3224e4178bf04d778cebbe9f14183977":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_69d603a2417b4aa39009adae13784403","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_40a05dd999974728ac75dabaa8bf0977","IPY_MODEL_0fdb6eb1fb4a41d69754bf0ac3694c9d"]}},"69d603a2417b4aa39009adae13784403":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"40a05dd999974728ac75dabaa8bf0977":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0deb0806437a4299b1d5ad5c9fa7bead","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":684,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":684,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_08d54ad8a86e4ea99ca1ed1194e16217"}},"0fdb6eb1fb4a41d69754bf0ac3694c9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b2eb6fe904474049b70ca15f72958074","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 684/684 [00:00&lt;00:00, 789B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_13953790fff64e389f2dcd60d967d491"}},"0deb0806437a4299b1d5ad5c9fa7bead":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"08d54ad8a86e4ea99ca1ed1194e16217":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b2eb6fe904474049b70ca15f72958074":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"13953790fff64e389f2dcd60d967d491":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f9687a2f17654fee95ec423c9b911967":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_83f5eefeebe34214b8406767dfbe7617","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6db3fd06165245929eda8d1989a4265b","IPY_MODEL_f5c4f0e13ae242758202dbe8ad059dc9"]}},"83f5eefeebe34214b8406767dfbe7617":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6db3fd06165245929eda8d1989a4265b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b795aa73ba1f4ac4bb89d81e54cf382b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":47376696,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":47376696,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_29fe5bf03e734c6c8aa8aeb48b34e745"}},"f5c4f0e13ae242758202dbe8ad059dc9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0ac61c39e12e4e26bae2d8dcf5dc3bf4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 47.4M/47.4M [00:01&lt;00:00, 26.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0800a5db30f34c69b56fb2f0c656efd5"}},"b795aa73ba1f4ac4bb89d81e54cf382b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"29fe5bf03e734c6c8aa8aeb48b34e745":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0ac61c39e12e4e26bae2d8dcf5dc3bf4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0800a5db30f34c69b56fb2f0c656efd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"GatZ6ZiXFzVh"},"source":["![image.png](data:image/png;base64,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)"]},{"cell_type":"markdown","metadata":{"id":"goRmGIRI5cfC"},"source":["# ALBERT for Question Answering\n","\n","We are using a tensor model on top of ALBERT for the SQUAD 2.0 dataset\n"]},{"cell_type":"markdown","metadata":{"id":"jKj5lgdr5j48"},"source":["## Setup  \n","First, let's check the GPU we got. If memory < 11GB, I'd suggest to do factory reset runtime. Ideally, try to get 16GB"]},{"cell_type":"code","metadata":{"id":"iesFMrWGTx3Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606831002616,"user_tz":-180,"elapsed":622,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"6fb7950c-3b3d-47af-cc93-9c364a3a0438"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue Dec  1 13:56:42 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yhf9UjQ3okV8"},"source":["Installing all necessary libraries -- Pytorch Lightning, transformers and tensorflow"]},{"cell_type":"code","metadata":{"id":"UGjilEHk4vb7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606831024939,"user_tz":-180,"elapsed":17964,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"e7dc9f65-5017-4f94-cc73-27fcea53ee0e"},"source":["%tensorflow_version 1.x\n","!pip install -q pytorch-lightning\n","#!pip install sentencepiece\n","!pip install -q transformers==3.5.0\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","\u001b[K     |████████████████████████████████| 563kB 6.9MB/s \n","\u001b[K     |████████████████████████████████| 829kB 62.2MB/s \n","\u001b[K     |████████████████████████████████| 276kB 48.7MB/s \n","\u001b[K     |████████████████████████████████| 92kB 11.7MB/s \n","\u001b[K     |████████████████████████████████| 10.6MB 51.4MB/s \n","\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: tensorflow 1.15.2 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 1.15.2 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.4.0 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 1.3MB 4.9MB/s \n","\u001b[K     |████████████████████████████████| 890kB 42.5MB/s \n","\u001b[K     |████████████████████████████████| 2.9MB 48.1MB/s \n","\u001b[K     |████████████████████████████████| 1.1MB 60.3MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"X5omrSOMpRDK"},"source":["Some more importing"]},{"cell_type":"code","metadata":{"id":"orKOA-dmpU1j","executionInfo":{"status":"ok","timestamp":1606831065682,"user_tz":-180,"elapsed":5851,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["import os\n","import pickle, json\n","import torch\n","import numpy as np\n","from tqdm import tqdm, trange\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler, DataLoader, random_split\n","import pytorch_lightning as pl\n","from copy import deepcopy\n","#import sentencepiece\n","#from transformers import AlbertModel, AlbertTokenizer"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S8NuAKW9o7hj"},"source":["## Data download \n","\n","Mount the drive to get access to reading and writing files"]},{"cell_type":"code","metadata":{"id":"C5WA386uEpS8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606831088100,"user_tz":-180,"elapsed":19550,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"3db92011-e91f-4e8d-ebc2-e33a100b6cb1"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","root_dir = \"/content/gdrive/My Drive/\"\n","base_dir = root_dir + 'ybshmmlchk/'"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yuUwBKpn-TIK"},"source":["#### Loading preprocessed data. For the preprocessing part -- see Albert_Preprocessing.ipynb\n"]},{"cell_type":"markdown","metadata":{"id":"c0E8SxTYvH2k"},"source":["Define your configuration -- bert model version and max_len"]},{"cell_type":"code","metadata":{"id":"fNHSSHxguiMP","executionInfo":{"status":"ok","timestamp":1606831089486,"user_tz":-180,"elapsed":732,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["conf = {\n","    'model': 'albert', ## options for now-- albert, bert\n","    'model_version' : 'base-v2',\n","    'max_len' : 256\n","}"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"YNlPCaDpuzia","colab":{"base_uri":"https://localhost:8080/","height":164,"referenced_widgets":["758bb5d3b2cf4298918c8b21dc4e31b1","9bab99dc471f4d659a8afdfedc597555","5db829307316435ead796b2d239779f5","7d2732ef3c744065b43be94b28768470","647c91d9c620455591a5315f2d7982ad","ca8f61f44d8c4200aee4950af9f7b139","f76244cd488047d8ada524f1bb7387be","da24a1328aaf4b6abc20e7fadae8a47e","3224e4178bf04d778cebbe9f14183977","69d603a2417b4aa39009adae13784403","40a05dd999974728ac75dabaa8bf0977","0fdb6eb1fb4a41d69754bf0ac3694c9d","0deb0806437a4299b1d5ad5c9fa7bead","08d54ad8a86e4ea99ca1ed1194e16217","b2eb6fe904474049b70ca15f72958074","13953790fff64e389f2dcd60d967d491","f9687a2f17654fee95ec423c9b911967","83f5eefeebe34214b8406767dfbe7617","6db3fd06165245929eda8d1989a4265b","f5c4f0e13ae242758202dbe8ad059dc9","b795aa73ba1f4ac4bb89d81e54cf382b","29fe5bf03e734c6c8aa8aeb48b34e745","0ac61c39e12e4e26bae2d8dcf5dc3bf4","0800a5db30f34c69b56fb2f0c656efd5"]},"executionInfo":{"status":"ok","timestamp":1606831098233,"user_tz":-180,"elapsed":9051,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"797c6ab2-2b40-405b-cb5c-7bcae67a0b2e"},"source":["#returns tokenizer and model from configuration\n","def nlp_model_tokenizer(conf):\n","  if conf['model'] == 'albert':\n","    from transformers import AlbertTokenizer as your_tokenizer, AlbertModel as your_nlp_model\n","  elif conf['model'] == 'bert':\n","    from transformers import BertTokenizer as your_tokenizer, BertModel as your_nlp_model\n","  else:\n","    print('Please select a different model or rewrite the code for this function to add your model')\n","    return False\n","  try:\n","    return your_tokenizer.from_pretrained(conf['model'] + '-' + conf['model_version']), your_nlp_model.from_pretrained(conf['model'] + '-' + conf['model_version'])\n","  except:\n","    print('Wrong model version. Please select a valid one')\n","    return False\n","\n","tokenizer, bert = nlp_model_tokenizer(conf)"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"758bb5d3b2cf4298918c8b21dc4e31b1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760289.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3224e4178bf04d778cebbe9f14183977","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=684.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f9687a2f17654fee95ec423c9b911967","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=47376696.0, style=ProgressStyle(descrip…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7dowEmZrEbl_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606831106851,"user_tz":-180,"elapsed":15296,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"1e2aebcd-6228-46a9-aae1-574cfbe1d156"},"source":["# load train dataset\n","pickle_prefix = conf['model'] + '-' + conf['model_version'] + '-' + str(conf['max_len'])\n","try:\n","  with open(root_dir + 'ybshmmlchk/' + pickle_prefix + '-train.pickle', 'rb') as f:\n","      train_data = pickle.load(f)\n","except:\n","  print('Training data hasnt been processed with your choice of model yet. Please go to preprocessing notebook first and run it with your configuration')  \n","input_ids = train_data[\"input_ids\"]\n","token_type_ids = train_data[\"token_type_ids\"]\n","labels = train_data[\"labels\"]\n","attention_mask = train_data[\"attention_mask\"]\n","answer_mask = train_data['answer_mask']\n","plausible_answer_mask = train_data['plausible_answer_mask']\n","actual_answers = train_data['actual_answers']\n","plausible_answers = train_data['plausible_answers']\n","answer_starts = train_data['answer_starts']\n","answer_ends = train_data['answer_ends']\n","full_questions = train_data['full_questions']\n","full_paragraphs = train_data['full_paragraphs']\n","indexing = list(range(0, len(labels)))\n","print('Number of train input ids:'.ljust(30), len(input_ids))\n","# print('Number of train token type ids:'.ljust(30), len(token_type_ids))\n","# print('Number of train labels:'.ljust(30), len(labels))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Number of train input ids:     111281\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RaUsGJo-w0Tl","executionInfo":{"status":"ok","timestamp":1606831107294,"user_tz":-180,"elapsed":14079,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"d1431de8-284e-4e74-85d8-e1e578d99625"},"source":["# load val dataset\n","pickle_prefix = conf['model'] + '-' + conf['model_version'] + '-' + str(conf['max_len'])\n","try:\n","  with open(root_dir + 'ybshmmlchk/' + pickle_prefix + '-val.pickle', 'rb') as f:\n","      val_data = pickle.load(f)\n","except:\n","  print('Training data hasnt been processed with your choice of model yet. Please go to preprocessing notebook first and run it with your configuration') \n","    \n","val_input_ids = val_data[\"input_ids\"]\n","val_token_type_ids = val_data[\"token_type_ids\"]\n","val_labels = val_data[\"labels\"]\n","val_attention_mask = val_data[\"attention_mask\"]\n","val_answer_mask = val_data['answer_mask']\n","val_plausible_answer_mask = val_data['plausible_answer_mask']\n","val_actual_answers = val_data['actual_answers']\n","val_plausible_answers = val_data['plausible_answers']\n","val_answer_starts = val_data['answer_starts']\n","val_answer_ends = val_data['answer_ends']\n","val_full_questions = val_data['full_questions']\n","val_full_paragraphs = val_data['full_paragraphs']\n","val_indexing = list(range(0, len(val_labels)))\n","print('Number of val input ids:'.ljust(30), len(val_input_ids))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Number of val input ids:       5296\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QoKj1WLzyLEU"},"source":["The fraction of unanswerable questions is about 33%, so about 66% have an answer. The average number of tokens that are in the answer is about 1%. Since the length of our \"sentences\" is 256, the average length of answers is about 3 tokens."]},{"cell_type":"code","metadata":{"id":"P7CfHp4Kyu6k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606561751904,"user_tz":-180,"elapsed":4077,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"5f1334e6-a9e4-4465-a8a3-39c95b558f61"},"source":["print('Fraction of unaswerable questions:', np.mean(labels))\n","print('Average fraction of answer tokens in paragraph:',np.array([np.array(x).mean() for x in answer_mask]).mean())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fraction of unaswerable questions: 0.3361939594360223\n","Average fraction of answer tokens in paragraph: 0.011225874700083573\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_gfRvBMctUCD"},"source":["Here is an example of an entry in the dataset. Note that label is is_unanswerable, so True means there is no answer."]},{"cell_type":"code","metadata":{"id":"k8CHPkGNpt5u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606564265952,"user_tz":-180,"elapsed":727,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"5194aea0-999f-4eeb-f15f-a8dd2f8ca3c0"},"source":["i = 153\n","print('Input id:', i)\n","print('Question:', full_questions[i])\n","print('Paragraph:', full_paragraphs[i])\n","print('Answer:', actual_answers[i])\n","print('Plausible answer (if answer doesnt exist):', plausible_answers[i])\n","print('Label:', labels[i]) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input id: 153\n","Question: What did the UN Peacebuliding Commission decide on Jan 8, 2008?\n","Paragraph: In 2006, due to ongoing violence, over 50,000 people in the country's northwest were at risk of starvation but this was averted due to assistance from the United Nations.[citation needed] On 8 January 2008, the UN Secretary-General Ban Ki-Moon declared that the Central African Republic was eligible to receive assistance from the Peacebuilding Fund. Three priority areas were identified: first, the reform of the security sector; second, the promotion of good governance and the rule of law; and third, the revitalization of communities affected by conflicts. On 12 June 2008, the Central African Republic requested assistance from the UN Peacebuilding Commission, which was set up in 2005 to help countries emerging from conflict avoid devolving back into war or chaos.\n","Answer: no answer\n","Plausible answer (if answer doesnt exist): the Central African Republic was eligible to receive assistance from the Peacebuilding Fund\n","Label: True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3F1sf5r59l6e"},"source":["Now we define a function which will return train and validation dataloaders. The breakdown is 95-5."]},{"cell_type":"code","metadata":{"id":"kMdQZUjO-MI7","executionInfo":{"status":"ok","timestamp":1606831107295,"user_tz":-180,"elapsed":10826,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["def generate_squad_dataloaders(batch_size):\n","  # ----------------------\n","  # TRAIN/VAL/TEST DATALOADERS\n","  # ----------------------\n","\n","  # TensorDataset from training examples. \".cuda()\" puts the corresponding tensor on gpu\n","  squad_train_dataset = TensorDataset(torch.tensor(input_ids, dtype=torch.long).cuda(),\n","                                torch.tensor(attention_mask, dtype=torch.long).cuda(),  \n","                                torch.tensor(token_type_ids, dtype=torch.long).cuda(), \n","                                1 - torch.tensor(labels, dtype=torch.long).cuda(), #label is 0 if there is an answer in the original dataset\n","                                torch.tensor(answer_mask, dtype=torch.long).cuda(),\n","                                torch.tensor(indexing, dtype=torch.long).cuda(),\n","                                torch.tensor(answer_starts).cuda(),\n","                                torch.tensor(answer_ends).cuda())\n","  \n","  squad_val_dataset = TensorDataset(torch.tensor(val_input_ids, dtype=torch.long).cuda(),\n","                                torch.tensor(val_attention_mask, dtype=torch.long).cuda(),  \n","                                torch.tensor(val_token_type_ids, dtype=torch.long).cuda(), \n","                                1 - torch.tensor(val_labels, dtype=torch.long).cuda(), #label is 0 if there is an answer in the original dataset\n","                                torch.tensor(val_answer_mask, dtype=torch.long).cuda(),\n","                                torch.tensor(val_indexing, dtype=torch.long).cuda(),\n","                                torch.tensor(val_answer_starts).cuda(),\n","                                torch.tensor(val_answer_ends).cuda())\n","  \n","  # test is not actually used yet\n","  \"\"\"squad_test_dataset = TensorDataset(torch.tensor(input_ids[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(),\n","                                torch.tensor(attention_mask[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(),  \n","                                torch.tensor(token_type_ids[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(), \n","                                1 - torch.tensor(labels[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(), #label is 0 if there is an answer in the original dataset\n","                                torch.tensor(answer_mask[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda(),\n","                                torch.tensor(indexing[nb_train_samples+nb_val_samples:], dtype=torch.long).cuda())\"\"\"\n","\n","  print('Train set size:', len(labels))\n","  print('Validation set size:', len(val_labels))\n","\n","  # train loader\n","  train_sampler = RandomSampler(squad_train_dataset)\n","  squad_train_dataloader = DataLoader(squad_train_dataset, sampler = train_sampler, batch_size = batch_size)\n","\n","  # val loader\n","  val_sampler = SequentialSampler(squad_val_dataset)\n","  squad_val_dataloader = DataLoader(squad_val_dataset, sampler = val_sampler, batch_size = batch_size, shuffle = False)\n","\n","  # test loader\n","  #test_sampler = RandomSampler(squad_test_dataset)\n","  #squad_test_dataloader = DataLoader(squad_test_dataset, sampler=test_sampler, batch_size = batch_size)\n"," \n","  return squad_train_dataloader, squad_val_dataloader#, squad_test_dataloader"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mvqBwNVaZzh2"},"source":["Defining the model from BERT paper with start and end vector"]},{"cell_type":"code","metadata":{"id":"u5oywwv6Py7u","executionInfo":{"status":"ok","timestamp":1606831108673,"user_tz":-180,"elapsed":1353,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["class SQUADBERTY(pl.LightningModule):\n","\n","    def __init__(self, proj_dim, num_inner_products, batch_size, weight =2., answer_punishment_coeff=1.):\n","        super(SQUADBERTY, self).__init__() \n","        self.bert = deepcopy(bert).cuda()\n","        self.bert_dim = bert.config.hidden_size #768\n","        self.weight = weight\n","        self.answer_punishment_coeff = answer_punishment_coeff\n","        self.batch_size = batch_size\n","        self.max_len = 256\n","        self.proj_dim = proj_dim\n","\n","        self.Proj = nn.Linear(self.bert_dim, self.proj_dim)\n","        self.Proj_cls = nn.Linear(self.bert_dim, self.proj_dim)\n","        self.BL = nn.Bilinear(self.proj_dim, self.proj_dim, num_inner_products) # l scalar products of 2 vectors of dim d\n","        self.L = nn.Linear(num_inner_products, 2)\n","        self.CLS = nn.Linear(self.bert_dim, 2) #(a,b) e^a/(e^a+e^b)\n","\n","        self.squad_train_dataloader, self.squad_val_dataloader = generate_squad_dataloaders(batch_size)\n","\n","    def my_forward_pass(self, cls_bert_output, bert_output_full):\n","        current_batch_size = bert_output_full.shape[0]\n","        bert_output_full = torch.reshape(bert_output_full, (current_batch_size * self.max_len, self.bert_dim))\n","        proj_output_full = self.Proj(bert_output_full)\n","        proj_cls = self.Proj_cls(cls_bert_output)\n","        proj_cls = torch.cat([proj_cls]*self.max_len) # replicated proj_cls to make it the same shape as proj_output_full\n","        long_logits = self.BL(proj_cls, proj_output_full)\n","        long_logits = nn.ReLU6()(long_logits)\n","        long_logits = self.L(long_logits)\n","        long_logits = torch.reshape(long_logits, (current_batch_size, self.max_len, 2))\n","        return long_logits\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","      \n","        bert_output_full, cls_pooler_output = self.bert(input_ids=input_ids, \n","                         attention_mask=attention_mask, \n","                         token_type_ids=token_type_ids)\n","        # bert_output_full.shape = (batch_size, max_len, bert_dim) -- one vector of dim=bert_dim for each token\n","        # cls_pooler_output of shape (batch_size, bert_dim) -- Last layer hidden-state of the first token of the sequence (classification token) \n","        # further processed by a Linear layer and a Tanh activation function. \n","        # The Linear layer weights are trained from the next sentence prediction (classification) objective during pretraining.\n","\n","        cls_bert_output = bert_output_full[:, 0, :] # vector corresponding to CLS token\n","\n","        # long_logits will have shape (batch_size, max_len, 2)\n","        # each output of bert is projected to smaller dimension, then take a few inner products with projection of the cls vector,\n","        # then another dense layer to get logits\n","        long_logits = self.my_forward_pass(cls_bert_output, bert_output_full)\n","        cls_logits = self.CLS(cls_pooler_output)\n","\n","        return cls_logits, long_logits\n","\n","    def training_step(self, batch, batch_nb):\n","        # batch\n","        input_ids, attention_mask, token_type_ids, label, answer_mask, indexing, answer_starts, answer_ends = batch\n","         \n","        # fwd\n","        cls_logits, long_logits = self.forward(input_ids, attention_mask, token_type_ids)\n","        \n","        # loss\n","        # loss for not guessing if there is an answer\n","        loss1 = F.cross_entropy(cls_logits, label, weight = torch.Tensor([2.,1.]))\n","\n","        # loss for each individual word -- is it in the answer?\n","        # TODO: need to insert weight -- around 90 bc of mismatch of 0s and 1s -- only 1% are 1s\n","        loss2 = F.cross_entropy(torch.reshape(long_logits, (long_logits.shape[0] * long_logits.shape[1], long_logits.shape[2])), \n","                                torch.reshape(answer_mask, (answer_mask.shape[0] * answer_mask.shape[1],)), weight = torch.Tensor([1.,50.]))\n","        # total loss\n","        # TODO: experiment with punishment coeff\n","        loss = self.answer_punishment_coeff*loss1 + loss2\n","        self.log('loss', loss, prog_bar=True)\n","        # logs\n","        tensorboard_logs = {'train_loss': loss}\n","\n","        return {'loss': loss, 'log': tensorboard_logs}\n","\n","    def validation_step(self, batch, batch_nb):\n","        # batch\n","        input_ids, attention_mask, token_type_ids, label, answer_mask, indexing, answer_starts, answer_ends = batch\n","         \n","        # fwd\n","        cls_logits, long_logits = self.forward(input_ids, attention_mask, token_type_ids)\n","        \n","        # loss\n","        # loss for not guessing if there is an answer\n","        loss1 = F.cross_entropy(cls_logits, label, weight = torch.Tensor([2.,1.]))\n","\n","        # loss for each individual word -- is it in the answer?\n","        # TODO: need to insert weight -- around 90 bc of mismatch of 0s and 1s -- only 1% are 1s\n","        loss2 = F.cross_entropy(torch.reshape(long_logits, (long_logits.shape[0] * long_logits.shape[1], long_logits.shape[2])), \n","                                torch.reshape(answer_mask, (answer_mask.shape[0] * answer_mask.shape[1],)))#, weight = torch.Tensor([1.,self.weight]))\n","        # total loss\n","        # TODO: experiment with punishment coeff\n","        loss = self.answer_punishment_coeff*loss1 + loss2\n","\n","        # compute accuracy \n","        # TODO: compute precision/recall on individual words, accuracy of start, end, exact match\n","\n","        # ну хоть одна переменная должна нормально называться\n","        a, y1 = torch.max(cls_logits, dim=1)\n","        label_acc = torch.sum(y1 == label) / label.shape[0]\n","        self.log('label_acc', label_acc, prog_bar=True)\n","\n","        return {'val_loss' : loss, 'label_acc' : label_acc}\n","        \n","    def dics_average(self, dics, name):\n","        d = dict()\n","        for key in dics[0].keys():\n","          d[name + key] = torch.stack([x[key] for x in dics]).mean()\n","        return d\n","    \n","    def validation_end(self, outputs):\n","        #'found_pos' : found_pos, 'pos_val' : pos_val, 'pos_res' : pos_res\n","        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n","\n","        \"\"\"pre_dics = [x['pre_guess'] for x in outputs]\n","        post_dics = [x['post_guess'] for x in outputs]\n","        pre_d = self.dics_average(pre_dics, 'pre_avg_')\n","        post_d = self.dics_average(post_dics, 'post_avg_')\n","        #print('\\n validation5 \\n')\n","        tensorboard_logs = {'val_loss': avg_loss, 'pre_guess': pre_d, 'smart_guess': post_d}\n","        #print('\\n validation6 \\n')\"\"\"\n","        self.log('validation_loss', avg_loss, prog_bar=True)\n","        #self.log('pre', pre_d, prog_bar=True)\n","        label_acc = torch.stack([x['label_acc'] for x in outputs]).mean()\n","        self.log('val_label_acc', label_acc, prog_bar=True)\n","        #self.log('end_accuracy', end_acc, prog_bar=True)\n","        tensorboard_logs = {'val_loss': avg_loss, 'val_label_acc' : label_acc}\n","        return {'avg_val_loss': avg_loss, 'progress_bar': tensorboard_logs}\n","\n","    '''\n","    def test_step(self, batch, batch_nb):\n","        input_ids, attention_mask, token_type_ids, label = batch\n","        \n","        y_hat, attn = self.forward(input_ids, attention_mask, token_type_ids)\n","        \n","        a, y_hat = torch.max(y_hat, dim=1)\n","        test_acc = accuracy_score(y_hat.cpu(), label.cpu())\n","        \n","        return {'test_acc': torch.tensor(test_acc)}\n","\n","    def test_end(self, outputs):\n","\n","        avg_test_acc = torch.stack([x['test_acc'] for x in outputs]).mean()\n","\n","        tensorboard_logs = {'avg_test_acc': avg_test_acc}\n","        return {'avg_test_acc': avg_test_acc, 'log': tensorboard_logs, 'progress_bar': tensorboard_logs}\n","    '''\n","    \n","    def configure_optimizers(self):\n","        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=5e-06, eps=1e-08)\n","\n","    def train_dataloader(self):\n","        return self.squad_train_dataloader\n","\n","    def val_dataloader(self):\n","        return self.squad_val_dataloader\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"frEirSZwSfil","executionInfo":{"status":"ok","timestamp":1606831110948,"user_tz":-180,"elapsed":960,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["class SQUADBERT(pl.LightningModule):\n","\n","    def __init__(self, batch_size):\n","        super(SQUADBERT, self).__init__()\n","        # initializing BERT, parameters, dataloaders\n","        self.bert = deepcopy(bert).cuda()\n","        self.n = bert.config.hidden_size\n","        self.max_len = 256\n","        self.batch_size = batch_size\n","        self.squad_train_dataloader, self.squad_val_dataloader = generate_squad_dataloaders(self.batch_size)\n","        # initializing additional layers -- start and end vectors\n","        self.Start = nn.Linear(self.n, 1)\n","        self.End = nn.Linear(self.n, 1)\n","\n","    def new_layers(self, q, new_layer):\n","        logits_wrong_shape = new_layer(torch.reshape(q, (q.shape[0]*q.shape[1], q.shape[2])))\n","        logits = torch.reshape(logits_wrong_shape, (q.shape[0], q.shape[1]))\n","        return logits\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        #apply BERT\n","        q, _ = self.bert(input_ids=input_ids, \n","                         attention_mask=attention_mask, \n","                         token_type_ids=token_type_ids)\n","        # shape of q will be (batch_size, max_len, bert_dim) = (batch_size, 256, 768)\n","        # take inner products of output vectors with trainable start and end vectors\n","        start_logits = self.new_layers(q, self.Start)\n","        end_logits = self.new_layers(q, self.End)\n","\n","        return start_logits, end_logits\n","\n","    # this is the main function of pl modules. defines architecture and loss function. training loop comes for free -- implemented inside PL\n","    def training_step(self, batch, batch_nb):\n","        # batch\n","        input_ids, attention_mask, token_type_ids, label, answer_mask, indexing, answer_starts, answer_ends = batch\n","         \n","        # fwd\n","        start_logits, end_logits = self.forward(input_ids, attention_mask, token_type_ids)\n","        \n","        # LOSS\n","        # get start and end positions from answer_mask\n","        start, end = answer_starts, answer_ends#get_start_end(answer_mask)\n","\n","        # compute cross_entropy loss between predictions and actual labels for start and end \n","        loss1 = F.cross_entropy(start_logits, start)\n","        loss2 = F.cross_entropy(end_logits, end)\n","        loss = loss1 + loss2\n","\n","        self.log('loss', loss, prog_bar=True)\n","        # logs\n","        tensorboard_logs = {'train_loss': loss}\n","        return {'loss': loss, 'log': tensorboard_logs}\n","\n","    def validation_step(self, batch, batch_nb):\n","        # batch\n","        input_ids, attention_mask, token_type_ids, label, answer_mask, indexing, answer_starts, answer_ends = batch\n","\n","        # fwd\n","        start_logits, end_logits = self.forward(input_ids, attention_mask, token_type_ids)\n","\n","        # loss\n","        start, end = answer_starts, answer_ends#get_start_end(answer_mask)\n","\n","        loss1 = F.cross_entropy(start_logits, start)\n","        loss2 = F.cross_entropy(end_logits, end)\n","        loss = loss1 + loss2\n","\n","        # ^^^^ the code above is the same as for training step, but we also add accuracy computation for validation below\n","\n","        # acc\n","        a, y1 = torch.max(start_logits, dim=1)\n","        a, y2 = torch.max(end_logits, dim=1)\n","        \n","        start_acc = torch.sum(y1 == start) / self.batch_size\n","        end_acc = torch.sum(y2 == end) / self.batch_size\n","        self.log('start_acc', start_acc, prog_bar=True)\n","        self.log('end_acc', end_acc, prog_bar=True)\n","        return {'val_loss' : loss, 'start_acc' : start_acc, 'end_acc' : end_acc}\n","\n","    def validation_end(self, outputs):\n","        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n","        start_acc = torch.stack([x['start_acc'] for x in outputs]).mean()\n","        end_acc = torch.stack([x['end_acc'] for x in outputs]).mean()\n","\n","        self.log('validation_loss', avg_loss, prog_bar=True)\n","        self.log('start_accuracy', start_acc, prog_bar=True)\n","        self.log('end_accuracy', end_acc, prog_bar=True)\n","        tensorboard_logs = {'val_loss': avg_loss, 'start_acc' : start_acc, 'end_acc' : end_acc}\n","        return {'avg_val_loss': avg_loss, 'progress_bar': tensorboard_logs}\n","    \n","    def configure_optimizers(self):\n","        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=3e-05, eps=1e-08)\n","\n","    def train_dataloader(self):\n","        return self.squad_train_dataloader\n","\n","    def val_dataloader(self):\n","        return self.squad_val_dataloader\n"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v-oJLdeFW2f6"},"source":["**Loading**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ZeKyNlkW7dm","executionInfo":{"status":"ok","timestamp":1606831128034,"user_tz":-180,"elapsed":13977,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"67a16e69-a0c4-4508-a733-e090ad7bedec"},"source":["torch.set_default_tensor_type('torch.cuda.FloatTensor')\n","model1 = SQUADBERTY(20, 5, 16)\n","model_name = 'tensor_model_v1_final'\n","checkpoint = torch.load(base_dir + 'saved_models/' + model_name, map_location=lambda storage, loc: storage)\n","model1.load_state_dict(checkpoint['state_dict'])\n","model1.eval()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Train set size: 111281\n","Validation set size: 5296\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SQUADBERTY(\n","  (bert): AlbertModel(\n","    (embeddings): AlbertEmbeddings(\n","      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0, inplace=False)\n","    )\n","    (encoder): AlbertTransformer(\n","      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n","      (albert_layer_groups): ModuleList(\n","        (0): AlbertLayerGroup(\n","          (albert_layers): ModuleList(\n","            (0): AlbertLayer(\n","              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (attention): AlbertAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (attention_dropout): Dropout(p=0, inplace=False)\n","                (output_dropout): Dropout(p=0, inplace=False)\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              )\n","              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n","              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n","              (dropout): Dropout(p=0, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (pooler): Linear(in_features=768, out_features=768, bias=True)\n","    (pooler_activation): Tanh()\n","  )\n","  (Proj): Linear(in_features=768, out_features=20, bias=True)\n","  (Proj_cls): Linear(in_features=768, out_features=20, bias=True)\n","  (BL): Bilinear(in1_features=20, in2_features=20, out_features=5, bias=True)\n","  (L): Linear(in_features=5, out_features=2, bias=True)\n","  (CLS): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjuPepioTOdc","executionInfo":{"status":"ok","timestamp":1606831145039,"user_tz":-180,"elapsed":4344,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"81235878-a75b-491d-fc1b-d0dc2a5a110a"},"source":["torch.set_default_tensor_type('torch.cuda.FloatTensor')\n","model2 = SQUADBERT(16)\n","model_name = '2epochs_base_albert'\n","checkpoint = torch.load(base_dir + 'saved_models/' + model_name, map_location=lambda storage, loc: storage)\n","model2.load_state_dict(checkpoint['state_dict'])\n","model2.eval()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Train set size: 111281\n","Validation set size: 5296\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SQUADBERT(\n","  (bert): AlbertModel(\n","    (embeddings): AlbertEmbeddings(\n","      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0, inplace=False)\n","    )\n","    (encoder): AlbertTransformer(\n","      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n","      (albert_layer_groups): ModuleList(\n","        (0): AlbertLayerGroup(\n","          (albert_layers): ModuleList(\n","            (0): AlbertLayer(\n","              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (attention): AlbertAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (attention_dropout): Dropout(p=0, inplace=False)\n","                (output_dropout): Dropout(p=0, inplace=False)\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              )\n","              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n","              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n","              (dropout): Dropout(p=0, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (pooler): Linear(in_features=768, out_features=768, bias=True)\n","    (pooler_activation): Tanh()\n","  )\n","  (Start): Linear(in_features=768, out_features=1, bias=True)\n","  (End): Linear(in_features=768, out_features=1, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137},"id":"goKaVTXhS389","executionInfo":{"status":"ok","timestamp":1606831149436,"user_tz":-180,"elapsed":670,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"89763857-d3cb-4734-9abb-7e9e8dfb03e0"},"source":["torch.cuda.memory_summary()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    1923 MB |    1923 MB |    1925 MB |    1822 KB |\\n|       from large pool |    1915 MB |    1915 MB |    1915 MB |       0 KB |\\n|       from small pool |       8 MB |       8 MB |      10 MB |    1822 KB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    1923 MB |    1923 MB |    1925 MB |    1822 KB |\\n|       from large pool |    1915 MB |    1915 MB |    1915 MB |       0 KB |\\n|       from small pool |       8 MB |       8 MB |      10 MB |    1822 KB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    1950 MB |    1950 MB |    1950 MB |       0 B  |\\n|       from large pool |    1940 MB |    1940 MB |    1940 MB |       0 B  |\\n|       from small pool |      10 MB |      10 MB |      10 MB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   26818 KB |   34859 KB |   81848 KB |   55030 KB |\\n|       from large pool |   25392 KB |   33872 KB |   73520 KB |   48128 KB |\\n|       from small pool |    1426 KB |    2468 KB |    8328 KB |    6902 KB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |      98    |      98    |     102    |       4    |\\n|       from large pool |      32    |      32    |      32    |       0    |\\n|       from small pool |      66    |      66    |      70    |       4    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |      98    |      98    |     102    |       4    |\\n|       from large pool |      32    |      32    |      32    |       0    |\\n|       from small pool |      66    |      66    |      70    |       4    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      26    |      26    |      26    |       0    |\\n|       from large pool |      21    |      21    |      21    |       0    |\\n|       from small pool |       5    |       5    |       5    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      17    |      17    |      20    |       3    |\\n|       from large pool |      12    |      12    |      13    |       1    |\\n|       from small pool |       5    |       5    |       7    |       2    |\\n|===========================================================================|\\n'"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"s9A5HGrcX5kk"},"source":["**Results on validation/train**"]},{"cell_type":"markdown","metadata":{"id":"qrOCKwm8YIeA"},"source":["Helper functions"]},{"cell_type":"code","metadata":{"id":"2XPQPLHxYCeP","executionInfo":{"status":"ok","timestamp":1606831154916,"user_tz":-180,"elapsed":651,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["#returns \"probabilities\" of start and end. not actually probabilities, because this is before softmax\n","def predict(model, batch):\n","  input_ids, attention_mask, token_type_ids, label, answer_mask, indexing, answer_starts, answer_ends = batch\n","  with torch.no_grad():\n","    res =  model(input_ids, attention_mask, token_type_ids)\n","  return res\n","\n","# returns start and end vectors, just based on argmax taken individually\n","def convert_predictions(l1, l2):#, label, answer_mask):\n","  a, y1 = torch.max(l1, dim=1)\n","  a, y2 = torch.max(l2, dim=1)\n","  \n","  return y1, y2#, guess1, guess2, d_pre, d_post\n","\n","# returns start and end vectors taking into account that end>=start + start can't be before question end\n","def convert_predictions_improved(l1, l2, min_start):\n","  starts, ends = [], []\n","  for i in range(l1.shape[0]):\n","    p1, p2 = l1[i], l2[i]\n","    highest_prob = p1[0] + p2[0]\n","    start, end = 0, 0\n","    for k in range(min_start[i], 256):\n","      for j in range(k, 256):\n","        if p1[k] + p2[j] > highest_prob:\n","          highest_prob, start, end = p1[k] + p2[j], k, j\n","    starts.append(start)\n","    ends.append(end)\n","  return torch.Tensor(starts), torch.Tensor(ends)\n","\n","def npf(tt):\n","  return tt.detach().cpu().numpy()\n","\n","def convert_predictions_improved_v3(start_batch, end_batch, min_start=None):\n","  start_batch, end_batch, min_start = npf(start_batch), npf(end_batch), npf(min_start)\n","  #start_batch, end_batch = npf(start_batch), npf(end_batch)\n","  batch_size, max_len = start_batch.shape\n","  probs = start_batch.reshape(-1,max_len,1) + end_batch.reshape(-1,1,max_len) # array of shape: (batch_size, max_len, max_len), matrix of pairwise sums per each element of the batch\n","  if min_start is not None:\n","    mask = np.zeros(probs.shape)  # create a mask to avoid including cases where i > j or i > min_start or j > min_start\n","    for i,s in enumerate(min_start):\n","        mask[i,:s,:] = 1\n","        mask[i,:,:s] = 1\n","        mask[i][np.tril_indices(max_len,-1)] = 1\n","    mask[:,0,0] = 0               # we however leave i=j=0 to detect questions without answers\n","    probs = np.ma.array(probs,mask=mask)\n","    probs = np.ma.filled(probs,-np.inf)\n","  else:\n","    probs = np.triu(probs)\n","  max_probs = np.argmax(probs.reshape(batch_size,-1), axis=-1) # array of shape: (batch_size,), argmaxes of flattened matrices of pairwise sums\n","  starts, ends = np.unravel_index(max_probs, (max_len, max_len)) # two arrays of shape: (batch_size,), 'unflattenning' of max_probs\n","  return starts, ends"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3x7xlrxYYLMQ"},"source":["Validation itself"]},{"cell_type":"code","metadata":{"id":"fEnO2eqy4vXy","executionInfo":{"status":"ok","timestamp":1606831158000,"user_tz":-180,"elapsed":641,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["from pprint import pprint"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"5qXUESXVhQwF","executionInfo":{"status":"ok","timestamp":1606831158229,"user_tz":-180,"elapsed":548,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["def get_stats_on_batch_1(model, batch):\n","    d = {}\n","    l1, l2 = predict(model, batch)\n","    print(l1.shape, l2.shape)\n","    #l1 = l1[:,1] - l1[:,0]\n","    l2 = l2[:,:,1] - l2[:,:,0]\n","    a, y1 = torch.max(l1, dim=1)\n","    #y2 = l2[(l2>0.).nonzero()]\n","    #y1, y2 = convert_predictions(l1, l2)\n","    input_ids, attention_mask, token_type_ids, label, answer_mask, indexing, answer_starts, answer_ends = batch\n","    start, end = answer_starts, answer_ends#get_start_end(answer_mask)\n","    d['num_examples'] = start.shape[0]\n","    #d['num_starts_guessed'] = torch.sum(start==y1)\n","    #d['num_ends_guessed'] = torch.sum(end==y2)\n","    #d['num_exact_matches_guessed'] = torch.sum(((start==y1).double()  + (end==y2).double() )==2.)\n","    #_ , min_start = torch.max(token_type_ids, dim=1)\n","    \n","    #predicted_start, predicted_end = convert_predictions_improved_v3(l1, l2, min_start)\n","    #input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","    #start, end = npf(start), npf(end)\n","\n","    #d['num_starts_guessed_post'] = np.sum(start==predicted_start)\n","    #d['num_ends_guessed_post'] = np.sum(end==predicted_end)\n","    #d['num_exact_matches_guessed_post'] = np.sum(((start==predicted_start).astype(int)  + (end==predicted_end).astype(int) )==2)\n","    predicted_label = npf(y1).astype(int)#predicted_start.copy().astype(int)\n","    #predicted_label[predicted_label!=0] = 1 \n","    label = npf(label).astype(int)\n","    d['num_labels_guessed'] = np.sum(label == predicted_label)\n","    d['label_prob'] = l1[:,1] - l1[:,0]\n","    #d['predicted_start'] = predicted_start\n","    #d['predicted_end'] = predicted_end\n","    d['predicted_label'] = predicted_label\n","    d['actual_start'] = answer_starts\n","    d['actual_end'] = answer_ends\n","    d['actual_label'] = label\n","    d['input_ids'] = input_ids\n","    d['indexing'] = indexing\n","    d['full_probs'] = l2\n","    #d['start_probs'] = l1\n","    #d['end_probs'] = l2\n","    return d\n","\n","def batch_by_number(model, i):\n","  dataloader = model.val_dataloader()\n","  for batch_ndx, batch in enumerate(dataloader):\n","    if batch_ndx == i:\n","      return batch\n","\n","def print_example_1(d, i):\n","  res = {}\n","  index = d['indexing'][i]\n","  #predicted_start = d['predicted_start'][i]\n","  #predicted_end = d['predicted_end'][i]\n","  input_ids = d['input_ids'][i]\n","  probs = d['full_probs'][i]\n","  res['predicted_answer'] = tokenizer.convert_ids_to_tokens(input_ids[probs>0])\n","  res['predicted_probs'] = probs[probs>0]\n","  res['actual_answer'] = val_actual_answers[index]\n","  #print(d['indexing'][i])\n","  res['actual_label'] = d['actual_label'][i]\n","  res['predicted_label'] = d['predicted_label'][i]\n","  res['text'] = val_full_paragraphs[index]\n","  res['question'] = val_full_questions[index]\n","  res['label_prob'] = d['label_prob'][i]\n","  return res"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"cNcSizIMUw9L","executionInfo":{"status":"ok","timestamp":1606831160213,"user_tz":-180,"elapsed":616,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}}},"source":["def get_stats_on_batch_2(model, batch):\n","    d = {}\n","    l1, l2 = predict(model, batch)\n","    y1, y2 = convert_predictions(l1, l2)\n","    input_ids, attention_mask, token_type_ids, label, answer_mask, indexing, answer_starts, answer_ends = batch\n","    start, end = answer_starts, answer_ends#get_start_end(answer_mask)\n","    d['num_examples'] = start.shape[0]\n","    d['num_starts_guessed'] = torch.sum(start==y1)\n","    d['num_ends_guessed'] = torch.sum(end==y2)\n","    d['num_exact_matches_guessed'] = torch.sum(((start==y1).double()  + (end==y2).double() )==2.)\n","    _ , min_start = torch.max(token_type_ids, dim=1)\n","    \n","    predicted_start, predicted_end = convert_predictions_improved_v3(l1, l2, min_start)\n","    #input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","    start, end = npf(start), npf(end)\n","\n","    d['num_starts_guessed_post'] = np.sum(start==predicted_start)\n","    d['num_ends_guessed_post'] = np.sum(end==predicted_end)\n","    d['num_exact_matches_guessed_post'] = np.sum(((start==predicted_start).astype(int)  + (end==predicted_end).astype(int) )==2)\n","    predicted_label = predicted_start.copy().astype(int)\n","    predicted_label[predicted_label!=0] = 1 \n","    label = npf(label).astype(int)\n","    d['num_labels_guessed'] = np.sum(label == predicted_label)\n","    d['predicted_start'] = predicted_start\n","    d['predicted_end'] = predicted_end\n","    d['predicted_label'] = predicted_label\n","    d['actual_start'] = answer_starts\n","    d['actual_end'] = answer_ends\n","    d['actual_label'] = label\n","    d['input_ids'] = input_ids\n","    d['indexing'] = indexing\n","    d['start_probs'] = l1\n","    d['end_probs'] = l2\n","    return d\n","\n","def print_example_2(d, i):\n","    res = {}\n","    index = d['indexing'][i]\n","    predicted_start = d['predicted_start'][i]\n","    predicted_end = d['predicted_end'][i]\n","    input_ids = d['input_ids'][i]\n","    res['predicted_answer'] = tokenizer.convert_ids_to_tokens(input_ids[predicted_start : predicted_end+1])\n","    res['actual_answer'] = val_actual_answers[index]\n","    #print(d['indexing'][i])\n","    res['actual_label'] = d['actual_label'][i]\n","    res['predicted_label'] = d['predicted_label'][i]\n","    res['text'] = val_full_paragraphs[index]\n","    res['question'] = val_full_questions[index]\n","    return res"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ydvgoewQhQ1i","executionInfo":{"status":"ok","timestamp":1606831167266,"user_tz":-180,"elapsed":1009,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"d7513d69-f81f-4e78-a119-89122b010b6d"},"source":["# prints one example in a batch\n","# predicted answers -- all words with > 0 logarithmic probability of being in the answer\n","batch = batch_by_number(model1, 8)\n","d1 = get_stats_on_batch_1(model1, batch)\n","d2 = get_stats_on_batch_2(model2, batch)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["torch.Size([16, 2]) torch.Size([16, 256, 2])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k4FeEQAZ4m1B","executionInfo":{"status":"ok","timestamp":1606831168527,"user_tz":-180,"elapsed":417,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"e30476d2-f74b-4505-eb8b-b80bad0b5f5c"},"source":["i = 2\n","pprint(print_example_1(d1, i))\n","pprint(print_example_2(d2, i))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["{'actual_answer': 'in an evolutionary context',\n"," 'actual_label': 1,\n"," 'label_prob': tensor(-1.1899),\n"," 'predicted_answer': ['▁striking',\n","                      '▁viewed',\n","                      '▁in',\n","                      '▁an',\n","                      '▁evolutionary',\n","                      '▁context'],\n"," 'predicted_label': 0,\n"," 'predicted_probs': tensor([0.3110, 0.7895, 2.1614, 3.3755, 3.8384, 3.7783]),\n"," 'question': \"How is it interesting to view hunter-gatherers' egalitarianism?\",\n"," 'text': 'The egalitarianism typical of human hunters and gatherers is never '\n","         'total, but is striking when viewed in an evolutionary context. One '\n","         \"of humanity's two closest primate relatives, chimpanzees, are \"\n","         'anything but egalitarian, forming themselves into hierarchies that '\n","         'are often dominated by an alpha male. So great is the contrast with '\n","         'human hunter-gatherers that it is widely argued by '\n","         'palaeoanthropologists that resistance to being dominated was a key '\n","         'factor driving the evolutionary emergence of human consciousness, '\n","         'language, kinship and social organization.'}\n","{'actual_answer': 'in an evolutionary context',\n"," 'actual_label': 1,\n"," 'predicted_answer': ['▁in', '▁an', '▁evolutionary', '▁context'],\n"," 'predicted_label': 1,\n"," 'question': \"How is it interesting to view hunter-gatherers' egalitarianism?\",\n"," 'text': 'The egalitarianism typical of human hunters and gatherers is never '\n","         'total, but is striking when viewed in an evolutionary context. One '\n","         \"of humanity's two closest primate relatives, chimpanzees, are \"\n","         'anything but egalitarian, forming themselves into hierarchies that '\n","         'are often dominated by an alpha male. So great is the contrast with '\n","         'human hunter-gatherers that it is widely argued by '\n","         'palaeoanthropologists that resistance to being dominated was a key '\n","         'factor driving the evolutionary emergence of human consciousness, '\n","         'language, kinship and social organization.'}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aM7ujFALyPtH"},"source":["**THIS IS THE END OF TRAINING CODE. THE CODE BELOW HASN'T BEEN REVIEWED/REWRITTEN**\n"]},{"cell_type":"code","metadata":{"id":"7EPaaRY2hQ42","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606825134381,"user_tz":-180,"elapsed":711,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"4bfc2f19-2365-4fd4-d042-13a0cbc68022"},"source":["from copy import deepcopy\n","deepcopy(d1)"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'actual_end': tensor([ 59,   0,  29,   0,  12,  68, 191,   0, 108,  40,  43, 104,   0,   0,\n","           0,  15]),\n"," 'actual_label': array([1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1]),\n"," 'actual_start': tensor([ 56,   0,  28,   0,  10,  59, 191,   0, 107,  37,  43, 103,   0,   0,\n","           0,  13]),\n"," 'full_probs': tensor([[-3.6336, -3.6336, -3.6336,  ..., -3.6336, -3.6336, -3.6336],\n","         [-3.5712, -3.6336, -3.6336,  ..., -3.6336, -3.6336, -3.6336],\n","         [-3.6336, -3.6336, -3.6336,  ..., -3.6336, -3.6336, -3.6336],\n","         ...,\n","         [-3.6336, -3.5904, -3.3390,  ..., -3.6336, -3.6336, -3.6336],\n","         [-3.6336, -3.6336, -3.6336,  ..., -3.6336, -3.6336, -3.6336],\n","         [-3.6336, -3.6336, -3.6336,  ..., -3.6336, -3.6336, -3.6336]]),\n"," 'indexing': tensor([80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]),\n"," 'input_ids': tensor([[    2,    72,   230,  ...,     0,     0,     0],\n","         [    2,   184,   175,  ...,     0,     0,     0],\n","         [    2,    32,    25,  ...,     0,     0,     0],\n","         ...,\n","         [    2,    98,  1025,  ...,     0,     0,     0],\n","         [    2,    98, 15448,  ...,     0,     0,     0],\n","         [    2,    98,    63,  ...,     0,     0,     0]]),\n"," 'label_prob': tensor([ 4.0201, -6.6683,  2.2474, -4.7025,  7.7143,  6.4186,  2.6226,  1.5820,\n","          3.4697,  5.1391,  1.8744,  5.6609,  3.5908, -6.9420, -4.7887, -1.9369]),\n"," 'num_examples': 16,\n"," 'num_labels_guessed': 13,\n"," 'predicted_label': array([1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0])}"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"_sug5SQ_Fwyc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f3XiObM4Fw54"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PoHcb1MmhQ8z"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DVWuTQ570bpy","colab":{"base_uri":"https://localhost:8080/","height":745},"outputId":"94196fca-1f79-43ee-fa96-393afdc08da3"},"source":["bert_finetuner"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SQUADBERT(\n","  (bert): AlbertModel(\n","    (embeddings): AlbertEmbeddings(\n","      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): AlbertTransformer(\n","      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n","      (albert_layer_groups): ModuleList(\n","        (0): AlbertLayerGroup(\n","          (albert_layers): ModuleList(\n","            (0): AlbertLayer(\n","              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (attention): AlbertAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              )\n","              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n","              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (pooler): Linear(in_features=768, out_features=768, bias=True)\n","    (pooler_activation): Tanh()\n","  )\n","  (A1): Linear(in_features=768, out_features=100, bias=True)\n","  (B1): Linear(in_features=768, out_features=100, bias=True)\n","  (LG1): Linear(in_features=10, out_features=2, bias=True)\n","  (A2): Linear(in_features=768, out_features=100, bias=True)\n","  (B2): Linear(in_features=768, out_features=100, bias=True)\n","  (LG2): Linear(in_features=10, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"bNR0ipTe0b1-"},"source":["def get_random_batch(model):\n","  iterator = iter(model.val_dataloader())\n","  batch = iterator.next()\n","  #for i in batch:\n","  #  i = i.to(torch.device('cuda',0))\n","  return (batch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3I-AErsq1F7t"},"source":["def predict(model, batch):\n","  input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","  return model(input_ids, attention_mask, token_type_ids)\n","\n","def convert_predictions(l1, l2, label, answer_mask):\n","  a, y1 = torch.max(l1, dim=1)\n","  a, y2 = torch.max(l2, dim=2)\n","  guess1, guess2 = final_guess(l1, l2)\n","  \"\"\"if self.counter < 10:\n","    self.counter += 1\n","    self.dic_1[self.counter] = [l2, y2]\"\"\"\n","  d_pre = results_dic(y1, y2, label, answer_mask)\n","  d_post = results_dic(guess1, guess2, label, answer_mask)\n","  return y1, y2, guess1, guess2, d_pre, d_post"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AuwZv_Ng1GED"},"source":["batch =  get_random_batch(new_model)#(bert_finetuner)\n","input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","l1, l2 = predict(new_model, batch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zopOdSYalAgt","colab":{"base_uri":"https://localhost:8080/","height":87},"outputId":"3b721249-e3bf-4f35-cb3e-6b4462827b94"},"source":["print(indexing)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([  1709,  50257,  28607,  85809,  18089,  43168, 109889, 114528,  36480,\n","        105855,  90441,  58618,  93205, 103048,  66757,  74668,   6850,  47620,\n","         88623,  44466,  21506, 101689,  32743,  40006,  49163, 112892,  74904,\n","         62193,  44188,  93296, 116388,  26653])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZARZmoMN0b_R"},"source":["y1, y2, guess1, guess2, d1, d2 = convert_predictions(l1, l2, label, answer_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ck-huWF-SYW","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"1d14eff0-689b-41d2-d751-9fdf01f18b1e"},"source":["print(y1)\n","print(guess1.type(torch.IntTensor))\n","print(label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n","        1, 1, 1, 1, 0, 1, 1, 0])\n","tensor([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n","        1, 1, 1, 1, 0, 1, 1, 0], device='cpu', dtype=torch.int32)\n","tensor([0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n","        1, 1, 1, 0, 0, 1, 1, 0])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LCaGo_h8Uvn1","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"bce5ca45-cf14-49ff-99d7-63b2381238f1"},"source":["print(y1)\n","print(guess1.type(torch.IntTensor))\n","print(label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n","        1, 0, 0, 1, 1, 0, 1, 1])\n","tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n","        1, 0, 1, 1, 1, 0, 1, 1], device='cpu', dtype=torch.int32)\n","tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n","        1, 0, 1, 1, 1, 0, 1, 1])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bAJG51UM-A5d","colab":{"base_uri":"https://localhost:8080/","height":834},"outputId":"6fb66077-5a43-4839-90d5-4137d729b006"},"source":["i = 10\n","print(y2[i])\n","print(guess2[i].type(torch.IntTensor))\n","print(answer_mask[i])\n","index = indexing[i].item()\n","print(torch.IntTensor(plausible_answer_mask[index]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cpu',\n","       dtype=torch.int32)\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cpu',\n","       dtype=torch.int32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LnoqxsIM_xwM","colab":{"base_uri":"https://localhost:8080/","height":161},"outputId":"d8198c69-5829-417e-d9b8-8537bf94ffad"},"source":["print(get_answer(input_ids[i], answer_mask[i]))\n","\n","print(get_answer(input_ids[i], guess2[i]))\n","index = indexing[i].item()\n","print(index)\n","print(full_answers[index])\n","print(full_questions[index])\n","print(full_paragraphs[index])\n","print(get_answer(input_ids[i], torch.Tensor(plausible_answer_mask[index])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['▁arab']\n","None\n","90441\n","Arab\n","What race was the majority in Palestine in the 1940s?\n","The British Mandate of Palestine, where an Arab majority lived alongside a Jewish minority, presented the British with a similar problem to that of India. The matter was complicated by large numbers of Jewish refugees seeking to be admitted to Palestine following the Holocaust, while Arabs were opposed to the creation of a Jewish state. Frustrated by the intractability of the problem, attacks by Jewish paramilitary organisations and the increasing cost of maintaining its military presence, Britain announced in 1947 that it would withdraw in 1948 and leave the matter to the United Nations to solve. The UN General Assembly subsequently voted for a plan to partition Palestine into a Jewish and an Arab state.\n","['▁arab']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I2J50MNEAhOQ"},"source":["def get_answer(input_id, answer):\n","  indices = (numpy.nonzero(answer)).tolist()\n","  #print(indices)\n","  #  indices.append(l[0])\n","  if indices:\n","    tokens = tokenizer.convert_ids_to_tokens(input_id)\n","    return tokens[indices[0][0]:indices[-1][0]+1]\n","  else:\n","    return None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WB9GOlzXld7M"},"source":["def get_probabilities_individual(l, answer):\n","  indices = (numpy.nonzero(answer)).tolist()\n","  if indices:\n","    res = l[indices[0][0]:indices[-1][0]+1]\n","    return res[:,1] - res[:,0]\n","  else:\n","    return None\n","\n","def get_probability_label(l):\n","  return l[1] - l[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oVEDXob-l4fm","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"d1abef62-8ddb-4575-8975-69a8cec86a01"},"source":["print(get_probabilities_individual(l2[i], guess2[i]))\n","print(get_probability_label(l1[i]))\n","print(guess1[i] - label[i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["None\n","tensor(-0.8393, grad_fn=<SubBackward0>)\n","tensor(-1.)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"55yY-rZ6Dr3A"},"source":["def get_wrong_guesses(guesses, lbls):\n","  wrong_guesses = []\n","  for x in (guesses - lbls).nonzero().cpu().numpy().tolist():\n","    wrong_guesses.append(x[0])\n","  return wrong_guesses"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ThmCMhScEqBY","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"52664d18-6788-467e-d927-924858fb8b95"},"source":["wrong_guesses = get_wrong_guesses(y1, label)\n","print(wrong_guesses)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[10, 26]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fhV42t3I0KOw","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"248107bd-b38a-413f-ab51-f378f979daad"},"source":["i = 26\n","print(get_probabilities_individual(l2[i], guess2[i]))\n","print(get_probabilities_individual(l2[i], answer_mask[i]))\n","index = indexing[i].item()\n","print(get_probabilities_individual(l2[i], torch.Tensor(plausible_answer_mask[index])))\n","print(get_probability_label(l1[i]))\n","#print(guess1[i] - label[i])\n","print(guess1[i], label[i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([3.1200, 2.9809, 2.7662, 3.3491, 0.1146, 0.0939, 0.4229],\n","       grad_fn=<SubBackward0>)\n","tensor([3.1200, 2.9809, 2.7662, 3.3491], grad_fn=<SubBackward0>)\n","tensor([3.1200, 2.9809, 2.7662, 3.3491], grad_fn=<SubBackward0>)\n","tensor(-0.6872, grad_fn=<SubBackward0>)\n","tensor(1.) tensor(1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zVbJ_YSXlq6X","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b62e26cd-1418-4907-f85f-fa6a5ce421d1"},"source":["l1.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 2])"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tQ4whqxy3JLg","executionInfo":{"status":"ok","timestamp":1606684555665,"user_tz":-180,"elapsed":722,"user":{"displayName":"Антон Осиненко","photoUrl":"","userId":"03486324011428020909"}},"outputId":"153c6f06-7071-494c-b45d-af340eda1541"},"source":["32*256*768*12*32/8/1024/1024"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["288.0"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"0s8xPk_s8SLd","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"dfaf627e-e448-4348-863c-025de107bd2b"},"source":["d1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answerable_actual': tensor(0.5625),\n"," 'answerable_result': tensor(0.5625),\n"," 'guessed_answerable': tensor(0.4375),\n"," 'guessed_ones': tensor(0.0115),\n"," 'ones_percentage_actual': tensor(0.0122),\n"," 'ones_percentage_guessed': tensor(0.0454),\n"," 'val_acc_individual': tensor(0.9653),\n"," 'val_acc_labels': tensor(0.7500)}"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"tHx6EqxVU30Q","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"241f371d-734a-4df7-b582-29a6cdcd24fb"},"source":["d1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answerable_actual': tensor(0.5625),\n"," 'answerable_result': tensor(0.5625),\n"," 'guessed_answerable': tensor(0.4375),\n"," 'guessed_ones': tensor(0.0115),\n"," 'ones_percentage_actual': tensor(0.0122),\n"," 'ones_percentage_guessed': tensor(0.0454),\n"," 'val_acc_individual': tensor(0.9653),\n"," 'val_acc_labels': tensor(0.7500)}"]},"metadata":{"tags":[]},"execution_count":147}]},{"cell_type":"code","metadata":{"id":"NAND2ZW88XMd","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"ec84b873-39db-4ada-952e-ab03073eebc9"},"source":["d2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answerable_actual': tensor(0.5625),\n"," 'answerable_result': tensor(0.5625),\n"," 'guessed_answerable': tensor(0.4375),\n"," 'guessed_ones': tensor(0.0112),\n"," 'ones_percentage_actual': tensor(0.0122),\n"," 'ones_percentage_guessed': tensor(0.0270),\n"," 'val_acc_individual': tensor(0.9833),\n"," 'val_acc_labels': tensor(0.7500)}"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"lVqPQ8u3VJ5t","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"711895e1-6ef7-4527-d4e5-54fe9caea34a"},"source":["d2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answerable_actual': tensor(0.5625),\n"," 'answerable_result': tensor(0.6875),\n"," 'guessed_answerable': tensor(0.5312),\n"," 'guessed_ones': tensor(0.0112),\n"," 'ones_percentage_actual': tensor(0.0122),\n"," 'ones_percentage_guessed': tensor(0.0270),\n"," 'val_acc_individual': tensor(0.9833),\n"," 'val_acc_labels': tensor(0.8125)}"]},"metadata":{"tags":[]},"execution_count":148}]},{"cell_type":"markdown","metadata":{"id":"tcrUfpD0X6nF"},"source":["##Saving"]},{"cell_type":"code","metadata":{"id":"T8i5psJPYCRY","colab":{"base_uri":"https://localhost:8080/","height":292},"outputId":"63fb2a35-ab66-43a4-8771-180c121a9b8a"},"source":["#bert_finetuner.save_checkpoint(base_dir + './saved_models_albert')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-152-22c3859db120>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_finetuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'./saved_models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'SQUADBERT' object has no attribute 'save_checkpoint'"]}]},{"cell_type":"code","metadata":{"id":"x6NEGHMBZGze"},"source":["#bert_finetuner."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bepR4KwgZyIo"},"source":["trainer.save_checkpoint(base_dir + 'saved_models/new')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LlBeUTTJYCaz","colab":{"base_uri":"https://localhost:8080/","height":316},"outputId":"e0b1b7b9-8ef0-4956-e957-0bc72b7ab90f"},"source":["#input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","#ll1, ll2 = predict(new_model, batch)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-175-e88a2b27191f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mll1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-144-abd96af2e684>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-cd8f6805240c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m    108\u001b[0m         q, _, attn = self.bert(input_ids=input_ids, \n\u001b[1;32m    109\u001b[0m                          \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                          token_type_ids=token_type_ids)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mq_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         )\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                 \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_idx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers_per_group\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgroup_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers_per_group\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m             )\n\u001b[1;32m    346\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_group_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malbert_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malbert_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mprojected_context_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bfnd,ndh->bfh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mprojected_context_layer_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojected_context_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mlayernormed_context_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprojected_context_layer_dropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayernormed_context_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_probs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_attentions\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayernormed_context_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 15.90 GiB total capacity; 15.14 GiB already allocated; 11.81 MiB free; 15.19 GiB reserved in total by PyTorch)"]}]},{"cell_type":"code","metadata":{"id":"rZew7826YCi3","colab":{"base_uri":"https://localhost:8080/","height":781},"outputId":"c2a72ba1-d41e-4678-fc60-c66c13b89bb8"},"source":["torch.set_default_tensor_type('torch.cuda.FloatTensor')\n","new_model = SQUADBERT({\"d1\": 10, 'l1' : 10, 'd2' : 10, 'l2' : 10}, batch_size = 32, weight = 20.)\n","#new_model = SQUADBERT.load_from_checkpoint(base_dir + 'saved_models/new')\n","checkpoint = torch.load(base_dir + 'saved_models/new', map_location=lambda storage, loc: storage)\n","new_model.load_state_dict(checkpoint['state_dict'])\n","new_model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train, validation, test --  114245 1166 1166\n","NEW\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SQUADBERT(\n","  (bert): AlbertModel(\n","    (embeddings): AlbertEmbeddings(\n","      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): AlbertTransformer(\n","      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n","      (albert_layer_groups): ModuleList(\n","        (0): AlbertLayerGroup(\n","          (albert_layers): ModuleList(\n","            (0): AlbertLayer(\n","              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (attention): AlbertAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              )\n","              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n","              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (pooler): Linear(in_features=768, out_features=768, bias=True)\n","    (pooler_activation): Tanh()\n","  )\n","  (A1): Linear(in_features=768, out_features=100, bias=True)\n","  (B1): Linear(in_features=768, out_features=100, bias=True)\n","  (LG1): Linear(in_features=10, out_features=2, bias=True)\n","  (A2): Linear(in_features=768, out_features=100, bias=True)\n","  (B2): Linear(in_features=768, out_features=100, bias=True)\n","  (LG2): Linear(in_features=10, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"PXiE35_AlMrg"},"source":["def predicte(model, batch):\n","  input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch\n","  #input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = input_ids.cpu(), attention_mask.cpu(), token_type_ids.cpu(), label.cpu(), answer_mask.cpu(), indexing.cpu()\n","  return model(input_ids, attention_mask, token_type_ids)\n","\n","def convert_predictions(l1, l2, label, answer_mask):\n","  a, y1 = torch.max(l1, dim=1)\n","  a, y2 = torch.max(l2, dim=2)\n","  guess1, guess2 = final_guess(l1, l2)\n","  \"\"\"if self.counter < 10:\n","    self.counter += 1\n","    self.dic_1[self.counter] = [l2, y2]\"\"\"\n","  d_pre = results_dic(y1, y2, label, answer_mask)\n","  d_post = results_dic(guess1, guess2, label, answer_mask)\n","  return y1, y2, guess1, guess2, d_pre, d_post"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGMkfO5TZux6"},"source":["test = torch.tensor(input_ids[153:155], dtype=torch.long).cuda(), torch.tensor(attention_mask[153:155], dtype=torch.long).cuda(), torch.tensor(token_type_ids[153:155], dtype=torch.long).cuda()\n","#                               1 - torch.tensor(labels, dtype=torch.long).cuda(), #label is 0 if there is an answer in the original dataset\n","#                                torch.tensor(answer_mask, dtype=torch.long).cuda(),\n","#                                torch.tensor(indexing, dtype=torch.long).cuda())\n","test_input_ids, test_attention_mask, test_token_type_ids = test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MzZlA05zab7s"},"source":["l1, l2 = bert_finetuner(test_input_ids, test_attention_mask, test_token_type_ids)\n","#v1, v2 = bert_finetuner(test_input_ids, test_attention_mask, test_token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z2GcGa67YCq1"},"source":["\"\"\"model = SQUADBERT('ProjectionModuleLong', {\"d1\": 8, 'l1' : 20, 'd2' : 8, 'l2' : 40}, batch_size = 32, weight = 60.)\n","checkpoint = torch.load(base_dir + \"/Checkpoints/_ckpt_epoch_2.ckpt\", map_location=lambda storage, loc: storage)\n","model.load_state_dict(checkpoint['state_dict'])\"\"\"\n","ll1, ll2 = new_model(test_input_ids, test_attention_mask, test_token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_7x4aQIxczUE","colab":{"base_uri":"https://localhost:8080/","height":283},"outputId":"135c322a-edfd-442a-fad6-62736fc6fe87"},"source":["l2-ll2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0., 0.],\n","         [0., 0.],\n","         [0., 0.],\n","         ...,\n","         [0., 0.],\n","         [0., 0.],\n","         [0., 0.]],\n","\n","        [[0., 0.],\n","         [0., 0.],\n","         [0., 0.],\n","         ...,\n","         [0., 0.],\n","         [0., 0.],\n","         [0., 0.]]], grad_fn=<SubBackward0>)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"kojxrYbPdO7f"},"source":["l1, _, l2 = bert_finetuner.bert(input_ids=test_input_ids, \n","                         attention_mask=test_attention_mask, \n","                         token_type_ids=test_token_type_ids)\n","ll1, _, ll2 = new_model.bert(input_ids=test_input_ids, \n","                         attention_mask=test_attention_mask, \n","                         token_type_ids=test_token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v10uVLUDn4e5"},"source":["lll1, _, lll2 = berty.cuda()(input_ids=test_input_ids, \n","                         attention_mask=test_attention_mask, \n","                         token_type_ids=test_token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oXZTvY3is0GN"},"source":["berty = AlbertModel.from_pretrained('albert-base-v1', output_attentions=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICb2xAhYs-ep"},"source":["berty = berty.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ve5EFiTp2saa","colab":{"base_uri":"https://localhost:8080/","height":692},"outputId":"3cc4576d-215e-4bd4-cb52-196a27d7c5db"},"source":["print(\"Model's state_dict:\")\n","for param_tensor in bert_finetuner.state_dict():\n","    print(param_tensor, \"\\t\", bert_finetuner.state_dict()[param_tensor].size())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model's state_dict:\n","bert.embeddings.word_embeddings.weight \t torch.Size([30000, 128])\n","bert.embeddings.position_embeddings.weight \t torch.Size([512, 128])\n","bert.embeddings.token_type_embeddings.weight \t torch.Size([2, 128])\n","bert.embeddings.LayerNorm.weight \t torch.Size([128])\n","bert.embeddings.LayerNorm.bias \t torch.Size([128])\n","bert.encoder.embedding_hidden_mapping_in.weight \t torch.Size([768, 128])\n","bert.encoder.embedding_hidden_mapping_in.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight \t torch.Size([3072, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias \t torch.Size([3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight \t torch.Size([768, 3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias \t torch.Size([768])\n","bert.pooler.weight \t torch.Size([768, 768])\n","bert.pooler.bias \t torch.Size([768])\n","A1.weight \t torch.Size([100, 768])\n","A1.bias \t torch.Size([100])\n","B1.weight \t torch.Size([100, 768])\n","B1.bias \t torch.Size([100])\n","LG1.weight \t torch.Size([2, 10])\n","LG1.bias \t torch.Size([2])\n","A2.weight \t torch.Size([100, 768])\n","A2.bias \t torch.Size([100])\n","B2.weight \t torch.Size([100, 768])\n","B2.bias \t torch.Size([100])\n","LG2.weight \t torch.Size([2, 10])\n","LG2.bias \t torch.Size([2])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WVc-MsFieptn","colab":{"base_uri":"https://localhost:8080/","height":478},"outputId":"6f3c7fb0-7462-4a46-f6f6-f5e0d6a19dfe"},"source":["print(\"Model's state_dict:\")\n","for param_tensor in bert_finetuner.state_dict():\n","    print(param_tensor, \"\\t\", bert_finetuner.state_dict()[param_tensor].size())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model's state_dict:\n","bert.embeddings.word_embeddings.weight \t torch.Size([30000, 128])\n","bert.embeddings.position_embeddings.weight \t torch.Size([512, 128])\n","bert.embeddings.token_type_embeddings.weight \t torch.Size([2, 128])\n","bert.embeddings.LayerNorm.weight \t torch.Size([128])\n","bert.embeddings.LayerNorm.bias \t torch.Size([128])\n","bert.encoder.embedding_hidden_mapping_in.weight \t torch.Size([768, 128])\n","bert.encoder.embedding_hidden_mapping_in.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight \t torch.Size([3072, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias \t torch.Size([3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight \t torch.Size([768, 3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias \t torch.Size([768])\n","bert.pooler.weight \t torch.Size([768, 768])\n","bert.pooler.bias \t torch.Size([768])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mUD0IG1xftWz","colab":{"base_uri":"https://localhost:8080/","height":478},"outputId":"3de4effe-1893-4312-87cc-485b0d520833"},"source":["print(\"Model's state_dict:\")\n","for param_tensor in new_model.state_dict():\n","    print(param_tensor, \"\\t\", new_model.state_dict()[param_tensor].size())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model's state_dict:\n","bert.embeddings.word_embeddings.weight \t torch.Size([30000, 128])\n","bert.embeddings.position_embeddings.weight \t torch.Size([512, 128])\n","bert.embeddings.token_type_embeddings.weight \t torch.Size([2, 128])\n","bert.embeddings.LayerNorm.weight \t torch.Size([128])\n","bert.embeddings.LayerNorm.bias \t torch.Size([128])\n","bert.encoder.embedding_hidden_mapping_in.weight \t torch.Size([768, 128])\n","bert.encoder.embedding_hidden_mapping_in.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight \t torch.Size([768, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight \t torch.Size([3072, 768])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias \t torch.Size([3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight \t torch.Size([768, 3072])\n","bert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias \t torch.Size([768])\n","bert.pooler.weight \t torch.Size([768, 768])\n","bert.pooler.bias \t torch.Size([768])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zGez9s2PuF3F"},"source":["input_ids, attention_mask, token_type_ids, label, answer_mask, indexing = batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Du2ImLt5uGAb"},"source":["q, _, _ = new_model.bert(input_ids=input_ids, \n","                         attention_mask=attention_mask, \n","                         token_type_ids=token_type_ids)\n","\n","qq, _, _ = berty(input_ids=input_ids, \n","                         attention_mask=attention_mask, \n","                         token_type_ids=token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kX39hwn6yDUc","colab":{"base_uri":"https://localhost:8080/","height":167},"outputId":"71477994-4954-4cf6-8042-ec33200a708b"},"source":[""],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-b862d2305077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_finetuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: summarize() missing 1 required positional argument: 'mode'"]}]},{"cell_type":"code","metadata":{"id":"CQ2Bw7FhYCyx"},"source":["import pickle\n","with open(base_dir + r\"l1l2\", \"wb\") as f:\n","    pickle.dump([l1, l2], f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xh4le09AYC6I"},"source":["with open(base_dir + r\"l1l2\", \"rb\") as f:\n","    [l1, l2] = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DthsMjZrYDCF"},"source":["with open(base_dir + r\"batch\", \"wb\") as f:\n","    pickle.dump(batch, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LzxZpx_fYDJo"},"source":["with open(base_dir + r\"batch\", \"rb\") as f:\n","    batch = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHjVXlyDgo9Z","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"76574056-8238-40f6-dabb-a5bb7a4165c2"},"source":["for i in range(len(batch)):\n","  print((batch[i] - batchh[i]).sum())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(0)\n","tensor(0)\n","tensor(0)\n","tensor(0)\n","tensor(0)\n","tensor(0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ie9HtHcwg_6u","colab":{"base_uri":"https://localhost:8080/","height":585},"outputId":"10a8f18a-4bf6-46d4-bcb6-13fb9b4e4747"},"source":["l1 - ll1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.3311, -1.1707],\n","        [-1.1836,  0.5233],\n","        [-0.3844, -0.3816],\n","        [-0.8956, -0.1006],\n","        [ 0.0560, -0.4223],\n","        [ 0.1867, -0.2628],\n","        [ 1.3606, -1.6090],\n","        [-1.6539,  0.3736],\n","        [-0.6360,  0.2532],\n","        [ 0.4264, -0.8577],\n","        [-1.4590,  0.6360],\n","        [ 0.0429, -0.3946],\n","        [-1.3437,  0.4152],\n","        [-1.2637,  0.2589],\n","        [-0.6773, -0.2426],\n","        [-0.4709,  0.0996],\n","        [ 0.6763, -0.9663],\n","        [ 0.6074, -0.9704],\n","        [ 1.3427, -0.6838],\n","        [-0.4018, -0.3278],\n","        [-0.7176,  0.1280],\n","        [-0.6025, -0.2789],\n","        [-1.1873,  0.7783],\n","        [-0.4975, -0.0069],\n","        [-1.1089, -0.0882],\n","        [-1.2815,  0.2321],\n","        [-0.0177, -0.4595],\n","        [-1.4720,  0.4155],\n","        [ 0.4455, -0.4733],\n","        [-0.6149, -0.2658],\n","        [-1.4690,  0.5316],\n","        [ 0.2757, -0.8703]], grad_fn=<SubBackward0>)"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"tyEp0rWqRTY7","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"f3f70f51-e687-4485-9e39-21d4f37990da"},"source":["'''\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","\n","# DEFAULTS used by the Trainer\n","checkpoint_callback = ModelCheckpoint(\n","    filepath='./saved_models',\n","    save_best_only=True,\n","    verbose=True,\n","    monitor='val_loss',\n","    mode='min',\n","    prefix=''\n",")\n","\n","#trainer = Trainer(checkpoint_callback=checkpoint_callback)\n","'''\n","#!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nfrom pytorch_lightning.callbacks import ModelCheckpoint\\n\\n# DEFAULTS used by the Trainer\\ncheckpoint_callback = ModelCheckpoint(\\n    filepath='./saved_models',\\n    save_best_only=True,\\n    verbose=True,\\n    monitor='val_loss',\\n    mode='min',\\n    prefix=''\\n)\\n\\n#trainer = Trainer(checkpoint_callback=checkpoint_callback)\\n\""]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"E6kuinpEU17b"},"source":["#!pip install apex\n","#import apex"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0UT3mRNoot1"},"source":["#import apex"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NZ1X94Lw-5pB"},"source":["## Summary\n","\n","That's it! Checkout [PyTorch Lightning](https://github.com/williamFalcon/pytorch-lightning/) which works with any machine learning approach that uses PyTorch."]},{"cell_type":"code","metadata":{"id":"4ARIT37rDdIZ"},"source":["from pprint import pprint as pp\n","pp(bert_finetuner.dic_1[1][1].cpu().numpy()[:5,:20])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pytSP8OxOrr1"},"source":["print(bert)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GHbKj70yOs3D"},"source":["bert_finetuner.dic_1[1][1].shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YfZpDAhMUwQO"},"source":["type(torch.Tensor(answer_mask).type(torch.cuda.FloatTensor))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_VPqM8BRa72r"},"source":["#dict_data = {\"input_ids\": input_ids, \"token_type_ids\": token_type_ids, \"labels\": labels, \"attention_mask\": attention_mask}\n","with open(base_dir + r\"albert256_tensor3model20.pickle\", \"wb\") as f:\n","    pickle.dump(bert_finetuner, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_1wxNwtIb64P"},"source":["torch.save(bert_finetuner, (base_dir + r\"albert256_tensor3model20\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gk9iV6KFdYxP"},"source":["trainer.default_save_path = base_dir + r'albert_model256'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HN-zi80lecp0"},"source":["try:\n","    from apex import amp\n","\n","    APEX_AVAILABLE = True\n","except ImportError:\n","    APEX_AVAILABLE = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a75UtTTYVC8G"},"source":["APEX_AVAILABLE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_YqJZx5VEY6"},"source":["a = torch.Tensor([[1,2,3],[4,5,6]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4goV0SYr8qqV"},"source":["torch.reshape(a,(2,2,2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rMJ4fE3N8ub-"},"source":["a.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q_Jhdys19Hwp"},"source":["torch.cat([a]*5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gtcok93D9gvq"},"source":["a = torch.Tensor([[1,0,1],[0,1,0]])\n","print(a.shape)\n","b = torch.Tensor([[1,0,0], [1, 0, 0]])\n","print(a*b)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p0P2I2KMT6jy"},"source":["print(torch.mul(a, b))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AmSXS5hqUQF5"},"source":["print((a==b).type(torch.cuda.FloatTensor).mean())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IG3Xpnc9Uatc"},"source":[""],"execution_count":null,"outputs":[]}]}